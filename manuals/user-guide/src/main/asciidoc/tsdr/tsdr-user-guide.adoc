== TSDR User Guide
This document describes how to use HSQLDB, HBase, and Cassandra Data Stores to 
capture time series data using Time Series Data Repository (TSDR) feature 
in the OpenDaylight Beryllium release. This document contains configuration, 
administration, management, usage, and troubleshooting sections for the feature.

=== Overview
The Time Series Data Repository (TSDR) project in OpenDaylight (ODL) creates a 
framework for collecting, storing, querying, and maintaining time series data 
in then OpenDaylight SDN controller. TSDR provides the framework for plugging 
in proper data collectors to collect various time series data and store into 
TSDR Data Stores. With a common data model and generic TSDR data persistence 
APIs, the user could choose various data stores to be plugged into TSDR 
Persistence framework. In Beryllium, two types of data stores are supported: 
HSQLDB relational database, HBase NoSQL database, and Cassandra database.

With the capabilities of data collection, storage, query, aggregation, and 
purging provided by TSDR, network administrators could leverage various data 
driven appliations built on top of TSDR for security risk detection, 
performance analysis, operational configuration optimization, traffic
engineering, and network analytics with automated intelligence.


=== TSDR Architecture
TSDR contains the following services and components:

* Data Collection Service
* Data Storage Service
* TSDR Persistence Layer with data stores as plugins
* TSDR Data Stores
* Data Query Service
* Data Aggregation Service
* Data Purging Service

Data Collection Service handles the collection of time series data into TSDR and 
hands it over to Data Storage Service. Data Storage Service stores the data into 
TSDR through TSDR Persistence Layer. TSDR Persistence Layer provides generic 
Service APIs allowing various data stores to be plugged in. Data Aggregation 
Service aggregates time series fine-grained raw data into course-grained roll-up 
data to control the size of the data. Data Purging Service periodically purges 
both fine-grained raw data and course-granined aggregated data according to 
user-defined schedules.


We have implemented Data Collection Service, Data Storage Service, TSDR 
Persistence Layer, TSDR H2 Data Store, TSDR HBase Data Store, and TSDR Cassandra 
Datastore. Among these services and components, time series data is communicated 
using a common TSDR data model, which is designed and implemented for the 
abstraction of time series data commonalities. With these functions, TSDR will 
be able to collect the data from the data sources and store them into one of 
the TSDR data stores: either HSQLDB Data Store, HBase Data Store or Cassandra Data 
Store. We also provided a simple query command from Karaf console for the user 
to retrieve TSDR data from the data stores.

=== Configuring TSDR Data Stores
To Configure HSQLDB Data Store:
The HSQLDB based storage files get stored automatically in <karaf install folder>/tsdr/ 
directory. If you want to change the default storage location, the configuration 
file to change can be found in <karaf install folder>/etc directory. The filename 
is org.ops4j.datasource-metric.cfg. Change the last portion of the  url=jdbc:hsqldb:./tsdr/metric  
to point to different directory. 
 
To Configure HBase Data Store:
After installing HBase Server on the same VM as the OpenDaylight Controller, if the user accepts the default configuration of the HBase Data Store, the user can directly proceed with the installation of HBase Data Store from Karaf console.

Optionally, the user can configure TSDR HBase Data Store following HBase Data Store Configuration Procedure.

* HBase Data Store Configuration Steps

** Open the file etc/tsdr-persistence-hbase.peroperties under karaf distribution directory. 
** Edit the following parameters:
*** HBase server name 
*** HBase server port
*** HBase client connection pool size
*** HBase client write buffer size

After the configuration of HBase Data Store is complete, proceed with the installation of HBase Data Store from Karaf console.

* HBase Data Store Installation Steps

** Start Karaf Console
** Run the following commands from Karaf Console:
feature:install odl-tsdr-hbase

To Configure Cassandra Data Store:
The TSDR project in Beryllium collects OpenFlow statistics data published to ODL controller in-memory data store and persist the data into persistence data stores. In Beryllium, TSDR provides Cassandra as a external data store in addition to HBase and H2 which were supported in Lithium.

Support for the below features have been implemented with H2,HBase and Cassandra.

* Data Purging Service - Periodically purges data from TSDR.

* Data Collection Framework - Define Data Collection SPIs to allow plugging in of various types of collectors

* Syslog data collector - to collect syslog data from network elements.

* NetFlow data collector - to collect netflow data from network elements.

* SNMP Data Collector - to integrate with SNMP plugin to bring SNMP data into TSDR.

Additionally separate commands have been implemented to enable collection service for a specific feature and to enable individual data store plugins. 
 
=== Administering or Managing TSDR Data Stores
To Administer HSQLDB Data Store:

Once the TSDR default datastore feature (odl-tsdr-hsqldb-all) is enabled, the TSDR captured OpenFlow statistics metrics can be accessed from Karaf Console by executing the command 

 tsdr:list <metric-category> <starttimestamp> <endtimestamp>

wherein

* <metric-category> = any one of the following categories FlowGroupStats, FlowMeterStats, FlowStats, FlowTableStats, PortStats, QueueStats
* <starttimestamp> = to filter the list of metrics starting this timestamp 
* <endtimestamp>   = to filter the list of metrics ending this timestamp 

If either of <starttimestamp> or <endtimestamp> is not specified, this command displays the latest 1000 metrics captured. 

With TSDR functionality with default H2 datastore you get an additional command 

 tsdr:purgeAll 

This will  purge the entire collected tsdr metrics record. 

To Administer HBase Data Store:
* Using Karaf Command to retrieve data from HBase Data Store
The user first need to install hbase data store from karaf console:

feature:install odl-tsdr-hbase

The user can retrieve the data from HBase data store using the following commands from Karaf console:

 tsdr:list

 tsdr:list <CategoryName> <StartTime> <EndTime>

Typing tab will get the context prompt of the arguments when typeing the command in Karaf console.

* Troubleshooting issues with log files
** Karaf logs
Similar to other OpenDaylight components and features, TSDR HBase Data Store writes logging information to Karaf logs.  All the information messages, warnings, error messages, and debug messages are written to Karaf logs. 

** HBase logs
For HBase system level logs, the user can check standard HBase server logs, which is under <HBase-installation-directory>/logs.

To Administer Cassandra Data Store:

The user first needs to install Cassandra data store from Karaf console:

 feature:install odl-tsdr-cassandra

Then the user can retrieve the data from Cassandra data store using the following commands from Karaf console:

 tsdr:list

 tsdr:list <CategoryName> <StartTime> <EndTime>

Typing tab will get the context prompt of the arguments when typeing the command in Karaf console.

* Troubleshooting issues with log files
** Karaf logs
Similar to other OpenDaylight components and features, TSDR Cassandra Data Store writes logging information to Karaf logs.  All the information messages, warnings, error messages, and debug messages are written to Karaf logs. 

==== How to use TSDR to collect, store, and view OpenFlow Interface Statistics 

===== Overview
This tutorial describes an example of using TSDR to collect, store, and view one type of time series data in OpenDaylight environment. 


===== Prerequisites
You would need to have the following as prerequisits:

* One or multiple OpenFlow enabled switches. Alternatively, you can use mininet to simulate such a switch.
* Successfully installed OpenDaylight Controller.
* Successfully installed HBase Data Store following TSDR HBase Data Store Installation Guide.
* Connect the OpenFlow enabled switch(es) to OpenDaylight Controller.
===== Target Environment
HBase data store is only supported in Linux operation system.

===== Instructions

* Start OpenDaylight controller.

* Connect OpenFlow enabled switch(es) to the controller.

** If using mininet, run the following commands from mininet command line:

*** mn --topo single,3  --controller 'remote,ip=172.17.252.210,port=6653' --switch ovsk,protocols=OpenFlow13

** If using real switch(es), the OpenDaylight controller should be able to discover the network toplogy containing the switches.


* Install tsdr hbase feature from Karaf:

** feature:install odl-tsdr-hbase

* run the following command from Karaf console:

** tsdr:list InterfaceStats

You should be able to see the interface statistics of the switch(es) from the HBase Data Store. If there are too many rows, you can use "tsdr:list InterfaceStats|more" to view it page by page.

By tabbing after "tsdr:list", you will see all the supported data categories. For example, "tsdr:list FlowStats" will output the Flow statistics data collected from the switch(es).

