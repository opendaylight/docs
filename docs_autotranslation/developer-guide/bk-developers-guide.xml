<?xml version="1.0" encoding="UTF-8"?>
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:lang="en">
<info>
<title>OpenDaylight Developer Guide</title>
<date>2016-07-19</date>

    <author>
        <personname>
            <firstname>OpenDaylight</firstname>
            <surname>Community</surname>
        </personname>
        <email>documentation@opendaylight.org</email>
        <affiliation>
            <orgname>Linux Foundation</orgname>
        </affiliation>
    </author>
    <copyright>
        <year>2016</year>
        <holder>Linux Foundation</holder>
    </copyright>
    <releaseinfo>Boron</releaseinfo>
    <productname>OpenDaylight</productname>
    <pubdate></pubdate>
    <legalnotice role="license">
        <para> This program and the accompanying materials are made available under the terms of the Eclipse Public License v1.0 which accompanies this distribution, and is available at <link xlink:href="http://www.eclipse.org/legal/epl-v10.html"/></para>
    </legalnotice>
    <abstract>
        <para>This guide describes how to develop using OpenDaylight.</para>
    </abstract>
    <revhistory>
        <revision>
            <date>2014-08-03</date>
            <revdescription>
                <itemizedlist spacing="compact">
                    <listitem>
                        <para>Initial Guide Creation</para>
                    </listitem>
                </itemizedlist>
            </revdescription>
        </revision>
    </revhistory>



</info>
<part xml:id="_overview">
<title>Overview</title>
<chapter xml:id="_getting_started_with_git_and_gerrit">
<title>Getting started with Git and Gerrit</title>
<section xml:id="_overview_of_git_and_gerrit">
<title>Overview of Git and Gerrit</title>
<simpara>Git is an opensource distributed version control system (dvcs) written in the C language and originally developed by Linus Torvalds and others to manage the Linux kernel. In Git, there is no central copy of the repository. After you have cloned the repository, you have a functioning copy of the source code with all the branches and tagged releases, in your local repository.</simpara>
<simpara>Gerrit is an opensource web-based collaborative code review tool that integrates with Git. It was developed at Google by Shawn Pearce. Gerrit provides a framework for reviewing code commits before they are accepted into the code base. Changes can be uploaded to Gerrit by any user. However, the changes are not made a part of the project until a code review is completed. Gerrit is also a good collaboration tool for storing the conversations that occur around the code commits.</simpara>
<simpara>The OpenDaylight source code is hosted in a repository in Git. Developers must use Gerrit to commit code to the OpenDaylight repository.</simpara>
<note>
<simpara>For more information on Git, see <link xlink:href="http://git-scm.com/">http://git-scm.com/</link>. For more information on Gerrit, see <link xlink:href="https://code.google.com/p/gerrit/">https://code.google.com/p/gerrit/</link>.</simpara>
</note>

</section>
<section xml:id="_setting_up_a_gerrit_account">
<title>Setting up a Gerrit account</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Using a Google Chrome or Mozilla Firefox browser, go to <link xlink:href="https://git.opendaylight.org/gerrit">https://git.opendaylight.org/gerrit</link></simpara>
</listitem>
</orderedlist>

<simpara>The main page shows existing Gerrit requests. These are patches that have been pushed to the repository and not yet verified, reviewed, and merged.</simpara>
<note>
<simpara>If you already have an OpenDaylight account, you can click <emphasis role="strong">Sign In</emphasis> in the top right corner of the page and follow the instructions to enter the OpenDaylight page.</simpara>
</note>

<figure>
<title>Signing in to OpenDaylight account</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Sign_in.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Signing in to OpenDaylight account</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>If you do not have an existing OpenDaylight account, click <emphasis role="strong">Account signup/management</emphasis> on the top bar of the main Gerrit page.</simpara>
</listitem>
</orderedlist>

<simpara>The <emphasis role="strong">WS02 Identity Server</emphasis> page is displayed.</simpara>
<figure>
<title>Gerrit Account signup/management link</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Gerrit_setup.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Account signup/management link</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">WS02 Identity Server</emphasis> page, click <emphasis role="strong">Sign-up</emphasis> in the left pane.</simpara>
</listitem>
</orderedlist>

<simpara>There is also an option to authenticate your sign in with OpenID. This option is not described in this document.</simpara>
<figure>
<title>Sign-up link for Gerrit account</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/sign-up.jpg"/>
    </imageobject>
    <textobject><phrase>Sign-up link for Gerrit account</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Click on the <emphasis role="strong">Sign-up with User Name/Password</emphasis> image on the right pane to continue to the actual sign-up page.</simpara>
</listitem>
</orderedlist>

<figure>
<title>Sign-up with User Name/Password Image</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/signup_image.jpg"/>
    </imageobject>
    <textobject><phrase>Sign-up with User Name / Password Image</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Fill out the details in the account creation form and then click <emphasis role="strong">Submit</emphasis>.</simpara>
</listitem>
</orderedlist>

<figure>
<title>Filling out the details</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/form_details.jpg"/>
    </imageobject>
    <textobject><phrase>Filling out the details</phrase></textobject>
  </mediaobject>
</figure>

<simpara>You now have an OpenDaylight account that can be used with Gerrit to pull the OpenDaylight code.</simpara>
</section>
<section xml:id="_generating_ssh_keys_for_your_system">
<title>Generating SSH keys for your system</title>
<simpara>You must have SSH keys for your system to register with your Gerrit account. The method for generating SSH keys is different for different types of operating systems.</simpara>
<simpara>The key you register with Gerrit must be identical to the one you will use later to pull or edit the code. For example, if you have a development VM which has a different UID login and keygen than that of your laptop, the SSH key you generate for the VM is different from the laptop. If you register the SSH key generated on your VM with Gerrit and do not reuse it on your laptop when using Git on the laptop, the pull fails.</simpara>
<note>
<simpara>For more information on SSH keys for Ubuntu, see <link xlink:href="https://help.ubuntu.com/community/SSH/OpenSSH/Keys">https://help.ubuntu.com/community/SSH/OpenSSH/Keys</link>. For generating SSH keys for Windows, see <link xlink:href="https://help.github.com/articles/generating-ssh-keys">https://help.github.com/articles/generating-ssh-keys</link>.</simpara>
</note>

<simpara>For a system running Ubuntu operating system, follow the steps below:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Run the following command:</simpara>
</listitem>
</orderedlist>


<literallayout class="monospaced">mkdir ~/.ssh
chmod 700 ~/.ssh
ssh-keygen -t rsa</literallayout>


<orderedlist numeration="arabic">
<listitem>
<simpara>You are prompted for a location to save the keys, and a passphrase for the keys.</simpara>
</listitem>
</orderedlist>

<simpara>This passphrase protects your private key while it is stored on the hard drive. You must use the passphrase to use the keys every time you need to login to a key-based system.</simpara>

<literallayout class="monospaced">Generating public/private rsa key pair.
Enter file in which to save the key (/home/b/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/b/.ssh/id_rsa.
Your public key has been saved in /home/b/.ssh/id_rsa.pub.</literallayout>


<simpara>Your public key is now available as <emphasis role="strong">.ssh/id_rsa.pub</emphasis> in your home folder.</simpara>
</section>
<section xml:id="_registering_your_ssh_key_with_gerrit">
<title>Registering your SSH key with Gerrit</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Using a Google Chrome or Mozilla Firefox browser, go to <link xlink:href="https://git.opendaylight.org/gerrit">https://git.opendaylight.org/gerrit</link>.</simpara>
</listitem>
</orderedlist>

<orderedlist numeration="arabic">
<listitem>
<simpara>Click <emphasis role="strong">Sign In</emphasis> to access the OpenDaylight repository.</simpara>
</listitem>
</orderedlist>

<figure>
<title>Signin in to OpenDaylight repository</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Sign_in.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Signin in to OpenDaylight repository</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Click your name in the top right corner of the window and then click <emphasis role="strong">Settings</emphasis>.</simpara>
</listitem>
</orderedlist>

<simpara>The <emphasis role="strong">Settings</emphasis> page is displayed.</simpara>
<figure>
<title>Settings page for your Gerrit account</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Gerrit_settings.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Settings page for your Gerrit account</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Click <emphasis role="strong">SSH Public Keys</emphasis> under <emphasis role="strong">Settings</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add Key</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Add SSH Public Key</emphasis> text box, paste the contents of your <emphasis role="strong">id_rsa.pub</emphasis> file and then click <emphasis role="strong">Add</emphasis>.</simpara>
</listitem>
</orderedlist>

<figure>
<title>Adding your SSH key</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/SSH_keys.jpg"/>
    </imageobject>
    <textobject><phrase>Adding your SSH key</phrase></textobject>
  </mediaobject>
</figure>

<simpara>To verify your SSH key is working correctly, try using an SSH client to connect to Gerrit&#8217;s SSHD port.</simpara>

<literallayout class="monospaced">$ ssh -p 29418 &lt;sshusername&gt;@git.opendaylight.org
Enter passphrase for key '/home/cisco/.ssh/id_rsa':
****    Welcome to Gerrit Code Review    ****
Hi &lt;user&gt;, you have successfully connected over SSH.
Unfortunately, interactive shells are disabled.
To clone a hosted Git repository, use: git clone ssh://&lt;user&gt;@git.opendaylight.org:29418/REPOSITORY_NAME.git
Connection to git.opendaylight.org closed.</literallayout>


<simpara>You can now proceed to either Pulling, Hacking, and Pushing the Code from the CLI or Pulling, Hacking, and Pushing the Code from Eclipse depending on your implementation.</simpara>
</section>
</chapter>
<chapter xml:id="_pulling_and_pushing_the_code_from_the_cli">
<title>Pulling and Pushing the Code from the CLI</title>
<simpara>OpenDayligh is a collection of projects, each with their own code repository. This section provides a general guide for to pulling, hacking, and pushing the code for each project. For project specific detail, refer to the project&#8217;s section in this guide.</simpara>
<simpara>Code reviews are enabled through Gerrit. For setting up Gerrit see the section on Getting started with Git and Gerrit.</simpara>
<note>
<simpara>You will need to perform the Gerrit Setup before you can access git via ssh as described below.</simpara>
</note>

<section xml:id="_pulling_code_via_git_cli">
<title>Pulling code via Git CLI</title>
<simpara>Pull the code by cloning the project&#8217;s repository.</simpara>
<screen> git clone ssh://&lt;username&gt;@git.opendaylight.org:29418/&lt;project_repo_name&gt;.git</screen>

<simpara>where &lt;username&gt; is your OpenDaylight username, and &lt;project_repo_name&gt; is the name of the repository for project you are trying to pull. Here is the current list of project repository names:</simpara>
<simpara>aaa, affinity, bgpcep, controller, defense4all, dlux, docs, groupbasedpolicy, integration, l2switch, lispflowmapping, odlparent, opendove, openflowjava, openflowplugin, opflex, ovsdb, packetcable, reservation, sdninterfaceapp, sfc, snbi, snmp4sdn, toolkit, ttp, vtn, yangtools.</simpara>
<simpara>For an anonymous git clone, you can use:</simpara>
<screen> git clone https://git.opendaylight.org/gerrit/p/&lt;project_repo_name&gt;.git</screen>

</section>
<section xml:id="_setting_up_gerrit_change_id_commit_message_hook">
<title>Setting up Gerrit Change-id Commit Message Hook</title>
<itemizedlist>
<listitem>
<simpara>This command inserts a unique Change-Id tag in the footer of a commit message. This step is optional but highly recommended for tracking changes.</simpara>
</listitem>
</itemizedlist>

<screen> cd &lt;project_repo_name&gt;
 scp -p -P 29418 &lt;username&gt;@git.opendaylight.org:hooks/commit-msg .git/hooks/
 chmod 755 .git/hooks/commit-msg</screen>

<itemizedlist>
<listitem>
<simpara>Install and setup Git-review. Git-review is a great tool to simplify the hassle of using several git commands to submit a patch for review. Refer to <link xlink:href="http://www.mediawiki.org/wiki/Gerrit/git-review#Installation%7Chere">How to install and push codes with git-review</link> for instructions. After initializing git-review, both commit-msg hook and a remote repo named gerrit will be created and a patch can be submitted to Gerrit with a single "git review" command.</simpara>
</listitem>
<listitem>
<simpara>Now you can start making your code changes.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_building_the_code">
<title>Building the code</title>
<simpara>While you are in the &lt;project_repo_name&gt; directory, run</simpara>
<screen> mvn clean install</screen>

<simpara>To run without unitests you can skip building those tests running the following:</simpara>
<screen> mvn clean install -DskipTests
 /* instead of "mvn clean install" */</screen>

</section>
<section xml:id="_runing_opendaylight_from_local_build">
<title>Runing OpenDaylight from local build</title>
<simpara>Change to the karaf distribution sub-directory, and run</simpara>
<screen> ./target/assembly/bin/karaf</screen>

<simpara>At this point the OpenDaylight controller is running. You can now open a web browser and point your browser at <link xlink:href="http://localhost:8080/">http://localhost:8080/</link></simpara>
<figure>
<title>OpenDaylight Main Page</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/800p_OpenDaylight_Login.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>OpenDaylight Main Page</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_commit_the_code_using_git_cli">
<title>Commit the code using Git CLI</title>
<note>
<simpara>To be accepted, all code mustcome with a <link xlink:href="http://elinux.org/Developer_Certificate_Of_Origin">developer certificate of origin</link> as expressed by having a Signed-off-by. This means that you are asserting that you have made the change and you understand that the work was done as part of an open-source license.</simpara>
</note>

<screen>Developer's Certificate of Origin 1.1

        By making a contribution to this project, I certify that:

        (a) The contribution was created in whole or in part by me and I
            have the right to submit it under the open source license
            indicated in the file; or

        (b) The contribution is based upon previous work that, to the best
            of my knowledge, is covered under an appropriate open source
            license and I have the right under that license to submit that
            work with modifications, whether created in whole or in part
            by me, under the same open source license (unless I am
            permitted to submit under a different license), as indicated
            in the file; or

        (c) The contribution was provided directly to me by some other
            person who certified (a), (b) or (c) and I have not modified
            it.

        (d) I understand and agree that this project and the contribution
            are public and that a record of the contribution (including all
            personal information I submit with it, including my sign-off) is
            maintained indefinitely and may be redistributed consistent with
            this project or the open source license(s) involved.</screen>

<simpara><emphasis role="strong">Mechanically you do it this way</emphasis>:</simpara>
<screen>git commit --signoff</screen>

<simpara>You will be prompted for a commit message. If you are fixing a buzilla bug you can add the associated bug number to your commit message and it will get linked from Gerrit:</simpara>
<formalpara>
<title>For Example:</title>
<para>
<screen>Fix for bug 2.

Signed-off-by: Ed Warnicke &lt;eaw@cisco.com&gt;
# Please enter the commit message for your changes. Lines starting
# with '#' will be ignored, and an empty message aborts the commit.
# On branch develop
# Changes to be committed:
#   (use "git reset HEAD &lt;file&gt;..." to unstage)
#
#       modified:   README
#</screen>
</para>
</formalpara>

</section>
<section xml:id="_pulling_the_code_changes_via_git_cli">
<title>Pulling the Code changes via Git CLI</title>
<simpara>Pull the latest changes from the remote repository</simpara>
<screen>git remote update
git rebase origin/&lt;project_main_branch_name&gt;</screen>

<simpara>where &lt;project_main_branch_name&gt; is the the branch you want to commit to. For most projects this is master branch. For some projects such as lispflowmapping, a different branch name (develop in the case of lispflowmapping) should be used.</simpara>
</section>
<section xml:id="_pushing_the_code_via_git_cli">
<title>Pushing the Code via Git CLI</title>
<simpara>Use git review to push your changes back to the remote repository using:</simpara>
<screen> git review</screen>

<simpara>You can set a topic for your patch by:</simpara>
<screen> git review -t &lt;topic&gt;</screen>

<simpara>You will get a message pointing you to your gerrit request like:</simpara>
<screen>==========================
remote: Resolving deltas: 100% (2/2) +
remote: Processing changes: new: 1, refs: 1, done    +
remote: +
remote: New Changes: +
remote:   http://git.opendaylight.org/gerrit/64 +
remote: +
==========================</screen>

<simpara>The Jenkins Controller User will verify your code and post the result on the your gerrit request.</simpara>
<section xml:id="_viewing_your_changes_in_gerrit">
<title>Viewing your Changes in Gerrit</title>
<simpara>Follow the link you got above to see your commit in Gerrit:</simpara>
<figure>
<title>Gerritt Code Review Sample</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/gerrit_code_review.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Gerritt Code Review Sample</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Note that the Jenkins Controller User has verified your code and at the bottom is a link to the Jenkins build.</simpara>
<simpara>Once your code has been reviewed and submitted by a committer it will be merged into the authoritative repo, which would look like this:</simpara>
<figure>
<title>Gerritt Code Merge Sample</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/gerrit_merged.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Gerritt Code Merge Sample</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_troubleshooting">
<title>Troubleshooting</title>
<orderedlist numeration="arabic">
<listitem>
<simpara><emphasis role="strong">What to do if your Firewall blocks port 29418</emphasis></simpara>
</listitem>
</orderedlist>

<simpara>There have been reports that many corporate firewalls block port 29418. If that&#8217;s the case, please follow the <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:Setting_up_HTTP_in_Gerrit">Setting up HTTP in Gerrit</link> instructions and use git URL:</simpara>
<screen>git clone https://&lt;your_username&gt;@git.opendaylight.org/gerrit/p/&lt;project_repo_name&gt;.git</screen>

<simpara>You will be prompted for the password you generated in <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:Setting_up_HTTP_in_Gerrit">Setting up HTTP in Gerrit</link>.</simpara>
<simpara>All other instructions on this page remain unchanged.</simpara>
<simpara>To download pre-built images with ODP bootstraps see the following Github project:</simpara>
<simpara><link xlink:href="https://github.com/nerdalert/OpenDaylight-Lab">Pre-Built OpenDaylight VM Images</link></simpara>
</section>
</section>
</chapter>
<chapter xml:id="_developing_apps_on_the_opendaylight_controller">
<title>Developing Apps on the OpenDaylight controller</title>
<simpara>This section provides information that is required to develop apps on the OpenDaylight controller.</simpara>
<simpara>You can either develop apps within the controller using the model-driven SAL (MD-SAL) archetype or develop external apps and use the RESTCONF to communicate with the controller.</simpara>
<section xml:id="_overview_2">
<title>Overview</title>
<simpara>This section enables you to get started with app development within the OpenDaylight controller. In this example, you perform the following steps to develop an app.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a local repository for the code using a simple build process.</simpara>
</listitem>
<listitem>
<simpara>Start the OpenDaylight controller.</simpara>
</listitem>
<listitem>
<simpara>Test a simple remote procedure call (RPC) which you have created based on the principle of <emphasis>hello world</emphasis>.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_pre_requisites">
<title>Pre requisites</title>
<simpara>This example requires the following.</simpara>
<itemizedlist>
<listitem>
<simpara>A development environment with following set up and working correctly from the shell:</simpara>
<itemizedlist>
<listitem>
<simpara>Maven 3.1.1 or later</simpara>
</listitem>
<listitem>
<simpara>Java 7- or Java 8-compliant JDK</simpara>
</listitem>
<listitem>
<simpara>An appropriate Maven settings.xml file. A simple way to get the default OpenDaylight settings.xml file is:</simpara>

<literallayout class="monospaced">cp -n ~/.m2/settings.xml{,.orig} ; \wget -q -O - https://raw.githubusercontent.com/opendaylight/odlparent/stable/lithium/settings.xml &gt; ~/.m2/settings.xml</literallayout>


</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<note>
<simpara>If you are using Linux or Mac OS X as your development OS, your local repository is ~/.m2/repository. For other platforms the local repository location will vary.</simpara>
</note>

</section>
<section xml:id="_building_an_example_module">
<title>Building an example module</title>
<simpara>To develop an app perform the following steps.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create an <emphasis>Example</emphasis> project using Maven and an archetype called the <emphasis>opendaylight-startup-archetype</emphasis>. If you are downloading this project for the first time, then it will take sometime to pull all the code from the remote repository.</simpara>
<programlisting language="shell" linenumbering="unnumbered">mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype \
-DarchetypeRepository=https://nexus.opendaylight.org/content/repositories/public/ \
-DarchetypeCatalog=https://nexus.opendaylight.org/content/repositories/public/archetype-catalog.xml</programlisting>

</listitem>
<listitem>
<simpara>Update the properties values as follows. Ensure that the groupid and the artifactid is lower case.</simpara>
<programlisting language="shell" linenumbering="unnumbered">Define value for property 'groupId': : org.opendaylight.example
Define value for property 'artifactId': : example
Define value for property 'version':  1.0-SNAPSHOT: : 1.0.0-SNAPSHOT
Define value for property 'package':  org.opendaylight.example: :
Define value for property 'classPrefix':  ${artifactId.substring(0,1).toUpperCase()}${artifactId.substring(1)}
Define value for property 'copyright': : Copyright (c) 2015 Yoyodyne, Inc.</programlisting>

</listitem>
<listitem>
<simpara>Accept the default value of classPrefix that is, <literal>(${artifactId.substring(0,1).toUpperCase()}${artifactId.substring(1)})</literal>.
The classPrefix creates a Java Class Prefix by capitalizing the first character of the artifactId.</simpara>
<note>
<simpara>In this scenario, the classPrefix used is "Example".
    Create a top-level directory for the archetype.</simpara>
</note>

<programlisting language="shell" linenumbering="unnumbered">${artifactId}/
example/
cd example/
api/
artifacts/
features/
impl/
karaf/
pom.xml</programlisting>

</listitem>
<listitem>
<simpara>Build the <emphasis>example</emphasis> project.</simpara>
<note>
<simpara>Depending on your development machine&#8217;s specification this might take a little while. Ensure that you are in the project&#8217;s root directory, example/, and then issue the build command, shown below.</simpara>
</note>

<programlisting language="shell" linenumbering="unnumbered">mvn clean install</programlisting>

</listitem>
<listitem>
<simpara>Start the <emphasis>example</emphasis> project for the first time.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd karaf/target/assembly/bin
ls
./karaf</programlisting>

</listitem>
<listitem>
<simpara>Wait for the karaf cli that appears as follows. Wait for OpenDaylight to fully load all the components. This can take a minute or two after the prompt appears. Check the CPU on your dev machine, specifically the Java process to see when it calms down.</simpara>
<programlisting language="shell" linenumbering="unnumbered">opendaylight-user@root&gt;</programlisting>

</listitem>
<listitem>
<simpara>Verify if the “example” module is built and search  for the log entry which includes the entry <emphasis>ExampleProvider Session Initiated</emphasis>.</simpara>
<programlisting language="shell" linenumbering="unnumbered">log:display | grep Example</programlisting>

</listitem>
<listitem>
<simpara>Shutdown the OpenDaylight through the console by using the following command.</simpara>
<programlisting language="shell" linenumbering="unnumbered">shutdown -f</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_defining_a_simple_hello_world_rpc">
<title>Defining a Simple Hello World RPC</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Run the maven archetype <emphasis>opendaylight-startup-archetype</emphasis>, and create the <emphasis>hello</emphasis> project.<?asciidoc-br?></simpara>
<programlisting language="shell" linenumbering="unnumbered">mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype \
-DarchetypeRepository=http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/ \
-DarchetypeCatalog=http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/archetype-catalog.xml</programlisting>

</listitem>
<listitem>
<simpara>Update the Properties values as follows.</simpara>
<programlisting language="shell" linenumbering="unnumbered">Define value for property 'groupId': : org.opendaylight.hello
Define value for property 'artifactId': : hello
Define value for property 'version':  1.0-SNAPSHOT: : 1.0.0-SNAPSHOT
Define value for property 'package':  org.opendaylight.hello: :
Define value for property 'classPrefix':  ${artifactId.substring(0,1).toUpperCase()}${artifactId.substring(1)}
Define value for property 'copyright': : Copyright(c) Yoyodyne, Inc.</programlisting>

</listitem>
<listitem>
<simpara>View the <emphasis>hello</emphasis> project.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd hello/
ls -1
api
artifacts
features
impl
karaf
pom.xml</programlisting>

</listitem>
<listitem>
<simpara>Build <emphasis>hello</emphasis> project by using the following command.</simpara>
<programlisting language="shell" linenumbering="unnumbered">mvn clean install</programlisting>

</listitem>
<listitem>
<simpara>Verify  that the project is functioning by executing karaf.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd karaf/target/assembly/bin
./karaf</programlisting>

</listitem>
<listitem>
<simpara>The karaf cli appears as follows.<?asciidoc-br?>
NOTE: Remember to wait for OpenDaylight to load completely. Verify that the Java process CPU has stabilized.+</simpara>
<programlisting language="shell" linenumbering="unnumbered">opendaylight-user@root&gt;</programlisting>

</listitem>
<listitem>
<simpara>Verify that the <emphasis>hello</emphasis> module is loaded by checking the log.</simpara>
<programlisting language="shell" linenumbering="unnumbered">log:display | grep Hello</programlisting>

</listitem>
<listitem>
<simpara>Shutdown karaf.</simpara>
<programlisting language="shell" linenumbering="unnumbered">shutdown -f</programlisting>

</listitem>
<listitem>
<simpara>Return to the top of the directory structure:</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../../../../</programlisting>

</listitem>
<listitem>
<simpara>View the entry point to understand where the log line came from. The entry point is in the impl project:</simpara>
<programlisting language="shell" linenumbering="unnumbered">impl/src/main/java/org/opendaylight/hello/impl/HelloProvider.java</programlisting>

</listitem>
<listitem>
<simpara>Add any new things that you are doing in your implementation by using the HelloProvider.onSessionInitiate method. Its analogous to an Activator.</simpara>
<programlisting language="java" linenumbering="unnumbered">@Override
    public void onSessionInitiated(ProviderContext session) {
        LOG.info("HelloProvider Session Initiated");
    }</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_add_a_simple_helloworld_rpc_api">
<title>Add a simple HelloWorld RPC API</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Navigate to the file.</simpara>
<screen>Edit
api/src/main/yang/hello.yang</screen>

</listitem>
<listitem>
<simpara>Edit this file as follows. In the following example, we are adding the code in a YANG module to define the <emphasis>hello-world</emphasis> RPC:</simpara>
<programlisting language="yang" linenumbering="unnumbered">module hello {
    yang-version 1;
    namespace "urn:opendaylight:params:xml:ns:yang:hello";
    prefix "hello";
    revision "2015-01-05" {
        description "Initial revision of hello model";
    }
    rpc hello-world {
        input {
            leaf name {
                type string;
            }
        }
        output {
            leaf greating {
                type string;
            }
        }
    }
}</programlisting>

</listitem>
<listitem>
<simpara>Return to the hello/api directory and build your API as follows.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../../../
mvn clean install</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_implement_the_helloworld_rpc_api">
<title>Implement the HelloWorld RPC API</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Define the HelloService, which is invoked through the <emphasis>hello-world</emphasis> API.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../impl/src/main/java/org/opendaylight/hello/impl/</programlisting>

</listitem>
<listitem>
<simpara>Create a new file called HelloWorldImpl.java and add in the code below.</simpara>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.hello.impl;
import java.util.concurrent.Future;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloService;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldInput;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldOutput;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldOutputBuilder;
import org.opendaylight.yangtools.yang.common.RpcResult;
import org.opendaylight.yangtools.yang.common.RpcResultBuilder;
public class HelloWorldImpl implements HelloService {
    @Override
    public Future&lt;RpcResult&lt;HelloWorldOutput&gt;&gt; helloWorld(HelloWorldInput input) {
        HelloWorldOutputBuilder helloBuilder = new HelloWorldOutputBuilder();
        helloBuilder.setGreating("Hello " + input.getName());
        return RpcResultBuilder.success(helloBuilder.build()).buildFuture();
    }
}</programlisting>

</listitem>
<listitem>
<simpara>The HelloProvider.java file is in the current directory. Register the RPC that you created in the <emphasis>hello.yang</emphasis> file in the HelloProvider.java file. You can either edit the HelloProvider.java to match what is below or you can simple replace it with the code below.</simpara>
<programlisting language="java" linenumbering="unnumbered">/*
 * Copyright(c) Yoyodyne, Inc. and others.  All rights reserved.
 *
 * This program and the accompanying materials are made available under the
 * terms of the Eclipse Public License v1.0 which accompanies this distribution,
 * and is available at http://www.eclipse.org/legal/epl-v10.html
 */
package org.opendaylight.hello.impl;

import org.opendaylight.controller.sal.binding.api.BindingAwareBroker.ProviderContext;
import org.opendaylight.controller.sal.binding.api.BindingAwareBroker.RpcRegistration;
import org.opendaylight.controller.sal.binding.api.BindingAwareProvider;
import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class HelloProvider implements BindingAwareProvider, AutoCloseable {
    private static final Logger LOG = LoggerFactory.getLogger(HelloProvider.class);
    private RpcRegistration&lt;HelloService&gt; helloService;
    @Override
    public void onSessionInitiated(ProviderContext session) {
        LOG.info("HelloProvider Session Initiated");
        helloService = session.addRpcImplementation(HelloService.class, new HelloWorldImpl());
    }
    @Override
    public void close() throws Exception {
        LOG.info("HelloProvider Closed");
        if (helloService != null) {
            helloService.close();
        }
    }
}</programlisting>

</listitem>
<listitem>
<simpara>Optionally, you can also build the Java classes which will register the new RPC. This is useful to test the edits you have made to HelloProvider.java and HelloWorldImpl.java.</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../../../../../../../
mvn clean install</programlisting>

</listitem>
<listitem>
<simpara>Return to the top level directory</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../</programlisting>

</listitem>
<listitem>
<simpara>Build the entire <emphasis>hello</emphasis> again, which will pickup the changes you have made and build them into your project:</simpara>
<programlisting language="shell" linenumbering="unnumbered">mvn clean install</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_execute_the_emphasis_hello_emphasis_project_for_the_first_time">
<title>Execute the <emphasis>hello</emphasis> project for the first time</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Run karaf</simpara>
<programlisting language="shell" linenumbering="unnumbered">cd ../karaf/target/assembly/bin
./karaf</programlisting>

</listitem>
<listitem>
<simpara>Wait for the project to load completely. Then view the log to see the loaded <emphasis>Hello</emphasis> Module:</simpara>
<programlisting language="shell" linenumbering="unnumbered">log:display | grep Hello</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_test_the_emphasis_hello_world_emphasis_rpc_via_rest">
<title>Test the <emphasis>hello-world</emphasis> RPC via REST</title>
<simpara>There are a lot of ways to test your RPC. Following are some examples.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Using the API Explorer through HTTP</simpara>
</listitem>
<listitem>
<simpara>Using a browser REST client</simpara>
</listitem>
</orderedlist>

<section xml:id="_using_the_api_explorer_through_http">
<title>Using the API Explorer through HTTP</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Navigate to <link xlink:href="http://localhost:8181/apidoc/explorer/index.html">apidoc UI</link> with your web browser.<?asciidoc-br?>
NOTE: In the URL mentioned above, Change <emphasis>localhost</emphasis> to the IP/Host name to reflect your development machine&#8217;s network address.</simpara>
</listitem>
<listitem>
<simpara>Select</simpara>
<programlisting language="shell" linenumbering="unnumbered">hello(2015-01-05)</programlisting>

</listitem>
<listitem>
<simpara>Select</simpara>
<screen>POST /operations/hello:hello-world</screen>

</listitem>
<listitem>
<simpara>Provide the required value.</simpara>
<programlisting language="json" linenumbering="unnumbered">{"hello:input": { "name":"Your Name"}}</programlisting>

</listitem>
<listitem>
<simpara>Click the button.</simpara>
</listitem>
<listitem>
<simpara>Enter the username and password, by default the credentials are admin/admin.</simpara>
</listitem>
<listitem>
<simpara>In the response body you should see.</simpara>
<programlisting language="json" linenumbering="unnumbered">{
  "output": {
    "greating": "Hello Your Name"
  }
}</programlisting>

</listitem>
</orderedlist>

</section>
<section xml:id="_using_a_browser_rest_client">
<title>Using a browser REST client</title>
<simpara>For example, use the following information in the Firefox plugin <emphasis>RESTClient</emphasis> [<link xlink:href="https://github.com/chao/RESTClient}">https://github.com/chao/RESTClient}</link><?asciidoc-br?></simpara>
<screen>POST: http://192.168.1.43:8181/restconf/operations/hello:hello-world</screen>

<simpara>Header:</simpara>
<screen>application/json</screen>

<simpara>Body:</simpara>
<programlisting language="json" linenumbering="unnumbered">{"input": {
    "name": "Andrew"
  }
}</programlisting>

</section>
</section>
<section xml:id="_troubleshooting_2">
<title>Troubleshooting</title>
<simpara>If you get a response code 501 while attempting to POST /operations/hello:hello-world, check the file: HelloProvider.java and make sure the helloService member is being set.
By not invoking "session.addRpcImplementation()" the REST API will be unable to map /operations/hello:hello-world url to HelloWorldImpl.</simpara>
</section>
</chapter>
</part>
<part xml:id="_project_specific_development_guides">
<title>Project-Specific Development Guides</title>
<chapter xml:id="_alto_developer_guide">
<title>ALTO Developer Guide</title>
<section xml:id="_overview_3">
<title>Overview</title>
<simpara>The topics of this guide are:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>How to add alto projects as dependencies;</simpara>
</listitem>
<listitem>
<simpara>How to put/fetch data from ALTO;</simpara>
</listitem>
<listitem>
<simpara>Basic API and DataType;</simpara>
</listitem>
<listitem>
<simpara>How to use customized service implementations.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_adding_alto_projects_as_dependencies">
<title>Adding ALTO Projects as Dependencies</title>
<simpara>Most ALTO packages can be added as dependencies in Maven projects by putting the
following code in the <emphasis>pom.xml</emphasis> file.</simpara>

<literallayout class="monospaced">&lt;dependency&gt;
    &lt;groupId&gt;org.opendaylight.alto&lt;/groupId&gt;
    &lt;artifactId&gt;${THE_NAME_OF_THE_PACKAGE_YOU_NEED}&lt;/artifactId&gt;
    &lt;version&gt;${ALTO_VERSION}&lt;/version&gt;
&lt;/dependency&gt;</literallayout>


<simpara>The current stable version for ALTO is <literal>0.2.0-Beryllium</literal>.</simpara>
</section>
<section xml:id="_putting_fetching_data_from_alto">
<title>Putting/Fetching data from ALTO</title>
<section xml:id="_using_restful_api">
<title>Using RESTful API</title>
<simpara>There are two kinds of RESTful APIs for ALTO: the one provided by
<literal>alto-northbound</literal> which follows the formats defined in
<link xlink:href="https://tools.ietf.org/html/rfc7285">RFC 7285</link>, and the one provided by
RESTCONF whose format is defined by the YANG model proposed in
<link xlink:href="https://tools.ietf.org/html/draft-shi-alto-yang-model-03">this draft</link>.</simpara>
<simpara>One way to get the URLs for the resources from <literal>alto-northbound</literal> is to visit
the IRD service first where there is a <literal>uri</literal> field for every entry. However, the
IRD service is not yet implemented so currently the developers have to construct
the URLs themselves. The base URL is <literal>/alto</literal> and below is a list
of the specific paths defined in <literal>alto-core/standard-northbound-route</literal>
using Jersey <literal>@Path</literal> annotation:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>/ird/{rid}</literal>: the path to access <emphasis>IRD</emphasis> services;</simpara>
</listitem>
<listitem>
<simpara><literal>/networkmap/{rid}[/{tag}]</literal>: the path to access <emphasis>Network Map</emphasis> and <emphasis>Filtered Network Map</emphasis> services;</simpara>
</listitem>
<listitem>
<simpara><literal>/costmap/{rid}[/{tag}[/{mode}/{metric}]]</literal>: the path to access <emphasis>Cost Map</emphasis> and <emphasis>Filtered Cost Map</emphasis> services;</simpara>
</listitem>
<listitem>
<simpara><literal>/endpointprop</literal>: the path to access <emphasis>Endpoint Property</emphasis> services;</simpara>
</listitem>
<listitem>
<simpara><literal>/endpointcost</literal>: the path to access <emphasis>Endpoint Cost</emphasis> services.</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>The segments in brackets are optional.</simpara>
</note>

<simpara>If you want to fetch the data using RESTCONF, it is highly recommended to take a
look at the <literal>apidoc</literal> page (<link xlink:href="http://{controller_ip}:8181/apidoc/explorer/index.html">http://{controller_ip}:8181/apidoc/explorer/index.html</link>)
after installing the <literal>odl-alto-release</literal> feature in karaf.</simpara>
<simpara>It is also worth pointing out that <literal>alto-northbound</literal> only supports <literal>GET</literal> and
<literal>POST</literal> operations so it is impossible to manipulate the data through its RESTful
APIs. To modify the data, use <literal>PUT</literal> and <literal>DELETE</literal> methods with RESTCONF.</simpara>
<note>
<simpara>The current implementation uses the <literal>configuration</literal> data store and that
enables the developers to modify the data directly through RESTCONF. In the future this
approach might be disabled in the core packages of ALTO but may still be
available as an extension.</simpara>
</note>

</section>
<section xml:id="_using_md_sal">
<title>Using MD-SAL</title>
<simpara>You can also fetch data from the datastore directly.</simpara>
<simpara>First you must get the access to the datastore by registering your module with
a data broker.</simpara>
<simpara>Then an <literal>InstanceIdentifier</literal> must be created. Here is an example of how to build
an <literal>InstanceIdentifier</literal> for a <emphasis>network map</emphasis>:</simpara>

<literallayout class="monospaced">import org.opendaylight...alto...Resources;
import org.opendaylight...alto...resources.NetworkMaps;
import org.opendaylight...alto...resources.network.maps.NetworkMap;
import org.opendaylight...alto...resources.network.maps.NetworkMapKey;
...
protected
InstanceIdentifier&lt;NetworkMap&gt; getNetworkMapIID(String resource_id) {
  ResourceId rid = ResourceId.getDefaultInstance(resource_id);
  NetworkMapKey key = new NetworkMapKey(rid);
  InstanceIdentifier&lt;NetworkMap&gt; iid = null;
  iid = InstanceIdentifier.builder(Resources.class)
                          .child(NetworkMaps.class)
                          .child(NetworkMap.class, key)
                          .build();
  return iid;
}
...</literallayout>


<simpara>With the <literal>InstanceIdentifier</literal> you can use <literal>ReadOnlyTransaction</literal>,
<literal>WriteTransaction</literal> and <literal>ReadWriteTransaction</literal> to manipulate the data
accordingly. The <literal>simple-impl</literal> package, which provides some of the AD-SAL APIs
mentioned above, is using this method to get data from the datastore and then
convert them into RFC7285-compatible objects.</simpara>
</section>
</section>
<section xml:id="_basic_api_and_datatype">
<title>Basic API and DataType</title>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>alto-basic-types: Defines basic types of ALTO protocol.</simpara>
</listitem>
<listitem>
<simpara>alto-service-model-api: Includes the YANG models for the five basic ALTO services defined in <link xlink:href="https://tools.ietf.org/html/rfc7285">RFC 7285</link>.</simpara>
</listitem>
<listitem>
<simpara>alto-resourcepool: Manages the meta data of each ALTO service, including capabilities and versions.</simpara>
</listitem>
<listitem>
<simpara>alto-northbound: Provides the root of RFC7285-compatible services at <link xlink:href="http://localhost:8080/alto">http://localhost:8080/alto</link>.</simpara>
</listitem>
<listitem>
<simpara>alto-northbound-route: Provides the root of the network map resources at <link xlink:href="http://localhost:8080/alto/networkmap/">http://localhost:8080/alto/networkmap/</link>.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_how_to_customize_service">
<title>How to customize service</title>
<section xml:id="_define_new_service_api">
<title>Define new service API</title>
<simpara>Add a new module in <literal>alto-core/standard-service-models</literal>. For example, we named our
service model module as <literal>model-example</literal>.</simpara>
</section>
<section xml:id="_implement_service_rpc">
<title>Implement service RPC</title>
<simpara>Add a new module in <literal>alto-basic</literal> to implement a service RPC in <literal>alto-core</literal>.</simpara>
<simpara>Currently <literal>alto-core/standard-service-models/model-base</literal> has defined a template of the service RPC.
You can define your own RPC using <literal>augment</literal> in YANG. Here is an example in <literal>alto-simpleird</literal>.</simpara>
<programlisting language="yang" linenumbering="unnumbered">    grouping "alto-ird-request" {
        container "ird-request" {
        }
    }
    grouping "alto-ird-response" {
        container "ird" {
            container "meta" {
            }
            list "resource" {
                key "resource-id";
                leaf "resource-id" {
                    type "alto-types:resource-id";
                }
            }
        }
    }
    augment "/base:query/base:input/base:request" {
        case "ird-request-data" {
            uses "alto-ird-request";
        }
    }
    augment "/base:query/base:output/base:response" {
        case "ird-response-data" {
            uses "alto-ird-response";
        }
    }</programlisting>

</section>
<section xml:id="_register_northbound_route">
<title>Register northbound route</title>
<simpara>If necessary, you can add a northbound route module in <literal>alto-core/standard-northbound-routes</literal>.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_bgp_developer_guide">
<title>BGP Developer Guide</title>
<section xml:id="_overview_4">
<title>Overview</title>
<simpara>This section provides an overview of <emphasis role="strong">feature odl-bgpcep-bgp-all</emphasis> . This
feature will install everything needed for BGP (Border Gateway Protocol)
from establishing the connection, storing the data in RIBs (Route Information
Base) and displaying data in network-topology overview.</simpara>
</section>
<section xml:id="_bgp_architecture">
<title>BGP Architecture</title>
<simpara>Each feature represents a module in the BGPCEP codebase. The following diagram
illustrates how the features are related.</simpara>
<figure>
<title>BGP Dependency Tree</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/bgp-dependency-tree.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>bgp dependency tree</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_key_apis_and_interfaces">
<title>Key APIs and Interfaces</title>
<section xml:id="_bgp_concepts">
<title>BGP concepts</title>
<simpara>This module contains the base BGP concepts contained in
<link xlink:href="http://tools.ietf.org/html/rfc4271">RFC4271</link>,
<link xlink:href="http://tools.ietf.org/html/rfc4760">RFC4760</link>,
<link xlink:href="http://tools.ietf.org/html/rfc4456">RFC4456</link>,
<link xlink:href="http://tools.ietf.org/html/rfc1997">RFC1997</link> and
<link xlink:href="http://tools.ietf.org/html/rfc4360">RFC4360</link>.</simpara>
<simpara>All the concepts are described in one yang model :
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/concepts/src/main/yang/bgp-types.yang;hb=refs/heads/stable/lithium">bgp-types.yang</link>
.</simpara>
<simpara>Outside generated classes, there is just one class
<emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/concepts/src/main/java/org/opendaylight/bgp/concepts/NextHopUtil.java;hb=refs/heads/stable/lithium">NextHopUtil</link></emphasis>
that contains methods for serializing and parsing NextHop.</simpara>
</section>
<section xml:id="_bgp_parser">
<title>BGP parser</title>
<simpara>Base BGP parser includes messages and attributes from
<link xlink:href="http://tools.ietf.org/html/rfc4271">RFC4271</link>,
<link xlink:href="http://tools.ietf.org/html/rfc4760">RFC4760</link>,
<link xlink:href="http://tools.ietf.org/html/rfc1997">RFC1997</link> and
<link xlink:href="http://tools.ietf.org/html/rfc4360">RFC4360</link>.</simpara>
<simpara><emphasis>API</emphasis> module defines BGP messages in YANG.</simpara>
<simpara><emphasis>IMPL</emphasis> module contains actual parsers and serializers for BGP messages
and
<emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/parser-impl/src/main/java/org/opendaylight/protocol/bgp/parser/impl/BGPActivator.java;hb=refs/heads/stable/lithium">Activator</link></emphasis>
class</simpara>
<simpara><emphasis>SPI</emphasis> module contains helper classes needed for registering parsers into
activators</simpara>
<section xml:id="_registration">
<title>Registration</title>
<simpara>As mentioned before, all parsers and serializers need to be registered
into the <emphasis>Extension provider</emphasis>. This <emphasis>Extension provider</emphasis> is configured in
initial configuration of the parser-spi module (<emphasis>31-bgp.xml</emphasis>).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
  &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:controller:bgp:parser:spi"&gt;prefix:bgp-extensions-impl&lt;/type&gt;
  &lt;name&gt;global-bgp-extensions&lt;/name&gt;
  &lt;extension&gt;
   &lt;type xmlns:bgpspi="urn:opendaylight:params:xml:ns:yang:controller:bgp:parser:spi"&gt;bgpspi:extension&lt;/type&gt;
   &lt;name&gt;base-bgp-parser&lt;/name&gt;
  &lt;/extension&gt;
  &lt;extension&gt;
   &lt;type xmlns:bgpspi="urn:opendaylight:params:xml:ns:yang:controller:bgp:parser:spi"&gt;bgpspi:extension&lt;/type&gt;
   &lt;name&gt;bgp-linkstate&lt;/name&gt;
  &lt;/extension&gt;
 &lt;/module&gt;</programlisting>

<itemizedlist>
<listitem>
<simpara><emphasis>base-bgp-parser</emphasis> - will register parsers and serializers
implemented in the bgp-parser-impl module</simpara>
</listitem>
<listitem>
<simpara><emphasis>bgp-linkstate</emphasis> - will register parsers and serializers
implemented in the bgp-linkstate module</simpara>
</listitem>
</itemizedlist>

<simpara>The bgp-linkstate module is a good example of a BGP parser extension.</simpara>
<simpara>The configuration of bgp-parser-spi specifies one implementation of
<emphasis>Extension provider</emphasis> that will take care of registering mentioned parser
extensions:
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/parser-spi/src/main/java/org/opendaylight/protocol/bgp/parser/spi/pojo/SimpleBGPExtensionProviderContext.java;hb=refs/heads/stable/lithium">SimpleBGPExtensionProviderContext</link>.
All registries are implemented in package
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=tree;f=bgp/parser-spi/src/main/java/org/opendaylight/protocol/bgp/parser/spi;hb=refs/heads/stable/lithium">bgp-parser-spi</link>.</simpara>
</section>
<section xml:id="_serializing">
<title>Serializing</title>
<simpara>The serializing of BGP elements is mostly done in the same way as in PCEP, the only
exception is the serialization of path attributes, that is described
here. Path attributes are different from any other BGP element, as
path attributes don&#8217;t implement one common interface, but this
interface contains getters for individual path attributes (this
structure is because update message can contain exactly one instance of
each path attribute). This means, that a given <emphasis>PathAttributes</emphasis> object,
you can only get to the specific type of the path attribute through
checking its presence. Therefore method <emphasis>serialize()</emphasis> in
<emphasis>AttributeRegistry</emphasis>, won&#8217;t look up the registered class, instead it will
go through the registrations and offer this object to the each
registered parser. This way the object will be passed also to
serializers unknown to module bgp-parser, for example to
LinkstateAttributeParser. RFC4271 recommends ordering path attributes,
hence the serializers are ordered in a list as they are registered in
the <emphasis>Activator</emphasis>. In other words, this is the only case, where
registration ordering matters.</simpara>
<figure>
<title>PathAttributesSerialization</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/PathAttributesSerialization.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>PathAttributesSerialization</phrase></textobject>
  </mediaobject>
</figure>

<simpara><emphasis>serialize()</emphasis> method in each Path Attribute parser contains check for
presence of its attribute in the PathAttributes object, which simply
returns, if the attribute is not there:</simpara>
<programlisting language="java" linenumbering="unnumbered"> if (pathAttributes.getAtomicAggregate() == null) {
     return;
 }
 //continue with serialization of Atomic Aggregate</programlisting>

</section>
</section>
</section>
<section xml:id="_bgp_rib">
<title>BGP RIB</title>
<simpara>The BGP RIB module can be divided into two semantic parts:
* BGP listener and speaker session handling
* RIB handling.</simpara>
<section xml:id="_session_handling">
<title>Session handling</title>
<simpara><emphasis>31-bgp.xml</emphasis> defines only bgp-dispatcher and the parser it should be
using (global-bgp-extensions).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
 &lt;type&gt;prefix:bgp-dispatcher-impl&lt;/type&gt;
 &lt;name&gt;global-bgp-dispatcher&lt;/name&gt;
 &lt;bgp-extensions&gt;
  &lt;type&gt;bgpspi:extensions&lt;/type&gt;
  &lt;name&gt;global-bgp-extensions&lt;/name&gt;
 &lt;/bgp-extensions&gt;
 &lt;boss-group&gt;
  &lt;type&gt;netty:netty-threadgroup&lt;/type&gt;
  &lt;name&gt;global-boss-group&lt;/name&gt;
 &lt;/boss-group&gt;
 &lt;worker-group&gt;
  &lt;type&gt;netty:netty-threadgroup&lt;/type&gt;
  &lt;name&gt;global-worker-group&lt;/name&gt;
 &lt;/worker-group&gt;
 &lt;/module&gt;</programlisting>

<simpara>For user configuration of BGP, check User Guide.</simpara>
</section>
<section xml:id="_synchronization">
<title>Synchronization</title>
<simpara>Synchronization is a phase, where upon connection, a BGP speaker sends all
available data about topology to its new client. After the whole
topology has been advertized, the synchronization is over. For the
listener, the synchronization is over when the RIB receives End-of-RIB
(EOR) messages. There is a special EOR message for each AFI (Address Family
Identifier).</simpara>
<itemizedlist>
<listitem>
<simpara>IPv4 EOR is an empty Update message</simpara>
</listitem>
<listitem>
<simpara>Ipv6 EOR is an Update message with empty MP_UNREACH attribute where
AFI and SAFI (Subsequent Address Family Identifier) are set to Ipv6.
OpenDaylight also supports EOR for IPv4 in this format</simpara>
</listitem>
<listitem>
<simpara>Linkstate EOR is an Update message with empty MP_UNREACH attribute
where AFI and SAFI are set to Linkstate</simpara>
</listitem>
</itemizedlist>

<simpara>For BGP connections, where both peers support graceful restart, the EORs
are sent by the BGP speaker and are redirected to RIB, where the specific
AFI/SAFI table is set to <emphasis>true</emphasis>. Without graceful restart, the
messages are generated by OpenDaylight itself and sent after second keepalive for
each AFI/SAFI. This is done in
<emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/BGPSynchronization.java;hb=refs/heads/stable/lithium">BGPSynchronization</link></emphasis></simpara>
<simpara><emphasis role="strong">Peers</emphasis></simpara>
<simpara><emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/BGPPeer.java;hb=refs/heads/stable/lithium">BGPPeer</link></emphasis>
has various meanings. If you configure BGP listener, <emphasis>BGPPeer</emphasis>
represents the BGP listener itself. If you are configuring BGP speaker,
you need to provide a list of peers, that are allowed to connect to this
speaker. Unknown peer represents, in this case, a peer that is allowed
to be refused. <emphasis>BGPPeer</emphasis> represents in this case peer, that is supposed
to connect to your speaker. <emphasis>BGPPeer</emphasis> is stored in <emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/StrictBGPPeerRegistry.java;hb=refs/heads/stable/lithium">BGPPeerRegistry</link></emphasis>.
This registry controls the number of sessions. Our strict implementation
limits sessions to one per peer.</simpara>
<simpara><emphasis><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/ApplicationPeer.java;hb=refs/heads/stable/lithium">ApplicationPeer</link></emphasis>
is a special case of peer, that has it&#8217;s own RIB. This RIB is populated
from RESTCONF. The RIB is synchronized with default BGP RIB. Incoming
routes to the default RIB are treated in the same way as they were from a
BGP peer (speaker or listener) in the network.</simpara>
</section>
<section xml:id="_rib_handling">
<title>RIB handling</title>
<simpara>RIB (Route Information Base) is defined as a concept in
<link xlink:href="http://tools.ietf.org/html/rfc4271#section-3.2">RFC4271</link>. RFC does not
define how it should be implemented. In our implementation,
the routes are stored in MD-SALs data-store. There are four supported
routes - <emphasis>Ipv4Routes</emphasis>, <emphasis>Ipv6Routes</emphasis>, <emphasis>LinkstateRoutes</emphasis> and
<emphasis>FlowspecRoutes</emphasis>.</simpara>
<simpara>Each route type needs to provide a
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-spi/src/main/java/org/opendaylight/protocol/bgp/rib/spi/RIBSupport.java;hb=refs/heads/stable/lithium">RIBSupport.java</link>
implementation. <emphasis>RIBSupport</emphasis> tells RIB how to parse binding-aware data
(BGP Update message) to binding-independent (datastore format).</simpara>
<simpara>Following picture describes the data flow from BGP message that is sent
to <emphasis>BGPPeer</emphasis> to datastore and various types of RIB.</simpara>
<figure>
<title>RIB</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/RIB.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>RIB</phrase></textobject>
  </mediaobject>
</figure>

<simpara><emphasis role="strong"><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/AdjRibInWriter.java;hb=refs/heads/stable/lithium">AdjRibInWriter</link></emphasis>
- represents the first step in putting data to datastore. This writer is
notified whenever a peer receives an Update message. The message is
transformed into binding-independent format and pushed into datastore to
<emphasis>adj-rib-in</emphasis>. This RIB is associated with a peer.</simpara>
<simpara><emphasis role="strong"><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/EffectiveRibInWriter.java;hb=refs/heads/stable/lithium">EffectiveRibInWriter</link></emphasis>
- this writer is notified whenever <emphasis>adj-rib-in</emphasis> is updated. It applies
all configured import policies to the routes and stores them in
<emphasis>effective-rib-in</emphasis>. This RIB is also associated with a peer.</simpara>
<simpara><emphasis role="strong"><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/LocRibWriter.java;hb=refs/heads/stable/lithium">LocRibWriter</link></emphasis>
- this writer is notified whenever <emphasis role="strong">any</emphasis> <emphasis>effective-rib-in</emphasis> is updated
(in any peer). Performs best path selection filtering and stores the
routes in <emphasis>loc-rib</emphasis>. It also determines which routes need to be
advertised and fills in <emphasis>adj-rib-out</emphasis> that is per peer as well.</simpara>
<simpara><emphasis role="strong"><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/rib-impl/src/main/java/org/opendaylight/protocol/bgp/rib/impl/AdjRibOutListener.java;h=a14fd54a29ea613b381a36248f67491d968963b8;hb=refs/heads/stable/lithium">AdjRibOutListener</link></emphasis>
- listens for changes in <emphasis>adj-rib-out</emphasis>, transforms the routes into
BGPUpdate messages and sends them to its associated peer.</simpara>
</section>
</section>
<section xml:id="_bgp_inet">
<title>BGP inet</title>
<simpara>This module contains only one YANG model
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/inet/src/main/yang/bgp-inet.yang;hb=refs/heads/stable/lithium">bgp-inet.yang</link>
that summarizes the ipv4 and ipv6 extensions to RIB routes and BGP
messages.</simpara>
</section>
<section xml:id="_bgp_flowspec">
<title>BGP flowspec</title>
<simpara>BGP flowspec is a module that implements
<link xlink:href="http://tools.ietf.org/html/rfc5575">RFC5575</link>. The RFC defines an
extension to BGP in form of a new subsequent address family, NLRI and
extended communities. All of those are defined in the
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/flowspec/src/main/yang/bgp-flowspec.yang;hb=refs/heads/stable/lithium">bgp-flowspec.yang</link>
model. In addition to generated sources, the module contains parsers for
newly defined elements and RIBSupport for flowspec-routes. The route key of
flowspec routes is a string representing human-readable flowspec
request.</simpara>
</section>
<section xml:id="_bgp_linkstate">
<title>BGP linkstate</title>
<simpara>BGP linkstate is a module that implements
<link xlink:href="http://tools.ietf.org/html/draft-ietf-idr-ls-distribution-04">draft-ietf-idr-ls-distribution</link>
version 04. The draft defines an extension to BGP in form of a new
address family, subsequent address family, NLRI and path attribute. All
of those are defined in the
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/linkstate/src/main/yang/bgp-linkstate.yang;hb=refs/heads/stable/lithium">bgp-linkstate.yang</link>
model. In addition to generated sources, the module contains
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/linkstate/src/main/java/org/opendaylight/protocol/bgp/linkstate/attribute/LinkstateAttributeParser.java;hb=refs/heads/stable/lithium">LinkstateAttributeParser</link>,
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=bgp/linkstate/src/main/java/org/opendaylight/protocol/bgp/linkstate/nlri/LinkstateNlriParser.java;hb=refs/heads/stable/lithium">LinkstateNlriParser</link>,
activators for both, parser and RIB, and RIBSupport handler for
linkstate address family. As each route needs a key, in case of
linkstate, the route key is defined as a binary string, containing all
the nlri serialized to byte format.</simpara>
</section>
<section xml:id="_bgp_topology_provider">
<title>BGP topology provider</title>
<simpara>BGP data besides RIB, is stored in network-topology view. The
format of how the data is displayed there conforms to
<link xlink:href="https://tools.ietf.org/html/draft-clemm-netmod-yang-network-topo-01">draft-clemm-netmod-yang-network-topo</link>.</simpara>
</section>
<section xml:id="_api_reference_documentation">
<title>API Reference Documentation</title>
<simpara>Javadocs are generated while creating mvn:site
and they are located in target/ directory in each module.</simpara>
</section>
</chapter>
<chapter xml:id="_bgp_monitoring_protocol_developer_guide">
<title>BGP Monitoring Protocol Developer Guide</title>
<section xml:id="_overview_5">
<title>Overview</title>
<simpara>This section provides an overview of <emphasis role="strong">feature odl-bgpcep-bmp</emphasis>. This
feature will install everything needed for BMP (BGP Monitoring Protocol)
including establishing the connection, processing messages, storing
information about monitored routers, peers and their Adj-RIB-In
(unprocessed routing information) and Post-Policy Adj-RIB-In
and displaying data in BGP RIBs overview.
The OpenDaylight BMP plugin plays the role of a monitoring station.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_2">
<title>Key APIs and Interfaces</title>
<section xml:id="_session_handling_2">
<title>Session handling</title>
<simpara><emphasis>32-bmp.xml</emphasis> defines only bmp-dispatcher the parser should be
using (global-bmp-extensions).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
  &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:controller:bmp:impl"&gt;prefix:bmp-dispatcher-impl&lt;/type&gt;
  &lt;name&gt;global-bmp-dispatcher&lt;/name&gt;
   &lt;bmp-extensions&gt;
    &lt;type xmlns:bmp-spi="urn:opendaylight:params:xml:ns:yang:controller:bmp:spi"&gt;bmp-spi:extensions&lt;/type&gt;
    &lt;name&gt;global-bmp-extensions&lt;/name&gt;
   &lt;/bmp-extensions&gt;
   &lt;boss-group&gt;
    &lt;type xmlns:netty="urn:opendaylight:params:xml:ns:yang:controller:netty"&gt;netty:netty-threadgroup&lt;/type&gt;
    &lt;name&gt;global-boss-group&lt;/name&gt;
   &lt;/boss-group&gt;
   &lt;worker-group&gt;
    &lt;type xmlns:netty="urn:opendaylight:params:xml:ns:yang:controller:netty"&gt;netty:netty-threadgroup&lt;/type&gt;
    &lt;name&gt;global-worker-group&lt;/name&gt;
  &lt;/worker-group&gt;
 &lt;/module&gt;</programlisting>

<simpara>For user configuration of BMP, check User Guide.</simpara>
</section>
<section xml:id="_parser">
<title>Parser</title>
<simpara>The base BMP parser includes messages and attributes from
<link xlink:href="https://tools.ietf.org/html/draft-ietf-grow-bmp-15">https://tools.ietf.org/html/draft-ietf-grow-bmp-15</link></simpara>
</section>
<section xml:id="_registration_2">
<title>Registration</title>
<simpara>All parsers and serializers need to be registered
into <emphasis>Extension provider</emphasis>. This <emphasis>Extension provider</emphasis> is configured in
initial configuration of the parser (<emphasis>32-bmp.xml</emphasis>).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
  &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:controller:bmp:spi"&gt;prefix:bmp-extensions-impl&lt;/type&gt;
  &lt;name&gt;global-bmp-extensions&lt;/name&gt;
  &lt;extension&gt;
   &lt;type xmlns:bmp-spi="urn:opendaylight:params:xml:ns:yang:controller:bmp:spi"&gt;bmp-spi:extension&lt;/type&gt;
   &lt;name&gt;bmp-parser-base&lt;/name&gt;
  &lt;/extension&gt;
 &lt;/module&gt;</programlisting>

<itemizedlist>
<listitem>
<simpara><emphasis>bmp-parser-base</emphasis> - will register parsers and serializers
implemented in bmp-impl module</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_parsing">
<title>Parsing</title>
<simpara>Parsing of BMP elements is mostly done equally to BGP. Some of the BMP messages includes wrapped
BGP messages.</simpara>
</section>
<section xml:id="_bmp_monitoring_station">
<title>BMP Monitoring Station</title>
<simpara>The BMP application (Monitoring Station) serves as message processor incoming from monitored routers.
The processed message is transformed and relevant information is stored. Route information is stored in a BGP
RIB data structure.</simpara>
<simpara>BMP data is displayed only through one URL that is accessible from the base BMP URL:</simpara>
<simpara><emphasis><link xlink:href="http://&lt;controllerIP&gt;:8181/restconf/operational/bmp-monitor:bmp-monitor">http://&lt;controllerIP&gt;:8181/restconf/operational/bmp-monitor:bmp-monitor</link></emphasis></simpara>
<simpara>Each Monitor station will be displayed and it may contains multiple monitored routers and peers within:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;bmp-monitor xmlns="urn:opendaylight:params:xml:ns:yang:bmp-monitor"&gt;
 &lt;monitor&gt;
 &lt;monitor-id&gt;example-bmp-monitor&lt;/monitor-id&gt;
  &lt;router&gt;
  &lt;router-id&gt;127.0.0.11&lt;/router-id&gt;
   &lt;status&gt;up&lt;/status&gt;
   &lt;peer&gt;
    &lt;peer-id&gt;20.20.20.20&lt;/peer-id&gt;
    &lt;as&gt;72&lt;/as&gt;
    &lt;type&gt;global&lt;/type&gt;
    &lt;peer-session&gt;
     &lt;remote-port&gt;5000&lt;/remote-port&gt;
     &lt;timestamp-sec&gt;5&lt;/timestamp-sec&gt;
     &lt;status&gt;up&lt;/status&gt;
     &lt;local-address&gt;10.10.10.10&lt;/local-address&gt;
     &lt;local-port&gt;220&lt;/local-port&gt;
    &lt;/peer-session&gt;
    &lt;pre-policy-rib&gt;
     &lt;tables&gt;
      &lt;afi xmlns:x="urn:opendaylight:params:xml:ns:yang:bgp-types"&gt;x:ipv4-address-family&lt;/afi&gt;
      &lt;safi xmlns:x="urn:opendaylight:params:xml:ns:yang:bgp-types"&gt;x:unicast-subsequent-address-family&lt;/safi&gt;
      &lt;ipv4-routes xmlns="urn:opendaylight:params:xml:ns:yang:bgp-inet"&gt;
       &lt;ipv4-route&gt;
        &lt;prefix&gt;10.10.10.0/24&lt;/prefix&gt;
         &lt;attributes&gt;
          ...
         &lt;/attributes&gt;
       &lt;/ipv4-route&gt;
      &lt;/ipv4-routes&gt;
      &lt;attributes&gt;
       &lt;uptodate&gt;true&lt;/uptodate&gt;
      &lt;/attributes&gt;
     &lt;/tables&gt;
    &lt;/pre-policy-rib&gt;
    &lt;address&gt;10.10.10.10&lt;/address&gt;
    &lt;post-policy-rib&gt;
     ...
    &lt;/post-policy-rib&gt;
    &lt;bgp-id&gt;20.20.20.20&lt;/bgp-id&gt;
    &lt;stats&gt;
     &lt;timestamp-sec&gt;5&lt;/timestamp-sec&gt;
     &lt;invalidated-cluster-list-loop&gt;53&lt;/invalidated-cluster-list-loop&gt;
     &lt;duplicate-prefix-advertisements&gt;16&lt;/duplicate-prefix-advertisements&gt;
     &lt;loc-rib-routes&gt;100&lt;/loc-rib-routes&gt;
     &lt;duplicate-withdraws&gt;11&lt;/duplicate-withdraws&gt;
     &lt;invalidated-as-confed-loop&gt;55&lt;/invalidated-as-confed-loop&gt;
     &lt;adj-ribs-in-routes&gt;10&lt;/adj-ribs-in-routes&gt;
     &lt;invalidated-as-path-loop&gt;66&lt;/invalidated-as-path-loop&gt;
     &lt;invalidated-originator-id&gt;70&lt;/invalidated-originator-id&gt;
     &lt;rejected-prefixes&gt;8&lt;/rejected-prefixes&gt;
    &lt;/stats&gt;
   &lt;/peer&gt;
   &lt;name&gt;name&lt;/name&gt;
   &lt;description&gt;description&lt;/description&gt;
   &lt;info&gt;some info;&lt;/info&gt;
  &lt;/router&gt;
 &lt;/monitor&gt;
&lt;/bmp-monitor&gt;
&lt;/source&gt;</programlisting>

</section>
</section>
<section xml:id="_api_reference_documentation_2">
<title>API Reference Documentation</title>
<simpara>Javadocs are generated while creating mvn:site
and they are located in target/ directory in each module.</simpara>
</section>
</chapter>
<chapter xml:id="_capwap_developer_guide">
<title>CAPWAP Developer Guide</title>
<section xml:id="_overview_6">
<title>Overview</title>
<simpara>The Control And Provisioning of Wireless Access Points (CAPWAP) plugin project aims to
provide new southbound interface for controller to be able to monitor and manage
CAPWAP compliant wireless termination point (WTP) network devices. The CAPWAP
feature will provide REST based northbound APIs.</simpara>
</section>
<section xml:id="_capwap_architecture">
<title>CAPWAP Architecture</title>
<simpara>The CAPWAP feature is implemented as an MD-SAL based provider module, which
helps discover WTP devices and update their states in the MD-SAL operational datastore.</simpara>
</section>
<section xml:id="_capwap_apis_and_interfaces">
<title>CAPWAP APIs and Interfaces</title>
<simpara>This section describes the APIs for interacting with the CAPWAP plugin.</simpara>
<section xml:id="_discovered_wtps">
<title>Discovered WTPs</title>
<simpara>The CAPWAP project maintains list of discovered CAPWAP WTPs that is YANG-based in MD-SAL.
These models are available via RESTCONF.</simpara>
<itemizedlist>
<listitem>
<simpara>Name: Discovered-WTPs</simpara>
</listitem>
<listitem>
<simpara>URL: <link xlink:href="http://${ipaddress}:8181/restconf/operational/capwap-impl:capwap-ac-root/">http://${ipaddress}:8181/restconf/operational/capwap-impl:capwap-ac-root/</link></simpara>
</listitem>
<listitem>
<simpara>Description: Displays list of discovered WTPs and their basic attributes</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_api_reference_documentation_3">
<title>API Reference Documentation</title>
<simpara>Go to <link xlink:href="http://${ipaddress}:8181/apidoc/explorer/index.html">http://${ipaddress}:8181/apidoc/explorer/index.html</link>, sign in, and expand the
capwap-impl panel.  From there, users can execute various API calls to test their
CAPWAP deployment.</simpara>
</section>
</chapter>
<chapter xml:id="_cardinal_opendaylight_monitoring_as_a_service">
<title>Cardinal: OpenDaylight Monitoring as a Service</title>
<section xml:id="_overview_7">
<title>Overview</title>
<simpara>Cardinal (OpenDaylight Monitoring as a Service) enables OpenDaylight and the underlying software defined network to be remotely monitored by deployed Network Management Systems (NMS) or Analytics suite. In the Boron release, Cardinal adds:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>OpenDaylight MIB.</simpara>
</listitem>
<listitem>
<simpara>Enable ODL diagnostics/monitoring to be exposed across SNMP (v2c, v3) and REST north-bound.</simpara>
</listitem>
<listitem>
<simpara>Extend ODL System health, Karaf parameter and feature info, ODL plugin scalability and network parameters.</simpara>
</listitem>
<listitem>
<simpara>Support autonomous notifications (SNMP Traps).</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_cardinal_architecture">
<title>Cardinal Architecture</title>
<simpara>The Cardinal architecture can be found at the below link:</simpara>
<simpara><link xlink:href="https://wiki.opendaylight.org/images/8/89/Cardinal-ODL_Monitoring_as_a_Service_V2.pdf">https://wiki.opendaylight.org/images/8/89/Cardinal-ODL_Monitoring_as_a_Service_V2.pdf</link></simpara>
</section>
<section xml:id="_key_apis_and_interfaces_3">
<title>Key APIs and Interfaces</title>
<simpara>There are 2 main APIs for requesting snmpget request of the Karaf info and System info.
To expose these APIs, it assumes that you already have the <literal>odl-cardinal</literal> and <literal>odl-restconf</literal> features installed. You can do that by entering the following at the Karaf console:</simpara>

<literallayout class="monospaced">feature:install odl-cardinal
feature:install odl-restconf-all</literallayout>


<section xml:id="_system_info_apis">
<title>System Info APIs</title>
<simpara>Open the REST interface and using the basic authentication, execute REST APIs for system info as:</simpara>

<literallayout class="monospaced">http://localhost:8181/restconf/operational/cardinal:CardinalSystemInfo/</literallayout>


<simpara>You should get the response code of the same as 200 OK with the following output as:</simpara>

<literallayout class="monospaced">{
  "CardinalSystemInfo": {
    "odlSystemMemUsage": " 9",
    "odlSystemSysInfo": " OpenDaylight Node Information",
    "odlSystemOdlUptime": " 00:29",
    "odlSystemCpuUsage": " 271",
    "odlSystemHostAddress": " Address of the Host should come up"
  }
}</literallayout>


</section>
<section xml:id="_karaf_info_apis">
<title>Karaf Info APIs</title>
<simpara>Open the REST interface and using the basic authentication, execute REST APIs for system info as:</simpara>

<literallayout class="monospaced">http://localhost:8181/restconf/operational/cardinal-karaf:CardinalKarafInfo/</literallayout>


<simpara>You should get the response code of the same as 200 OK with the following output as:</simpara>

<literallayout class="monospaced">  {
  "CardinalKarafInfo": {
    "odlKarafBundleListActive1": " org.ops4j.pax.url.mvn_2.4.5 [1]",
    "odlKarafBundleListActive2": " org.ops4j.pax.url.wrap_2.4.5 [2]",
    "odlKarafBundleListActive3": " org.ops4j.pax.logging.pax-logging-api_1.8.4 [3]",
    "odlKarafBundleListActive4": " org.ops4j.pax.logging.pax-logging-service_1.8.4 [4]",
    "odlKarafBundleListActive5": " org.apache.karaf.service.guard_3.0.6 [5]",
    "odlKarafBundleListActive6": " org.apache.felix.configadmin_1.8.4 [6]",
    "odlKarafBundleListActive7": " org.apache.felix.fileinstall_3.5.2 [7]",
    "odlKarafBundleListActive8": " org.objectweb.asm.all_5.0.3 [8]",
    "odlKarafBundleListActive9": " org.apache.aries.util_1.1.1 [9]",
    "odlKarafBundleListActive10": " org.apache.aries.proxy.api_1.0.1 [10]",
    "odlKarafBundleListInstalled1": " org.ops4j.pax.url.mvn_2.4.5 [1]",
    "odlKarafBundleListInstalled2": " org.ops4j.pax.url.wrap_2.4.5 [2]",
    "odlKarafBundleListInstalled3": " org.ops4j.pax.logging.pax-logging-api_1.8.4 [3]",
    "odlKarafBundleListInstalled4": " org.ops4j.pax.logging.pax-logging-service_1.8.4 [4]",
    "odlKarafBundleListInstalled5": " org.apache.karaf.service.guard_3.0.6 [5]",
    "odlKarafFeatureListInstalled1": " config",
    "odlKarafFeatureListInstalled2": " region",
    "odlKarafFeatureListInstalled3": " package",
    "odlKarafFeatureListInstalled4": " http",
    "odlKarafFeatureListInstalled5": " war",
    "odlKarafFeatureListInstalled6": " kar",
    "odlKarafFeatureListInstalled7": " ssh",
    "odlKarafFeatureListInstalled8": " management",
    "odlKarafFeatureListInstalled9": " odl-netty",
    "odlKarafFeatureListInstalled10": " odl-lmax",
    "odlKarafBundleListResolved1": " org.ops4j.pax.url.mvn_2.4.5 [1]",
    "odlKarafBundleListResolved2": " org.ops4j.pax.url.wrap_2.4.5 [2]",
    "odlKarafBundleListResolved3": " org.ops4j.pax.logging.pax-logging-api_1.8.4 [3]",
    "odlKarafBundleListResolved4": " org.ops4j.pax.logging.pax-logging-service_1.8.4 [4]",
    "odlKarafBundleListResolved5": " org.apache.karaf.service.guard_3.0.6 [5]",
    "odlKarafFeatureListUnInstalled1": " aries-annotation",
    "odlKarafFeatureListUnInstalled2": " wrapper",
    "odlKarafFeatureListUnInstalled3": " service-wrapper",
    "odlKarafFeatureListUnInstalled4": " obr",
    "odlKarafFeatureListUnInstalled5": " http-whiteboard",
    "odlKarafFeatureListUnInstalled6": " jetty",
    "odlKarafFeatureListUnInstalled7": " webconsole",
    "odlKarafFeatureListUnInstalled8": " scheduler",
    "odlKarafFeatureListUnInstalled9": " eventadmin",
    "odlKarafFeatureListUnInstalled10": " jasypt-encryption"
  }
}</literallayout>


</section>
</section>
</chapter>
<chapter xml:id="_controller">
<title>Controller</title>
<section xml:id="_overview_8">
<title>Overview</title>
<simpara>OpenDaylight Controller is Java-based, model-driven controller using YANG
as its modeling language for various aspects of the system and applications
and with its components serves as a base platform for other OpenDaylight
applications.</simpara>
<simpara>The OpenDaylight Controller relies on the following technologies:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">OSGI</emphasis> - This framework is the back-end of OpenDaylight as it allows
dynamically loading of bundles and packages JAR files, and binding bundles
together for exchanging information.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Karaf</emphasis> - Application container built on top of OSGI, which simplifies
operational aspects of packaging and installing applications.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">YANG</emphasis> - a data modeling language used to model configuration and
state data manipulated by the applications, remote procedure calls, and
notifications.</simpara>
</listitem>
</itemizedlist>

<simpara>The OpenDaylight Controller provides following model-driven subsystems as a
foundation for Java applications:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong"><link linkend="_config_subsystem">Config Subsystem</link></emphasis> - an activation, dependency-injection
and configuration framework, which allows two-phase commits of configuration
and dependency-injection, and allows for run-time rewiring.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong"><link linkend="_md_sal_overview">MD-SAL</link></emphasis> - messaging and data storage functionality for data,
notifications and RPCs modeled by application developers. MD-SAL uses YANG
as the modeling for both interface and data definitions, and provides
a messaging and data-centric runtime for such services based on YANG modeling.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">MD-SAL Clustering</emphasis> - enables cluster support for core MD-SAL functionality
and provides location-transparent accesss to YANG-modeled data.</simpara>
</listitem>
</itemizedlist>

<simpara>The OpenDaylight Controller supports external access to applications and data using
following model-driven protocols:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">NETCONF</emphasis> - XML-based RPC protocol, which provides abilities for client to
invoke YANG-modeled RPCs, receive notifications and to read, modify and
manipulate YANG modeled data.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">RESTCONF</emphasis> - HTTP-based protocol, which provides REST-like APIs to manipulate
YANG modeled data and invoke YANG modeled RPCs, using XML or JSON as payload
format.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_md_sal_overview">
<title>MD-SAL Overview</title>
<simpara>The Model-Driven Service Adaptation Layer (MD-SAL) is message-bus inspired
extensible middleware component that provides messaging and data storage
functionality based on data and interface models defined by application developers
(i.e. user-defined models).</simpara>
<simpara>The MD-SAL:</simpara>
<itemizedlist>
<listitem>
<simpara>Defines a <emphasis role="strong">common-layer, concepts, data model building blocks and messaging
patterns</emphasis> and provides infrastructure / framework for applications and
inter-application communication.</simpara>
</listitem>
</itemizedlist>

<itemizedlist>
<listitem>
<simpara>Provide common support for user-defined transport and payload formats, including
payload serialization and adaptation (e.g. binary, XML or JSON).</simpara>
</listitem>
</itemizedlist>

<simpara>The MD-SAL uses <emphasis role="strong">YANG</emphasis> as the modeling language for both interface and data
definitions, and provides a messaging and data-centric runtime for such services
based on YANG modeling.</simpara>
<simpara>The MD-SAL provides two different API types (flavours):<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">MD-SAL Binding:</emphasis> MD-SAL APIs which extensively uses APIs and classes generated
from YANG models, which provides compile-time safety.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">MD-SAL DOM:</emphasis> (Document Object Model) APIs which uses DOM-like
representation of data, which makes them more powerful, but provides less
compile-time safety.</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>Model-driven nature of the MD-SAL and <emphasis role="strong">DOM</emphasis>-based APIs allows for
behind-the-scene API and payload type mediation and transformation
to facilitate seamless communication between applications - this enables
for other components and applications to provide connectors / expose different
set of APIs and derive most of its functionality purely from models, which
all existing code can benefit from without modification.
For example <emphasis role="strong">RESTCONF Connector</emphasis> is an application built on top of MD-SAL
and exposes YANG-modeled application APIs transparently via HTTP and adds support
for XML and JSON payload type.</simpara>
</note>

<section xml:id="_basic_concepts">
<title>Basic concepts</title>
<simpara>Basic concepts are building blocks which are used by applications, and from
which MD-SAL uses to define messaging patterns and to provide services and
behavior based on developer-supplied YANG models.</simpara>
<variablelist>
<varlistentry>
<term>Data Tree</term>
<listitem>
<simpara>All state-related data are modeled and represented as data tree,
with possibility to address any element / subtree</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Operational Data Tree</emphasis> - Reported state of the system, published by the
providers using MD-SAL. Represents a feedback loop for applications
to observe state of the network / system.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Configuration Data Tree</emphasis> - Intended state of the system or network,
populated by consumers, which expresses their intention.</simpara>
</listitem>
</itemizedlist>

</listitem>
</varlistentry>
<varlistentry>
<term>Instance Identifier</term>
<listitem>
<simpara>Unique identifier of node / subtree in data tree, which provides unambiguous
information, how to reference and retrieve node / subtree from conceptual
data trees.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Notification</term>
<listitem>
<simpara>Asynchronous transient event which may be consumed by subscribers and they may
act upon it</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>RPC</term>
<listitem>
<simpara>asynchronous request-reply message pair, when request is triggered
by consumer, send to the provider, which in future replies with reply message.</simpara>
<note>
<simpara>In MD-SAL terminology, the term <emphasis>RPC</emphasis> is used to define the input and
output for a procedure (function) that is to be provided by a provider,
and mediated by the MD-SAL, that means it may not result in remote call.</simpara>
</note>

</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_messaging_patterns">
<title>Messaging Patterns</title>
<simpara>MD-SAL provides several messaging patterns using broker derived from
basic concepts, which are intended to transfer YANG modeled data between
applications to provide data-centric integration between applications instead
of API-centric integration.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Unicast communication</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Remote Procedure Calls</emphasis> - unicast between consumer and provider, where
consumer sends <emphasis role="strong">request</emphasis> message to provider, which asynchronously responds
with <emphasis role="strong">reply</emphasis> message</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">Publish / Subscribe</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Notifications</emphasis> - multicast transient message which is published by provider
and is delivered to subscribers</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Data Change Events</emphasis> - multicast asynchronous event, which is sent by data
broker if there is change in conceptual data tree, and is delivered to subscribers</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">Transactional access to Data Tree</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Transactional <emphasis role="strong">reads</emphasis> from conceptual <emphasis role="strong">data tree</emphasis> - read-only transactions with
isolation from other running transactions.</simpara>
</listitem>
<listitem>
<simpara>Transactional <emphasis role="strong">modification</emphasis> to conceptual <emphasis role="strong">data tree</emphasis> - write transactions with
isolation from other running transactions.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Transaction chaining</emphasis></simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_md_sal_data_transactions">
<title>MD-SAL Data Transactions</title>
<simpara>MD-SAL <emphasis role="strong">Data Broker</emphasis> provides transactional access to conceptual <emphasis role="strong">data trees</emphasis>
representing configuration and operational state.</simpara>
<note>
<simpara><emphasis role="strong">Data tree</emphasis> usually represents state of the modeled data, usually this
      is state of controller, applications and also external systems (network
      devices).</simpara>
</note>

<simpara><emphasis role="strong">Transactions</emphasis> provide <emphasis role="strong"><link linkend="_transaction_isolation">stable and isolated view</link></emphasis>
from other currently running transactions. The state of running transaction and
underlying data tree is not affected by other concurrently running transactions.</simpara>
<variablelist>
<title>Transaction Types</title>
<varlistentry>
<term>Write-Only</term>
<listitem>
<simpara>Transaction provides only modification capabilities, but does not provide
read capabilities. Write-only transaction is allocated using
<literal>newWriteOnlyTransaction()</literal>.</simpara>
<note>
<simpara>This allows less state tracking for
      write-only transactions and allows MD-SAL Clustering to optimize
      internal representation of transaction in cluster.</simpara>
</note>

</listitem>
</varlistentry>
<varlistentry>
<term>Read-Write</term>
<listitem>
<simpara>Transaction provides both read and write capabilities. It is allocated using
<literal>newReadWriteTransaction()</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Read-Only</term>
<listitem>
<simpara>Transaction provides stable read-only view based on current data tree.
Read-only view is not affected by any subsequent write transactions.
Read-only transaction is allocated using <literal>newReadOnlyTransaction()</literal>.</simpara>
<note>
<simpara>If an application needs to observe changes itself in data tree, it should use
<emphasis role="strong">data tree listeners</emphasis> instead of read-only transactions and polling data tree.</simpara>
</note>

</listitem>
</varlistentry>
</variablelist>

<simpara>Transactions may be allocated using the <emphasis role="strong">data broker</emphasis> itself or using
<emphasis role="strong">transaction chain</emphasis>. In the case of <emphasis role="strong">transaction chain</emphasis>, the new allocated transaction
is not based on current state of data tree, but rather on state introduced by
previous transaction from the same chain, even if the commit for previous transaction
has not yet occurred (but transaction was submitted).</simpara>
<section xml:id="_write_only_read_write_transaction">
<title>Write-Only &amp; Read-Write Transaction</title>
<simpara>Write-Only and Read-Write transactions provide modification capabilities for
the conceptual data trees.</simpara>
<orderedlist numeration="arabic">
<title>Usual workflow for data tree modifications</title>
<listitem>
<simpara>application allocates new transactions using <literal>newWriteOnlyTransaction()</literal>
or <literal>newReadWriteTransaction()</literal>.</simpara>
</listitem>
<listitem>
<simpara>application <link linkend="_modification_of_data_tree">modifies data tree</link> using <literal>put</literal>,
<literal>merge</literal> and/or <literal>delete</literal>.</simpara>
</listitem>
<listitem>
<simpara>application finishes transaction using <link linkend="_submitting_transaction"><literal>submit()</literal></link>,
which seals transaction and submits it to be processed.</simpara>
</listitem>
<listitem>
<simpara>application observes the result of the transaction commit using either blocking
or asynchronous calls.</simpara>
</listitem>
</orderedlist>

<simpara>The <emphasis role="strong">initial state</emphasis> of the write transaction is a <emphasis role="strong">stable snapshot</emphasis> of the current
data tree state captured when transaction was created and it&#8217;s state and
underlying data tree are not affected by other concurrently running transactions.</simpara>
<simpara>Write transactions are <emphasis role="strong">isolated</emphasis> from other concurrent write transactions. All
<emphasis role="strong"><link linkend="_transaction_local_state">writes are local</link></emphasis> to the transaction and
represents only a <emphasis role="strong">proposal of state change</emphasis> for data tree and <emphasis role="strong">are not visible</emphasis>
to any other concurrently running transactions (including read-only transactions).</simpara>
<simpara>The transaction <emphasis role="strong"><link linkend="_commit_failure_scenarios">commit may fail</link></emphasis> due to failing
verification of data or concurrent transaction modifying and affected data
in an incompatible way.</simpara>
<section xml:id="_modification_of_data_tree">
<title>Modification of Data Tree</title>
<simpara>Write-only and read-write transaction provides following methods to modify
data tree:</simpara>
<variablelist>
<varlistentry>
<term>put</term>
<listitem>
<programlisting language="java" linenumbering="unnumbered">&lt;T&gt; void put(LogicalDatastoreType store, InstanceIdentifier&lt;T&gt; path, T data);</programlisting>

<simpara>Stores a piece of data at a specified path. This acts as an <emphasis role="strong">add / replace</emphasis>
operation, which is to say that whole subtree will be replaced by the
specified data.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>merge</term>
<listitem>
<programlisting language="java" linenumbering="unnumbered">&lt;T&gt; void merge(LogicalDatastoreType store, InstanceIdentifier&lt;T&gt; path, T data);</programlisting>

<simpara>Merges a piece of data with the existing data at a specified path.
Any <emphasis role="strong">pre-existing data</emphasis> which are not explicitly overwritten <emphasis role="strong">will be preserved</emphasis>.
This means that if you store a container, its child subtrees will be merged.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>delete</term>
<listitem>
<programlisting language="java" linenumbering="unnumbered">void delete(LogicalDatastoreType store, InstanceIdentifier&lt;?&gt; path);</programlisting>

<simpara>Removes a whole subtree from a specified path.</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_submitting_transaction">
<title>Submitting transaction</title>
<simpara>Transaction is submitted to be processed and committed using following method:</simpara>
<programlisting language="java" linenumbering="unnumbered">CheckedFuture&lt;Void,TransactionCommitFailedException&gt; submit();</programlisting>

<simpara>Applications publish the changes proposed in the transaction by calling <literal>submit()</literal>
on the transaction.
This <emphasis role="strong">seals the transaction</emphasis> (preventing any further writes using this transaction)
and submits it to be processed and applied to global conceptual data tree.
The <literal>submit()</literal> method does not block, but rather returns <literal>ListenableFuture</literal>, which
will complete successfully once processing of transaction is finished and changes
are applied to data tree. If <emphasis role="strong">commit</emphasis> of data failed, the future will fail with
<literal>TransactionFailedException</literal>.</simpara>
<simpara>Application may listen on commit state asynchronously using <literal>ListenableFuture</literal>.</simpara>
<programlisting language="java" linenumbering="unnumbered">Futures.addCallback( writeTx.submit(), new FutureCallback&lt;Void&gt;() { <co xml:id="CO1-1"/>
        public void onSuccess( Void result ) { <co xml:id="CO1-2"/>
            LOG.debug("Transaction committed successfully.");
        }

        public void onFailure( Throwable t ) { <co xml:id="CO1-3"/>
            LOG.error("Commit failed.",e);
        }
    });</programlisting>

<calloutlist>
  
  <callout arearefs="CO1-1">
    <para>Submits <literal>writeTx</literal> and registers application provided <literal>FutureCallback</literal>
on returned future.</para>
    
  </callout>
  
  <callout arearefs="CO1-2">
    <para>Invoked when future completed successfully - transaction <literal>writeTx</literal> was
successfully committed to data tree.</para>
    
  </callout>
  
  <callout arearefs="CO1-3">
    <para>Invoked when future failed - commit of transaction <literal>writeTx</literal> failed.
Supplied exception provides additional details and cause of failure.</para>
    
  </callout>
  
</calloutlist>

<simpara>If application need to block till commit is finished it may use <literal>checkedGet()</literal>
to wait till commit is finished.</simpara>
<programlisting language="java" linenumbering="unnumbered">try {
    writeTx.submit().checkedGet(); <co xml:id="CO2-1"/>
} catch (TransactionCommitFailedException e) { <co xml:id="CO2-2"/>
    LOG.error("Commit failed.",e);
}</programlisting>

<calloutlist>
  
  <callout arearefs="CO2-1">
    <para>Submits <literal>writeTx</literal> and blocks till commit of <literal>writeTx</literal> is finished. If
commit fails <literal>TransactionCommitFailedException</literal> will be thrown.</para>
    
  </callout>
  
  <callout arearefs="CO2-2">
    <para>Catches <literal>TransactionCommitFailedException</literal> and logs it.</para>
    
  </callout>
  
</calloutlist>

</section>
<section xml:id="_transaction_local_state">
<title>Transaction local state</title>
<simpara>Read-Write transactions maintain transaction-local state, which renders all
modifications as if they happened, but this is only local to transaction.</simpara>
<simpara>Reads from the transaction returns data as if the previous modifications in
transaction already happened.</simpara>
<simpara>Let assume initial state of data tree for <literal>PATH</literal> is <literal>A</literal>.</simpara>
<programlisting language="java" linenumbering="unnumbered">ReadWriteTransaction rwTx = broker.newReadWriteTransaction(); <co xml:id="CO3-1"/>

rwRx.read(OPERATIONAL,PATH).get(); <co xml:id="CO3-2"/>
rwRx.put(OPERATIONAL,PATH,B); <co xml:id="CO3-3"/>
rwRx.read(OPERATIONAL,PATH).get(); <co xml:id="CO3-4"/>
rwRx.put(OPERATIONAL,PATH,C); <co xml:id="CO3-5"/>
rwRx.read(OPERATIONAL,PATH).get(); <co xml:id="CO3-6"/></programlisting>

<calloutlist>
  
  <callout arearefs="CO3-1">
    <para>Allocates new <literal>ReadWriteTransaction</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO3-2">
    <para>Read from <literal>rwTx</literal> will return value <literal>A</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO3-3">
    <para>Writes value <literal>B</literal> to <literal>PATH</literal> using <literal>rwTx</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO3-4">
    <para>Read will return value <literal>B</literal> for <literal>PATH</literal>, since previous write occurred in same
transaction.</para>
    
  </callout>
  
  <callout arearefs="CO3-5">
    <para>Writes value <literal>C</literal> to <literal>PATH</literal> using <literal>rwTx</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO3-6">
    <para>Read will return value <literal>C</literal> for <literal>PATH</literal>, since previous write occurred in same
transaction.</para>
    
  </callout>
  
</calloutlist>

</section>
</section>
<section xml:id="_transaction_isolation">
<title>Transaction isolation</title>
<simpara>Running (not submitted) transactions are isolated from each other and changes
done in one transaction are not observable in other currently running
transaction.</simpara>
<simpara>Lets assume initial state of data tree for <literal>PATH</literal> is <literal>A</literal>.</simpara>
<programlisting language="java" linenumbering="unnumbered">ReadOnlyTransaction txRead = broker.newReadOnlyTransaction(); <co xml:id="CO4-1"/>
ReadWriteTransaction txWrite = broker.newReadWriteTransaction(); <co xml:id="CO4-2"/>

txRead.read(OPERATIONAL,PATH).get(); <co xml:id="CO4-3"/>
txWrite.put(OPERATIONAL,PATH,B); <co xml:id="CO4-4"/>
txWrite.read(OPERATIONAL,PATH).get(); <co xml:id="CO4-5"/>
txWrite.submit().get(); <co xml:id="CO4-6"/>
txRead.read(OPERATIONAL,PATH).get(); <co xml:id="CO4-7"/>
txAfterCommit = broker.newReadOnlyTransaction(); <co xml:id="CO4-8"/>
txAfterCommit.read(OPERATIONAL,PATH).get(); <co xml:id="CO4-9"/></programlisting>

<calloutlist>
  
  <callout arearefs="CO4-1">
    <para>Allocates read only transaction, which is based on data tree which
contains value  <literal>A</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO4-2">
    <para>Allocates read write transaction, which is based on data tree which
contains value <literal>A</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO4-3">
    <para>Read from read-only transaction returns value <literal>A</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO4-4">
    <para>Data tree is updated using read-write transaction, <literal>PATH</literal> contains <literal>B</literal>.
Change is not public and only local to transaction.</para>
    
  </callout>
  
  <callout arearefs="CO4-5">
    <para>Read from read-write transaction returns value <literal>B</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO4-6">
    <para>Submits changes in read-write transaction to be committed to data tree.
Once commit will finish, changes will be published and <literal>PATH</literal> will be
updated for value <literal>B</literal>. Previously allocated transactions are not affected by
this change.</para>
    
  </callout>
  
  <callout arearefs="CO4-7">
    <para>Read from previously allocated read-only transaction still returns value <literal>A</literal>
for <literal>PATH</literal>, since it provides stable and isolated view.</para>
    
  </callout>
  
  <callout arearefs="CO4-8">
    <para>Allocates new read-only transaction, which is based on data tree,
which contains value <literal>B</literal> for <literal>PATH</literal>.</para>
    
  </callout>
  
  <callout arearefs="CO4-9">
    <para>Read from new read-only transaction return value <literal>B</literal> for <literal>PATH</literal> since
read-write transaction was committed.</para>
    
  </callout>
  
</calloutlist>

<note>
<simpara>Examples contain blocking calls on future only to illustrate
that action happened after other asynchronous action. The use of the blocking call
<literal>ListenableFuture#get()</literal> is discouraged for most use-cases and you should use
<literal>Futures#addCallback(ListenableFuture, FutureCallback)</literal> to listen asynchronously
for result.</simpara>
</note>

</section>
<section xml:id="_commit_failure_scenarios">
<title>Commit failure scenarios</title>
<simpara>A transaction commit may fail because of following reasons:</simpara>
<variablelist>
<varlistentry>
<term>Optimistic Lock Failure</term>
<listitem>
<simpara>Another transaction finished earlier and <emphasis role="strong">modified the same node in a
non-compatible way</emphasis>. The commit (and the returned future) will fail
with an <literal>OptimisticLockFailedException</literal>.</simpara>
<simpara>It is the responsibility of the
caller to create a new transaction and submit the same modification again in
order to update data tree.</simpara>
<warning>
<simpara><literal>OptimisticLockFailedException</literal> usually exposes <emphasis role="strong">multiple writers</emphasis> to
the same data subtree, which may conflict on same resources.</simpara>
<simpara>In most cases, retrying may result in a probability of success.</simpara>
<simpara>There are scenarios, albeit unusual, where any number of retries will
not succeed. Therefore it is strongly recommended to limit the number of
retries (2 or 3) to avoid an endless loop.</simpara>
</warning>

</listitem>
</varlistentry>
<varlistentry>
<term>Data Validation</term>
<listitem>
<simpara>The data change introduced by this transaction <emphasis role="strong">did not pass validation</emphasis> by
commit handlers or data was incorrectly structured. The returned future will
fail with a <literal>DataValidationFailedException</literal>. User <emphasis role="strong">should not retry</emphasis> to
create new transaction with same data, since it probably will fail again.</simpara>
</listitem>
</varlistentry>
</variablelist>

<section xml:id="_example_conflict_of_two_transactions">
<title>Example conflict of two transactions</title>
<simpara>This example illustrates two concurrent transactions, which derived from
same initial state of data tree and proposes conflicting modifications.</simpara>
<programlisting language="java" linenumbering="unnumbered">WriteTransaction txA = broker.newWriteTransaction();
WriteTransaction txB = broker.newWriteTransaction();

txA.put(CONFIGURATION, PATH, A);    <co xml:id="CO5-1"/>
txB.put(CONFIGURATION, PATH, B);     <co xml:id="CO5-2"/>

CheckedFuture&lt;?,?&gt; futureA = txA.submit(); <co xml:id="CO5-3"/>
CheckedFuture&lt;?,?&gt; futureB = txB.submit(); <co xml:id="CO5-4"/></programlisting>

<calloutlist>
  
  <callout arearefs="CO5-1">
    <para>Updates <literal>PATH</literal> to value <literal>A</literal> using <literal>txA</literal></para>
    
  </callout>
  
  <callout arearefs="CO5-2">
    <para>Updates <literal>PATH</literal> to value <literal>B</literal> using <literal>txB</literal></para>
    
  </callout>
  
  <callout arearefs="CO5-3">
    <para>Seals &amp; submits <literal>txA</literal>. The commit will be processed asynchronously and
data tree will be updated to contain value <literal>A</literal> for <literal>PATH</literal>.
The returned &#8216;ListenableFuture&#8217; will complete successfully once
state is applied to data tree.</para>
    
  </callout>
  
  <callout arearefs="CO5-4">
    <para>Seals &amp; submits <literal>txB</literal>. Commit of <literal>txB</literal> will fail, because previous transaction
also modified path in a concurrent way. The state introduced by <literal>txB</literal> will
not be applied. The returned <literal>ListenableFuture</literal> will fail
with <literal>OptimisticLockFailedException</literal> exception, which indicates
that concurrent transaction prevented the submitted transaction from being
applied.</para>
    
  </callout>
  
</calloutlist>

</section>
<section xml:id="_example_asynchronous_retry_loop">
<title>Example asynchronous retry-loop</title>
<programlisting language="java" linenumbering="unnumbered">private void doWrite( final int tries ) {
    WriteTransaction writeTx = dataBroker.newWriteOnlyTransaction();

    MyDataObject data = ...;
    InstanceIdentifier&lt;MyDataObject&gt; path = ...;
    writeTx.put( LogicalDatastoreType.OPERATIONAL, path, data );

    Futures.addCallback( writeTx.submit(), new FutureCallback&lt;Void&gt;() {
        public void onSuccess( Void result ) {
            // succeeded
        }

        public void onFailure( Throwable t ) {
            if( t instanceof OptimisticLockFailedException &amp;&amp; (( tries - 1 ) &gt; 0)) {
                doWrite( tries - 1 );
            }
        }
      });
}
...
doWrite( 2 );</programlisting>

</section>
</section>
<section xml:id="_concurrent_change_compatibility">
<title>Concurrent change compatibility</title>
<simpara>There are several sets of changes which could be considered incompatible
between two transactions which are derived from same initial state.
Rules for conflict detection applies recursively for each subtree
level.</simpara>
<simpara>Following table shows  state changes and failures between two concurrent
transactions, which are based on same initial state, <literal>tx1</literal> is submitted before
<literal>tx2</literal>.</simpara>
<simpara>INFO: Following tables stores numeric values and shows data using <literal>toString()</literal>
to simplify examples.</simpara>
<table frame="all"
    rowsep="1" colsep="1">
<title>Concurrent change resolution for leaves and leaf-list items</title>
  
  <tgroup cols="4">
    
    <colspec colname="col_1" colwidth="25*"/>
    
    <colspec colname="col_2" colwidth="25*"/>
    
    <colspec colname="col_3" colwidth="25*"/>
    
    <colspec colname="col_4" colwidth="25*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Initial state</entry>
        
        <entry align="left" valign="top">tx1</entry>
        
        <entry align="left" valign="top">tx2</entry>
        
        <entry align="left" valign="top">Observable Result</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, value of <literal>A</literal> is <literal>1</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>value of <literal>A</literal> is <literal>2</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, value of <literal>A</literal> is <literal>1</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>A</literal> is <literal>2</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, <literal>A</literal> is <literal>1</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>A</literal> is <literal>2</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, value of <literal>A</literal> is <literal>1</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,1)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>A</literal> is <literal>2</literal></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>delete(A)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>put(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, <literal>A</literal> does not exists</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>A=0</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>delete(A)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>merge(A,2)</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>A</literal> is <literal>2</literal></simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</table>

<table frame="all"
    rowsep="1" colsep="1">
<title>Concurrent change resolution for containers, lists, list items</title>
  
  <tgroup cols="4">
    
    <colspec colname="col_1" colwidth="25*"/>
    
    <colspec colname="col_2" colwidth="25*"/>
    
    <colspec colname="col_3" colwidth="25*"/>
    
    <colspec colname="col_4" colwidth="25*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Initial state</entry>
        
        <entry align="left" valign="top"><literal>tx1</literal></entry>
        
        <entry align="left" valign="top"><literal>tx2</literal></entry>
        
        <entry align="left" valign="top">Result</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is TOP=[]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is
TOP=[FOO=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is
TOP=[FOO=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is
TOP=[FOO=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is
TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is
TOP=[FOO=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[FOO=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is
TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is empty
store</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP,[BAR=1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/FOO,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1])</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/FOO,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/FOO,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/FOO,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[FOO=1,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is empty
store</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>tx2</literal> will fail, state is empty
store</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/FOO,2)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[FOO=2,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/FOO,2)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is
TOP=[FOO=2,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/FOO,2)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is
TOP=[FOO=2,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/FOO,2)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is
TOP=[FOO=2,BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP/FOO)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>put(TOP/BAR,1)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[BAR=1]</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TOP=[FOO=1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>delete(TOP/FOO)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>merge(TOP/BAR,1]</simpara></entry>
        
        <entry align="left" valign="top"><simpara>state is TOP=[BAR=1]</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</table>

</section>
</section>
<section xml:id="_md_sal_rpc_routing">
<title>MD-SAL RPC routing</title>
<simpara>The MD-SAL provides a way to deliver Remote Procedure Calls (RPCs) to a
particular implementation based on content in the input as it is modeled in
YANG. This part of the the RPC input is referred to as a <emphasis role="strong">context reference</emphasis>.</simpara>
<simpara>The MD-SAL does not dictate the name of the leaf which is used for this RPC
routing, but provides necessary functionality for YANG model author to define
their <emphasis role="strong">context reference</emphasis> in their model of RPCs.</simpara>
<simpara>MD-SAL routing behavior is modeled using following terminology and its
application to YANG models:</simpara>
<variablelist>
<varlistentry>
<term>Context Type</term>
<listitem>
<simpara>Logical type of RPC routing. Context type is modeled as YANG <literal>identity</literal>
and is referenced in model to provide scoping information.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Context Instance</term>
<listitem>
<simpara>Conceptual location in data tree, which represents context in which RPC
could be executed. Context instance usually represent logical point
to which RPC execution is attached.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Context Reference</term>
<listitem>
<simpara>Field of RPC input payload which contains Instance Identifier referencing
<emphasis role="strong">context instance</emphasis>  in which the RPC should be executed.</simpara>
</listitem>
</varlistentry>
</variablelist>

<section xml:id="_modeling_a_routed_rpc">
<title>Modeling a routed RPC</title>
<simpara>In order to define routed RPCs, the YANG model author needs to declare (or
reuse) a <emphasis role="strong">context type</emphasis>, set of possible <emphasis role="strong">context instances</emphasis> and finally RPCs
which will contain <emphasis role="strong">context reference</emphasis> on which they will be routed.</simpara>
<section xml:id="_declaring_a_routing_context_type">
<title>Declaring a routing context type</title>
<programlisting language="yang" linenumbering="unnumbered">identity node-context {
    description "Identity used to mark node context";
}</programlisting>

<simpara>This declares an identity named <literal>node-context</literal>, which is used as marker
for node-based routing and is used in other places to reference that routing
type.</simpara>
</section>
<section xml:id="_declaring_possible_context_instances">
<title>Declaring possible context instances</title>
<simpara>In order to define possible values of <emphasis role="strong">context instances</emphasis> for routed RPCs, we
need to model that set accordingly using <literal>context-instance</literal> extension from the
<literal>yang-ext</literal> model.</simpara>
<programlisting language="yang" linenumbering="unnumbered">import yang-ext { prefix ext; }

/** Base structure **/
container nodes {
    list node {
        key "id";
        ext:context-instance "node-context";
        // other node-related fields would go here
    }
}</programlisting>

<simpara>The statement <literal>ext:context-instance "node-context";</literal> marks any element of the
<literal>list node</literal> as a possible valid <emphasis role="strong">context instance</emphasis> in <literal>node-context</literal> based
routing.</simpara>
<note>
<simpara>The existence of a <emphasis role="strong">context instance</emphasis> node in operational or config data tree
is not strongly tied to existence of RPC implementation.</simpara>
<simpara>For most routed RPC models, there is relationship between the data present in
operational data tree and RPC implementation availability, but this is
not enforced by MD-SAL. This provides some flexibility for YANG model writers
to better specify their routing model and requirements for implementations.
Details when RPC implementations are available should be documented in YANG model.</simpara>
<simpara>If user invokes RPC with a <emphasis role="strong">context instance</emphasis> that has no registered
implementation, the RPC invocation will fail with the exception
<literal>DOMRpcImplementationNotAvailableException</literal>.</simpara>
</note>

</section>
<section xml:id="_declaring_a_routed_rpc">
<title>Declaring a routed RPC</title>
<simpara>To declare RPC to be routed based on <literal>node-context</literal> we need to add leaf
of <literal>instance-identifier</literal> type (or type derived from <literal>instance-identifier</literal>)
to the RPC and mark it as <emphasis role="strong">context reference</emphasis>.</simpara>
<simpara>This is achieved using YANG extension <literal>context-reference</literal> from <literal>yang-ext</literal> model
on leaf, which will be used for RPC routing.</simpara>
<programlisting language="yang" linenumbering="unnumbered">rpc example-routed-rpc  {
    input {
        leaf node {
            ext:context-reference "node-context";
            type "instance-identifier";
        }
        // other input to the RPC would go here
    }
}</programlisting>

<simpara>The statement <literal>ext:context-reference "node-context"</literal> marks <literal>leaf node</literal> as
<emphasis role="strong">context reference</emphasis> of type <literal>node-context</literal>. The value of this leaf, will be used
by the MD-SAL to select the particular RPC implementation that registered itself
as the implementation of the RPC for particular <emphasis role="strong">context instance</emphasis>.</simpara>
</section>
</section>
<section xml:id="_using_routed_rpcs">
<title>Using routed RPCs</title>
<simpara>From a user perspective (e.g. invoking RPCs) there is no difference between
routed and non-routed RPCs. Routing information is just an additional leaf in
RPC which must be populated.</simpara>
</section>
<section xml:id="_implementing_a_routed_rpc">
<title>Implementing a routed RPC</title>
<simpara>Implementation</simpara>
<section xml:id="_registering_implementations">
<title>Registering implementations</title>
<simpara>Implementations of a routed RPC (e.g., southbound plugins) will specify an
instance-identifier for the <emphasis role="strong">context reference</emphasis> (in this case a node) for which
they want to provide an implementation during registration. Consumers, e.g.,
those calling the RPC are required to specify that instance-identifier (in this
case the identifier of a node) when invoking RPC.</simpara>
<simpara>Simple code which showcases that for add-flow via Binding-Aware APIs
(<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=controller.git;a=blob;f=opendaylight/md-sal/sal-binding-it/src/test/java/org/opendaylight/controller/test/sal/binding/it/RoutedServiceTest.java;h=d49d6f0e25e271e43c8550feb5eef63d96301184;hb=HEAD">RoutedServiceTest.java</link>
):</simpara>
<programlisting language="java" linenumbering="unnumbered"> 61  @Override
 62  public void onSessionInitiated(ProviderContext session) {
 63      assertNotNull(session);
 64      firstReg = session.addRoutedRpcImplementation(SalFlowService.class, salFlowService1);
 65  }</programlisting>

<simpara>Line 64: We are registering salFlowService1 as implementation of
SalFlowService RPC</simpara>
<programlisting language="java" linenumbering="unnumbered">107  NodeRef nodeOne = createNodeRef("foo:node:1");
109  /**
110   * Provider 1 registers path of node 1
111   */
112  firstReg.registerPath(NodeContext.class, nodeOne);</programlisting>

<simpara>Line 107: We are creating NodeRef (encapsulation of InstanceIdentifier)
for "foo:node:1".</simpara>
<simpara>Line 112: We register salFlowService1 as implementation for nodeOne.</simpara>
<simpara>The salFlowService1 will be executed only for RPCs which contains
Instance Identifier for foo:node:1.</simpara>
</section>
</section>
</section>
<section xml:id="_opendaylight_controller_md_sal_restconf">
<title>OpenDaylight Controller MD-SAL: RESTCONF</title>
<section xml:id="_resconf_operations_overview">
<title>RESCONF operations overview</title>
<simpara>RESTCONF allows access to datastores in the controller.<?asciidoc-br?>
There are two datastores:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Config: Contains data inserted via controller</simpara>
</listitem>
<listitem>
<simpara>Operational: Contains other data</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>Each request must start with the URI /restconf.<?asciidoc-br?>
RESTCONF listens on port 8080 for HTTP requests.</simpara>
</note>

<simpara>RESTCONF supports <emphasis role="strong">OPTIONS</emphasis>, <emphasis role="strong">GET</emphasis>, <emphasis role="strong">PUT</emphasis>, <emphasis role="strong">POST</emphasis>, and <emphasis role="strong">DELETE</emphasis> operations. Request and response data can either be in the XML or JSON format. XML structures according to yang are defined at: <link xlink:href="http://tools.ietf.org/html/rfc6020">XML-YANG</link>. JSON structures are defined at: <link xlink:href="http://tools.ietf.org/html/draft-lhotka-netmod-yang-json-02">JSON-YANG</link>. Data in the request must have a correctly set <emphasis role="strong">Content-Type</emphasis> field in the http header with the allowed value of the media type. The media type of the requested data has to be set in the <emphasis role="strong">Accept</emphasis> field. Get the media types for each resource by calling the OPTIONS operation.
Most of the paths of the pathsRestconf endpoints use <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:MD-SAL:Concepts#Instance_Identifier">Instance Identifier</link>. <literal>&lt;identifier&gt;</literal> is used in the explanation of the operations.</simpara>
<simpara><emphasis role="strong">&lt;identifier&gt;</emphasis><?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>It must start with &lt;moduleName&gt;:&lt;nodeName&gt; where &lt;moduleName&gt; is a name of the module and &lt;nodeName&gt; is the name of a node in the module. It is sufficient to just use &lt;nodeName&gt; after &lt;moduleName&gt;:&lt;nodeName&gt;. Each &lt;nodeName&gt; has to be separated by /.</simpara>
</listitem>
<listitem>
<simpara>&lt;nodeName&gt; can represent a data node which is a list or container yang built-in type. If the data node is a list, there must be defined keys of the list behind the data node name for example, &lt;nodeName&gt;/&lt;valueOfKey1&gt;/&lt;valueOfKey2&gt;.</simpara>
</listitem>
<listitem>
<simpara>The format &lt;moduleName&gt;:&lt;nodeName&gt; has to be used in this case as well:<?asciidoc-br?>
Module A has node A1. Module B augments node A1 by adding node X. Module C augments node A1 by adding node X. For clarity, it has to be known which node is X (for example: C:X).
For more details about encoding, see: <link xlink:href="http://tools.ietf.org/html/draft-bierman-netconf-restconf-02#section-5.3.1">RESTCONF 02 - Encoding YANG Instance Identifiers in the Request URI.</link></simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_mount_point">
<title>Mount point</title>
<simpara>A Node can be behind a mount point. In this case, the URI has to be in format &lt;identifier&gt;/<emphasis role="strong">yang-ext:mount</emphasis>/&lt;identifier&gt;. The first &lt;identifier&gt; is the path to a mount point and the second &lt;identifier&gt; is the path to a node behind the mount point. A URI can end in a mount point itself by using &lt;identifier&gt;/<emphasis role="strong">yang-ext:mount</emphasis>.<?asciidoc-br?>
More information on how to actually use mountpoints is available at: <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:Config:Examples:Netconf">OpenDaylight Controller:Config:Examples:Netconf</link>.</simpara>
</section>
<section xml:id="_http_methods">
<title>HTTP methods</title>
<section xml:id="_options_restconf_asciidoc_br">
<title>OPTIONS /restconf<?asciidoc-br?></title>
<itemizedlist>
<listitem>
<simpara>Returns the XML description of the resources with the required request and response media types in Web Application Description Language (WADL)</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_get_restconf_config_identifier_asciidoc_br">
<title>GET /restconf/config/&lt;identifier&gt;<?asciidoc-br?></title>
<itemizedlist>
<listitem>
<simpara>Returns a data node from the Config datastore.</simpara>
</listitem>
<listitem>
<simpara>&lt;identifier&gt; points to a data node which must be retrieved.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_get_restconf_operational_identifier_asciidoc_br">
<title>GET /restconf/operational/&lt;identifier&gt;<?asciidoc-br?></title>
<itemizedlist>
<listitem>
<simpara>Returns the value of the data node from the Operational datastore.</simpara>
</listitem>
<listitem>
<simpara>&lt;identifier&gt; points to a data node which must be retrieved.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_put_restconf_config_identifier">
<title>PUT /restconf/config/&lt;identifier&gt;</title>
<itemizedlist>
<listitem>
<simpara>Updates or creates data in the Config datastore and returns the state about success.</simpara>
</listitem>
<listitem>
<simpara>&lt;identifier&gt; points to a data node which must be stored.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Example:</emphasis><?asciidoc-br?></simpara>
<screen>PUT http://&lt;controllerIP&gt;:8080/restconf/config/module1:foo/bar
Content-Type: applicaton/xml
&lt;bar&gt;
  …
&lt;/bar&gt;</screen>

<simpara><emphasis role="strong">Example with mount point:</emphasis><?asciidoc-br?></simpara>
<screen>PUT http://&lt;controllerIP&gt;:8080/restconf/config/module1:foo1/foo2/yang-ext:mount/module2:foo/bar
Content-Type: applicaton/xml
&lt;bar&gt;
  …
&lt;/bar&gt;</screen>

</section>
<section xml:id="_post_restconf_config">
<title>POST /restconf/config</title>
<itemizedlist>
<listitem>
<simpara>Creates the data if it does not exist</simpara>
</listitem>
</itemizedlist>

<simpara>For example:<?asciidoc-br?></simpara>
<screen>POST URL: http://localhost:8080/restconf/config/
content-type: application/yang.data+json
JSON payload:

   {
     "toaster:toaster" :
     {
       "toaster:toasterManufacturer" : "General Electric",
       "toaster:toasterModelNumber" : "123",
       "toaster:toasterStatus" : "up"
     }
  }</screen>

</section>
<section xml:id="_post_restconf_config_identifier">
<title>POST /restconf/config/&lt;identifier&gt;</title>
<itemizedlist>
<listitem>
<simpara>Creates the data if it does not exist in the Config datastore, and returns the state about success.</simpara>
</listitem>
<listitem>
<simpara>&lt;identifier&gt; points to a data node where data must be stored.</simpara>
</listitem>
<listitem>
<simpara>The root element of data must have the namespace (data are in XML) or module name (data are in JSON.)</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Example:</emphasis><?asciidoc-br?></simpara>
<screen>POST http://&lt;controllerIP&gt;:8080/restconf/config/module1:foo
Content-Type: applicaton/xml/
&lt;bar xmlns=“module1namespace”&gt;
  …
&lt;/bar&gt;</screen>

<simpara><emphasis role="strong">Example with mount point:</emphasis></simpara>
<screen>http://&lt;controllerIP&gt;:8080/restconf/config/module1:foo1/foo2/yang-ext:mount/module2:foo
Content-Type: applicaton/xml
&lt;bar xmlns=“module2namespace”&gt;
  …
&lt;/bar&gt;</screen>

</section>
<section xml:id="_post_restconf_operations_modulename_rpcname">
<title>POST /restconf/operations/&lt;moduleName&gt;:&lt;rpcName&gt;</title>
<itemizedlist>
<listitem>
<simpara>Invokes RPC.</simpara>
</listitem>
<listitem>
<simpara>&lt;moduleName&gt;:&lt;rpcName&gt; - &lt;moduleName&gt; is the name of the module and &lt;rpcName&gt; is the name of the RPC in this module.</simpara>
</listitem>
<listitem>
<simpara>The Root element of the data sent to RPC must have the name “input”.</simpara>
</listitem>
<listitem>
<simpara>The result can be the status code or the retrieved data having the root element “output”.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Example:</emphasis><?asciidoc-br?></simpara>
<screen>POST http://&lt;controllerIP&gt;:8080/restconf/operations/module1:fooRpc
Content-Type: applicaton/xml
Accept: applicaton/xml
&lt;input&gt;
  …
&lt;/input&gt;

The answer from the server could be:
&lt;output&gt;
  …
&lt;/output&gt;</screen>

<simpara><emphasis role="strong">An example using a JSON payload:</emphasis><?asciidoc-br?></simpara>
<screen>POST http://localhost:8080/restconf/operations/toaster:make-toast
Content-Type: application/yang.data+json
{
  "input" :
  {
     "toaster:toasterDoneness" : "10",
     "toaster:toasterToastType":"wheat-bread"
  }
}</screen>

<note>
<simpara>Even though this is a default for the toasterToastType value in the yang, you still need to define it.</simpara>
</note>

</section>
<section xml:id="_delete_restconf_config_identifier">
<title>DELETE /restconf/config/&lt;identifier&gt;</title>
<itemizedlist>
<listitem>
<simpara>Removes the data node in the Config datastore and returns the state about success.</simpara>
</listitem>
<listitem>
<simpara>&lt;identifier&gt; points to a data node which must be removed.</simpara>
</listitem>
</itemizedlist>

<simpara>More information is available in the <link xlink:href="http://tools.ietf.org/html/draft-bierman-netconf-restconf-02">RESTCONF RFC</link>.</simpara>
</section>
</section>
<section xml:id="_how_restconf_works">
<title>How RESTCONF works</title>
<simpara>RESTCONF uses these base classes:<?asciidoc-br?></simpara>
<variablelist>
<varlistentry>
<term>InstanceIdentifier</term>
<listitem>
<simpara>Represents the path in the data tree</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>ConsumerSession</term>
<listitem>
<simpara>Used for invoking RPCs</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>DataBrokerService</term>
<listitem>
<simpara>Offers manipulation with transactions and reading data from the datastores</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>SchemaContext</term>
<listitem>
<simpara>Holds information about yang modules</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>MountService</term>
<listitem>
<simpara>Returns MountInstance based on the InstanceIdentifier pointing to a mount point</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>MountInstace</term>
<listitem>
<simpara>Contains the SchemaContext behind the mount point</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>DataSchemaNode</term>
<listitem>
<simpara>Provides information about the schema node</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>SimpleNode</term>
<listitem>
<simpara>Possesses the same name as the schema node, and contains the value representing the data node value</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>CompositeNode</term>
<listitem>
<simpara>Can contain CompositeNode-s and SimpleNode-s</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_get_in_action">
<title>GET in action</title>
<simpara>Figure 1 shows the GET operation with URI restconf/config/M:N where M is the module name, and N is the node name.</simpara>
<figure>
<title>Get</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Get.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Get</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>The requested URI is translated into the InstanceIdentifier which points to the data node. During this translation, the DataSchemaNode that conforms to the data node is obtained. If the data node is behind the mount point, the MountInstance is obtained as well.</simpara>
</listitem>
<listitem>
<simpara>RESTCONF asks for the value of the data node from DataBrokerService based on InstanceIdentifier.</simpara>
</listitem>
<listitem>
<simpara>DataBrokerService returns CompositeNode as data.</simpara>
</listitem>
<listitem>
<simpara>StructuredDataToXmlProvider or StructuredDataToJsonProvider is called based on the <emphasis role="strong">Accept</emphasis> field from the http request. These two providers can transform CompositeNode regarding DataSchemaNode to an XML or JSON document.</simpara>
</listitem>
<listitem>
<simpara>XML or JSON is returned as the answer on the request from the client.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_put_in_action">
<title>PUT in action</title>
<simpara>Figure 2 shows the PUT operation with the URI restconf/config/M:N where M is the module name, and N is the node name. Data is sent in the request either in the XML or JSON format.</simpara>
<figure>
<title>Put</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Put.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Put</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Input data is sent to JsonToCompositeNodeProvider or XmlToCompositeNodeProvider. The correct provider is selected based on the Content-Type field from the http request. These two providers can transform input data to CompositeNode. However, this CompositeNode does not contain enough information for transactions.</simpara>
</listitem>
<listitem>
<simpara>The requested URI is translated into InstanceIdentifier which points to the data node. DataSchemaNode conforming to the data node is obtained during this translation. If the data node is behind the mount point, the MountInstance is obtained as well.</simpara>
</listitem>
<listitem>
<simpara>CompositeNode can be normalized by adding additional information from DataSchemaNode.</simpara>
</listitem>
<listitem>
<simpara>RESTCONF begins the transaction, and puts CompositeNode with InstanceIdentifier into it. The response on the request from the client is the status code which depends on the result from the transaction.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_something_practical">
<title>Something practical</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a new flow on the switch openflow:1 in table 2.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">HTTP request</emphasis><?asciidoc-br?></simpara>
<screen>Operation: POST
URI: http://192.168.11.1:8080/restconf/config/opendaylight-inventory:nodes/node/openflow:1/table/2
Content-Type: application/xml</screen>

<screen>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;flow
    xmlns="urn:opendaylight:flow:inventory"&gt;
    &lt;strict&gt;false&lt;/strict&gt;
    &lt;instructions&gt;
        &lt;instruction&gt;
          	&lt;order&gt;1&lt;/order&gt;
            &lt;apply-actions&gt;
                &lt;action&gt;
                  &lt;order&gt;1&lt;/order&gt;
                    &lt;flood-all-action/&gt;
                &lt;/action&gt;
            &lt;/apply-actions&gt;
        &lt;/instruction&gt;
    &lt;/instructions&gt;
    &lt;table_id&gt;2&lt;/table_id&gt;
    &lt;id&gt;111&lt;/id&gt;
    &lt;cookie_mask&gt;10&lt;/cookie_mask&gt;
    &lt;out_port&gt;10&lt;/out_port&gt;
    &lt;installHw&gt;false&lt;/installHw&gt;
    &lt;out_group&gt;2&lt;/out_group&gt;
    &lt;match&gt;
        &lt;ethernet-match&gt;
            &lt;ethernet-type&gt;
                &lt;type&gt;2048&lt;/type&gt;
            &lt;/ethernet-type&gt;
        &lt;/ethernet-match&gt;
        &lt;ipv4-destination&gt;10.0.0.1/24&lt;/ipv4-destination&gt;
    &lt;/match&gt;
    &lt;hard-timeout&gt;0&lt;/hard-timeout&gt;
    &lt;cookie&gt;10&lt;/cookie&gt;
    &lt;idle-timeout&gt;0&lt;/idle-timeout&gt;
    &lt;flow-name&gt;FooXf22&lt;/flow-name&gt;
    &lt;priority&gt;2&lt;/priority&gt;
    &lt;barrier&gt;false&lt;/barrier&gt;
&lt;/flow&gt;</screen>

<simpara><emphasis role="strong">HTTP response</emphasis><?asciidoc-br?></simpara>
<screen>Status: 204 No Content</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Change <emphasis>strict</emphasis> to <emphasis>true</emphasis> in the previous flow.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">HTTP request</emphasis><?asciidoc-br?></simpara>
<screen>Operation: PUT
URI: http://192.168.11.1:8080/restconf/config/opendaylight-inventory:nodes/node/openflow:1/table/2/flow/111
Content-Type: application/xml</screen>

<screen>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;flow
    xmlns="urn:opendaylight:flow:inventory"&gt;
    &lt;strict&gt;true&lt;/strict&gt;
    &lt;instructions&gt;
        &lt;instruction&gt;
          	&lt;order&gt;1&lt;/order&gt;
            &lt;apply-actions&gt;
                &lt;action&gt;
                  &lt;order&gt;1&lt;/order&gt;
                    &lt;flood-all-action/&gt;
                &lt;/action&gt;
            &lt;/apply-actions&gt;
        &lt;/instruction&gt;
    &lt;/instructions&gt;
    &lt;table_id&gt;2&lt;/table_id&gt;
    &lt;id&gt;111&lt;/id&gt;
    &lt;cookie_mask&gt;10&lt;/cookie_mask&gt;
    &lt;out_port&gt;10&lt;/out_port&gt;
    &lt;installHw&gt;false&lt;/installHw&gt;
    &lt;out_group&gt;2&lt;/out_group&gt;
    &lt;match&gt;
        &lt;ethernet-match&gt;
            &lt;ethernet-type&gt;
                &lt;type&gt;2048&lt;/type&gt;
            &lt;/ethernet-type&gt;
        &lt;/ethernet-match&gt;
        &lt;ipv4-destination&gt;10.0.0.1/24&lt;/ipv4-destination&gt;
    &lt;/match&gt;
    &lt;hard-timeout&gt;0&lt;/hard-timeout&gt;
    &lt;cookie&gt;10&lt;/cookie&gt;
    &lt;idle-timeout&gt;0&lt;/idle-timeout&gt;
    &lt;flow-name&gt;FooXf22&lt;/flow-name&gt;
    &lt;priority&gt;2&lt;/priority&gt;
    &lt;barrier&gt;false&lt;/barrier&gt;
&lt;/flow&gt;</screen>

<simpara><emphasis role="strong">HTTP response</emphasis><?asciidoc-br?></simpara>
<screen>Status: 200 OK</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Show flow: check that <emphasis>strict</emphasis> is <emphasis>true</emphasis>.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">HTTP request</emphasis><?asciidoc-br?></simpara>
<screen>Operation: GET
URI: http://192.168.11.1:8080/restconf/config/opendaylight-inventory:nodes/node/openflow:1/table/2/flow/111
Accept: application/xml</screen>

<simpara><emphasis role="strong">HTTP response</emphasis><?asciidoc-br?></simpara>
<screen>Status: 200 OK</screen>

<screen>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;flow
    xmlns="urn:opendaylight:flow:inventory"&gt;
    &lt;strict&gt;true&lt;/strict&gt;
    &lt;instructions&gt;
        &lt;instruction&gt;
          	&lt;order&gt;1&lt;/order&gt;
            &lt;apply-actions&gt;
                &lt;action&gt;
                  &lt;order&gt;1&lt;/order&gt;
                    &lt;flood-all-action/&gt;
                &lt;/action&gt;
            &lt;/apply-actions&gt;
        &lt;/instruction&gt;
    &lt;/instructions&gt;
    &lt;table_id&gt;2&lt;/table_id&gt;
    &lt;id&gt;111&lt;/id&gt;
    &lt;cookie_mask&gt;10&lt;/cookie_mask&gt;
    &lt;out_port&gt;10&lt;/out_port&gt;
    &lt;installHw&gt;false&lt;/installHw&gt;
    &lt;out_group&gt;2&lt;/out_group&gt;
    &lt;match&gt;
        &lt;ethernet-match&gt;
            &lt;ethernet-type&gt;
                &lt;type&gt;2048&lt;/type&gt;
            &lt;/ethernet-type&gt;
        &lt;/ethernet-match&gt;
        &lt;ipv4-destination&gt;10.0.0.1/24&lt;/ipv4-destination&gt;
    &lt;/match&gt;
    &lt;hard-timeout&gt;0&lt;/hard-timeout&gt;
    &lt;cookie&gt;10&lt;/cookie&gt;
    &lt;idle-timeout&gt;0&lt;/idle-timeout&gt;
    &lt;flow-name&gt;FooXf22&lt;/flow-name&gt;
    &lt;priority&gt;2&lt;/priority&gt;
    &lt;barrier&gt;false&lt;/barrier&gt;
&lt;/flow&gt;</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Delete the flow created.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">HTTP request</emphasis><?asciidoc-br?></simpara>
<screen>Operation: DELETE
URI: http://192.168.11.1:8080/restconf/config/opendaylight-inventory:nodes/node/openflow:1/table/2/flow/111</screen>

<simpara><emphasis role="strong">HTTP response</emphasis><?asciidoc-br?></simpara>
<screen>Status: 200 OK</screen>

</section>
</section>
<section xml:id="_websocket_change_event_notification_subscription_tutorial">
<title>Websocket change event notification subscription tutorial</title>
<simpara>Subscribing to data change notifications makes it possible to obtain
notifications about data manipulation (insert, change, delete) which are
done on any specified <emphasis role="strong">path</emphasis> of any specified <emphasis role="strong">datastore</emphasis> with specific
<emphasis role="strong">scope</emphasis>. In following examples <emphasis>{odlAddress}</emphasis> is address of server
where ODL is running and <emphasis>{odlPort}</emphasis> is port on which OpenDaylight is
running.</simpara>
<section xml:id="_websocket_notifications_subscription_process">
<title>Websocket notifications subscription process</title>
<simpara>In this section we will learn what steps need to be taken in order to
successfully subscribe to data change event notifications.</simpara>
<section xml:id="_create_stream">
<title>Create stream</title>
<simpara>In order to use event notifications you first need to call RPC that
creates notification stream that you can later listen to. You need to
provide three parameters to this RPC:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">path</emphasis>: data store path that you plan to listen to. You can register
listener on containers, lists and leaves.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">datastore</emphasis>: data store type. <emphasis>OPERATIONAL</emphasis> or <emphasis>CONFIGURATION</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">scope</emphasis>: Represents scope of data change. Possible options are:</simpara>
<itemizedlist>
<listitem>
<simpara>BASE: only changes directly to the data tree node specified in the
path will be reported</simpara>
</listitem>
<listitem>
<simpara>ONE: changes to the node and to direct child nodes will be reported</simpara>
</listitem>
<listitem>
<simpara>SUBTREE: changes anywhere in the subtree starting at the node will
be reported</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara>The RPC to create the stream can be invoked via RESCONF like this:</simpara>
<itemizedlist>
<listitem>
<simpara>URI:
http://{odlAddress}:{odlPort}/restconf/operations/sal-remote:create-data-change-event-subscription</simpara>
</listitem>
<listitem>
<simpara>HEADER: Content-Type=application/json</simpara>
</listitem>
<listitem>
<simpara>OPERATION: POST</simpara>
</listitem>
<listitem>
<simpara>DATA:</simpara>
<programlisting language="json" linenumbering="unnumbered">{
    "input": {
        "path": "/toaster:toaster/toaster:toasterStatus",
        "sal-remote-augment:datastore": "OPERATIONAL",
        "sal-remote-augment:scope": "ONE"
    }
}</programlisting>

</listitem>
</itemizedlist>

<simpara>The response should look something like this:</simpara>
<programlisting language="json" linenumbering="unnumbered">{
    "output": {
        "stream-name": "toaster:toaster/toaster:toasterStatus/datastore=CONFIGURATION/scope=SUBTREE"
    }
}</programlisting>

<simpara><emphasis role="strong">stream-name</emphasis> is important because you will need to use it when you
subscribe to the stream in the next step.</simpara>
<note>
<simpara>Internally, this will create a new listener  for <emphasis>stream-name</emphasis>
      if it did not already exist.</simpara>
</note>

</section>
<section xml:id="_subscribe_to_stream">
<title>Subscribe to stream</title>
<simpara>In order to subscribe to stream and obtain WebSocket location you need
to call <emphasis>GET</emphasis> on your stream path. The URI should generally be
http://{odlAddress}:{odlPort}/restconf/streams/stream/{streamName},
where <emphasis>{streamName}</emphasis> is the <emphasis>stream-name</emphasis> parameter contained in
response from <emphasis>create-data-change-event-subscription</emphasis> RPC from the
previous step.</simpara>
<itemizedlist>
<listitem>
<simpara>URI:
http://{odlAddress}:{odlPort}/restconf/streams/stream/toaster:toaster/datastore=CONFIGURATION/scope=SUBTREE</simpara>
</listitem>
<listitem>
<simpara>OPERATION: GET</simpara>
</listitem>
</itemizedlist>

<simpara>The expected response status is 200 OK and response body should be empty.
You will get your WebSocket location from <emphasis role="strong">Location</emphasis> header of response.
For example in our particular toaster example location header would have
this value:
<emphasis>ws://{odlAddress}:8185/toaster:toaster/datastore=CONFIGURATION/scope=SUBTREE</emphasis></simpara>
<note>
<simpara>During this phase there is an internal check for to see if a
      listener for the <emphasis>stream-name</emphasis> from the URI exists. If not, new
      a new listener is registered with the DOM data broker.</simpara>
</note>

</section>
<section xml:id="_receive_notifications">
<title>Receive notifications</title>
<simpara>You should now have a data change notification stream created and have
location of a WebSocket. You can use this WebSocket to listen to data
change notifications. To listen to notifications you can use a
JavaScript client or if you are using chrome browser you can use the
<link xlink:href="https://chrome.google.com/webstore/detail/simple-websocket-client/pfdhoblngboilpfeibdedpjgfnlcodoo">Simple
WebSocket Client</link>.</simpara>
<simpara>Also, for testing purposes, there is simple Java application named
WebSocketClient. The application is placed in the
<emphasis>-sal-rest-connector-classes.class</emphasis> project. It accepts a WebSocket URI
as and input parameter. After starting the utility (WebSocketClient
class directly in Eclipse/InteliJ Idea) received notifications should be
displayed in console.</simpara>
<simpara>Notifications are always in XML format and look like this:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;notification xmlns="urn:ietf:params:xml:ns:netconf:notification:1.0"&gt;
    &lt;eventTime&gt;2014-09-11T09:58:23+02:00&lt;/eventTime&gt;
    &lt;data-changed-notification xmlns="urn:opendaylight:params:xml:ns:yang:controller:md:sal:remote"&gt;
        &lt;data-change-event&gt;
            &lt;path xmlns:meae="http://netconfcentral.org/ns/toaster"&gt;/meae:toaster&lt;/path&gt;
            &lt;operation&gt;updated&lt;/operation&gt;
            &lt;data&gt;
               &lt;!-- updated data --&gt;
            &lt;/data&gt;
        &lt;/data-change-event&gt;
    &lt;/data-changed-notification&gt;
&lt;/notification&gt;</programlisting>

</section>
</section>
<section xml:id="_example_use_case">
<title>Example use case</title>
<simpara>The typical use case is listening to data change events to update web
page data in real-time. In this tutorial we will be using toaster as
the base.</simpara>
<simpara>When you call <emphasis>make-toast</emphasis> RPC, it sets <emphasis>toasterStatus</emphasis> to "down" to
reflect that the toaster is busy making toast. When it finishes,
<emphasis>toasterStatus</emphasis> is set to "up" again. We will listen to this toaster
status changes in data store and will reflect it on our web page in
real-time thanks to WebSocket data change notification.</simpara>
</section>
<section xml:id="_simple_javascript_client_implementation">
<title>Simple javascript client implementation</title>
<simpara>We will create simple JavaScript web application that will listen
updates on <emphasis>toasterStatus</emphasis> leaf and update some element of our web page
according to new toaster status state.</simpara>
<section xml:id="_create_stream_2">
<title>Create stream</title>
<simpara>First you need to create stream that you are planing to subscribe to.
This can be achieved by invoking "create-data-change-event-subscription"
RPC on RESTCONF via AJAX request. You need to provide data store <emphasis role="strong">path</emphasis>
that you plan to listen on, <emphasis role="strong">data store type</emphasis> and <emphasis role="strong">scope</emphasis>. If the
request is successful you can extract the <emphasis role="strong">stream-name</emphasis> from the
response and use that to subscribe to the newly created stream. The
<emphasis>{username}</emphasis> and <emphasis>{password}</emphasis> fields represent your credentials that
you use to connect to OpenDaylight via RESTCONF:</simpara>
<note>
<simpara>The default user name and password are "admin".</simpara>
</note>

<programlisting language="javascript" linenumbering="unnumbered">function createStream() {
    $.ajax(
        {
            url: 'http://{odlAddress}:{odlPort}/restconf/operations/sal-remote:create-data-change-event-subscription',
            type: 'POST',
            headers: {
              'Authorization': 'Basic ' + btoa('{username}:{password}'),
              'Content-Type': 'application/json'
            },
            data: JSON.stringify(
                {
                    'input': {
                        'path': '/toaster:toaster/toaster:toasterStatus',
                        'sal-remote-augment:datastore': 'OPERATIONAL',
                        'sal-remote-augment:scope': 'ONE'
                    }
                }
            )
        }).done(function (data) {
            // this function will be called when ajax call is executed successfully
            subscribeToStream(data.output['stream-name']);
        }).fail(function (data) {
            // this function will be called when ajax call fails
            console.log("Create stream call unsuccessful");
        })
}</programlisting>

</section>
<section xml:id="_subscribe_to_stream_2">
<title>Subscribe to stream</title>
<simpara>The Next step is to subscribe to the stream. To subscribe to the stream
you need to call <emphasis>GET</emphasis> on
<emphasis>http://{odlAddress}:{odlPort}/restconf/streams/stream/{stream-name}</emphasis>.
If the call is successful, you get WebSocket address for this stream in
<emphasis role="strong">Location</emphasis> parameter inside response header. You can get response header
by calling <emphasis>getResponseHeader(<emphasis>Location</emphasis>)</emphasis> on HttpRequest object inside
<emphasis>done()</emphasis> function call:</simpara>
<programlisting language="javascript" linenumbering="unnumbered">function subscribeToStream(streamName) {
    $.ajax(
        {
            url: 'http://{odlAddress}:{odlPort}/restconf/streams/stream/' + streamName;
            type: 'GET',
            headers: {
              'Authorization': 'Basic ' + btoa('{username}:{password}'),
            }
        }
    ).done(function (data, textStatus, httpReq) {
        // we need function that has http request object parameter in order to access response headers.
        listenToNotifications(httpReq.getResponseHeader('Location'));
    }).fail(function (data) {
        console.log("Subscribe to stream call unsuccessful");
    });
}</programlisting>

</section>
<section xml:id="_receive_notifications_2">
<title>Receive notifications</title>
<simpara>Once you got WebSocket server location you can now connect to it and
start receiving data change events. You need to define functions that
will handle events on WebSocket. In order to process incoming events
from OpenDaylight you need to provide a function that will handle
<emphasis>onmessage</emphasis> events. The function must have one parameter that represents
the received event object. The event data will be stored in <emphasis>event.data</emphasis>.
The data will be in an XML format that you can then easily parse using
jQuery.</simpara>
<programlisting language="javascript" linenumbering="unnumbered">function listenToNotifications(socketLocation) {
    try {
        var notificatinSocket = new WebSocket(socketLocation);

        notificatinSocket.onmessage = function (event) {
            // we process our received event here
            console.log('Received toaster data change event.');
            $($.parseXML(event.data)).find('data-change-event').each(
                function (index) {
                    var operation = $(this).find('operation').text();
                    if (operation == 'updated') {
                        // toaster status was updated so we call function that gets the value of toasterStatus leaf
                        updateToasterStatus();
                        return false;
                    }
                }
            );
        }
        notificatinSocket.onerror = function (error) {
            console.log("Socket error: " + error);
        }
        notificatinSocket.onopen = function (event) {
            console.log("Socket connection opened.");
        }
        notificatinSocket.onclose = function (event) {
            console.log("Socket connection closed.");
        }
        // if there is a problem on socket creation we get exception (i.e. when socket address is incorrect)
    } catch(e) {
        alert("Error when creating WebSocket" + e );
    }
}</programlisting>

<simpara>The <emphasis>updateToasterStatus()</emphasis> function represents function that calls
<emphasis>GET</emphasis> on the path that was modified and sets toaster status in some web
page element according to received data. After the WebSocket connection
has been established you can test events by calling make-toast RPC via
RESTCONF.</simpara>
<note>
<simpara>for more information about WebSockets in JavaScript visit
<link xlink:href="https://developer.mozilla.org/en-US/docs/WebSockets/Writing_WebSocket_client_applications">Writing
WebSocket client applications</link></simpara>
</note>

</section>
</section>
</section>
<section xml:id="_config_subsystem">
<title>Config Subsystem</title>
<section xml:id="_overview_9">
<title>Overview</title>
<simpara>The Controller configuration operation has three stages:</simpara>
<itemizedlist>
<listitem>
<simpara>First, a Proposed configuration is created. Its target is to replace the old configuration.</simpara>
</listitem>
<listitem>
<simpara>Second, the Proposed configuration is validated, and then committed. If it passes validation successfully, the Proposed configuration state will be changed to Validated.</simpara>
</listitem>
<listitem>
<simpara>Finally, a Validated configuration can be Committed, and the affected modules can be reconfigured.</simpara>
</listitem>
</itemizedlist>

<simpara>In fact, each configuration operation is wrapped in a transaction. Once a transaction is created, it can be configured, that is to say, a user can abort the transaction during this stage. After the transaction configuration is done, it is committed to the validation stage. In this stage, the validation procedures are invoked.
 If one or more validations fail, the transaction can be reconfigured. Upon success, the second phase commit is invoked.
 If this commit is successful, the transaction enters the last stage, committed. After that, the desired modules are reconfigured. If the second phase commit fails, it means that the transaction is unhealthy - basically, a new configuration instance creation failed, and the application can be in an inconsistent state.</simpara>
<figure>
<title>Configuration states</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/configuration.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>configuration</phrase></textobject>
  </mediaobject>
</figure>

<figure>
<title>Transaction states</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/Transaction.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Transaction</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_validation">
<title>Validation</title>
<simpara>To secure the consistency and safety of the new configuration and to avoid conflicts, the configuration validation process is necessary.
Usually, validation checks the input parameters of a new configuration, and mostly verifies module-specific relationships.
The validation procedure results in a decision on whether the proposed configuration is healthy.</simpara>
</section>
<section xml:id="_dependency_resolver">
<title>Dependency resolver</title>
<simpara>Since there can be dependencies between modules, a change in a module configuration can affect the state of other modules. Therefore, we need to verify whether dependencies on other modules can be resolved.
The Dependency Resolver acts in a manner similar to dependency injectors. Basically, a dependency tree is built.</simpara>
</section>
<section xml:id="_apis_and_spis">
<title>APIs and SPIs</title>
<simpara>This section describes configuration system APIs and SPIs.</simpara>
<section xml:id="_spis">
<title>SPIs</title>
<simpara><emphasis role="strong">Module</emphasis> org.opendaylight.controller.config.spi. Module is the common interface for all modules: every module must implement it. The module is designated to hold configuration attributes, validate them, and create instances of service based on the attributes.
This instance must implement the AutoCloseable interface, owing to resources clean up. If the module was created from an already running instance, it contains an old instance of the module. A module can implement multiple services. If the module depends on other modules, setters need to be annotated with @RequireInterface.</simpara>
<simpara><emphasis role="strong">Module creation</emphasis></simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>The module needs to be configured, set with all required attributes.</simpara>
</listitem>
<listitem>
<simpara>The module is then moved to the commit stage for validation. If the validation fails, the module attributes can be reconfigured. Otherwise, a new instance is either created, or an old instance is reconfigured.
A module instance is identified by ModuleIdentifier, consisting of the factory name and instance name.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">ModuleFactory</emphasis> org.opendaylight.controller.config.spi. The ModuleFactory interface must be implemented by each module factory.<?asciidoc-br?>
A module factory can create a new module instance in two ways:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>From an existing module instance</simpara>
</listitem>
<listitem>
<simpara>An entirely new instance<?asciidoc-br?>
ModuleFactory can also return default modules, useful for populating registry with already existing configurations.
A module factory implementation must have a globally unique name.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_apis">
<title>APIs</title>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>ConfigRegistry</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Represents functionality provided by a configuration transaction (create, destroy module, validate, or abort transaction).</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>ConfigTransactionController</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Represents functionality for manipulating with configuration transactions (begin, commit config).</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>RuntimeBeanRegistratorAwareConfiBean</simpara></entry>
        
        <entry align="left" valign="top"><simpara>The module implementing this interface will receive RuntimeBeanRegistrator before getInstance is invoked.</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_runtime_apis">
<title>Runtime APIs</title>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>RuntimeBean</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Common interface for all runtime beans</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>RootRuntimeBeanRegistrator</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Represents functionality for root runtime bean registration, which subsequently allows hierarchical registrations</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>HierarchicalRuntimeBeanRegistration</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Represents functionality for runtime bean registration and unreregistration from hierarchy</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_jmx_apis">
<title>JMX APIs</title>
<simpara>JMX API is purposed as a transition between the Client API and the JMX platform.<?asciidoc-br?></simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>ConfigTransactionControllerMXBean</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Extends ConfigTransactionController, executed by Jolokia clients on configuration transaction.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>ConfigRegistryMXBean</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Represents entry point of configuration management for MXBeans.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Object names</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Object Name is the pattern used in JMX to locate JMX beans. It consists of domain and key properties (at least one key-value pair). Domain is defined as "org.opendaylight.controller". The only mandatory property is "type".</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_use_case_scenarios">
<title>Use case scenarios</title>
<simpara>A few samples of successful and unsuccessful transaction scenarios follow:<?asciidoc-br?></simpara>
<simpara><emphasis role="strong">Successful commit scenario</emphasis></simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>The user creates a transaction calling creteTransaction() method on ConfigRegistry.</simpara>
</listitem>
<listitem>
<simpara>ConfigRegisty creates a transaction controller, and registers the transaction as a new bean.</simpara>
</listitem>
<listitem>
<simpara>Runtime configurations are copied to the transaction. The user can create modules and set their attributes.</simpara>
</listitem>
<listitem>
<simpara>The configuration transaction is to be committed.</simpara>
</listitem>
<listitem>
<simpara>The validation process is performed.</simpara>
</listitem>
<listitem>
<simpara>After successful validation, the second phase commit begins.</simpara>
</listitem>
<listitem>
<simpara>Modules proposed to be destroyed are destroyed, and their service instances are closed.</simpara>
</listitem>
<listitem>
<simpara>Runtime beans are set to registrator.</simpara>
</listitem>
<listitem>
<simpara>The transaction controller invokes the method getInstance on each module.</simpara>
</listitem>
<listitem>
<simpara>The transaction is committed, and resources are either closed or released.</simpara>
</listitem>
</orderedlist>

<simpara><emphasis role="strong">Validation failure scenario</emphasis><?asciidoc-br?>
The transaction is the same as the previous case until the validation process.<?asciidoc-br?></simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>If validation fails, (that is to day, illegal input attributes values or dependency resolver failure), the validationException is thrown and exposed to the user.</simpara>
</listitem>
<listitem>
<simpara>The user can decide to reconfigure the transaction and commit again, or abort the current transaction.</simpara>
</listitem>
<listitem>
<simpara>On aborted transactions, TransactionController and JMXRegistrator are properly closed.</simpara>
</listitem>
<listitem>
<simpara>Unregistration event is sent to ConfigRegistry.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_default_module_instances">
<title>Default module instances</title>
<simpara>The configuration subsystem provides a way for modules to create default instances. A default instance is an instance of a module, that is created at the module bundle start-up (module becomes visible for
configuration subsystem, for example, its bundle is activated in the OSGi environment). By default, no default instances are produced.</simpara>
<simpara>The default instance does not differ from instances created later in the module life-cycle. The only difference is that the configuration for the default instance cannot be provided by the configuration subsystem.
The module has to acquire the configuration for these instances on its own. It can be acquired from, for example, environment variables.
After the creation of a default instance, it acts as a regular instance and fully participates in the configuration subsystem (It can be reconfigured or deleted in following transactions.).</simpara>
</section>
</section>
</section>
</chapter>
<chapter xml:id="_didm_developer_guide">
<title>DIDM Developer Guide</title>
<section xml:id="_overview_10">
<title>Overview</title>
<simpara>The Device Identification and Driver Management (DIDM) project addresses the
need to provide device-specific functionality. Device-specific functionality is
code that performs a feature, and the code is knowledgeable of the capability
and limitations of the device. For example, configuring VLANs and adjusting
FlowMods are features, and there may be different implementations for different
device types. Device-specific functionality is implemented as Device Drivers.
Device Drivers need to be associated with the devices they can be used with. To
determine this association requires the ability to identify the device type.</simpara>
</section>
<section xml:id="_didm_architecture">
<title>DIDM Architecture</title>
<simpara>The DIDM project creates the infrastructure to support the following functions:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Discovery</emphasis> - Determination that a device exists in the controller
management domain and connectivity to the device can be established. For
devices that support the OpenFlow protocol, the existing discovery
mechanism in OpenDaylight suffices. Devices that do not support OpenFlow
will be discovered through manual means such as the operator entering
device information via GUI or REST API.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Identification</emphasis> – Determination of the device type.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Driver Registration</emphasis> – Registration of Device Drivers as routed RPCs.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Synchronization</emphasis> – Collection of device information, device configuration,
and link (connection) information.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Data Models for Common Features</emphasis> – Data models will be defined to
perform common features such as VLAN configuration. For example,
applications can configure a VLAN by writing the VLAN data to the data store
as specified by the common data model.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">RPCs for Common Features</emphasis> – Configuring VLANs and adjusting
FlowMods are example of features. RPCs will be defined that specify the
APIs for these features. Drivers implement features for specific devices and
support the APIs defined by the RPCs. There may be different Driver
implementations for different device types.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_key_apis_and_interfaces_4">
<title>Key APIs and Interfaces</title>
<simpara>The Beryllium release includes a flow mod driver for the HP 3800.
This driver adjusts the flows and push the same to the device.
This API takes the flow to be adjusted as input and displays the adjusted flow as output in the REST output container.
Here is the REST API to adjust and push flows to HP 3800 device:</simpara>
<screen>http://&lt;CONTROLLER-IP:8181&gt;/restconf/operations/openflow-feature:adjust-flow</screen>

<simpara>Here is an example of an ARP flow and how it gets adjusted and pushed to device HP3800:</simpara>
<formalpara>
<title>adjust-flow input</title>
<para>
<screen>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
&lt;input xmlns="urn:opendaylight:params:xml:ns:yang:didm:drivers:openflow" xmlns:opendaylight-inventory="urn:opendaylight:inventory"&gt;
  &lt;node&gt;/opendaylight-inventory:nodes/opendaylight-inventory:node[opendaylight-inventory:id='openflow:673249119553088']&lt;/node&gt;
    &lt;flow&gt;
      &lt;match&gt;
        &lt;ethernet-match&gt;
            &lt;ethernet-type&gt;
                &lt;type&gt;2054&lt;/type&gt;
            &lt;/ethernet-type&gt;
        &lt;/ethernet-match&gt;
      &lt;/match&gt;
      &lt;flags&gt;SEND_FLOW_REM&lt;/flags&gt;
      &lt;priority&gt;0&lt;/priority&gt;
      &lt;flow-name&gt;ARP_FLOW&lt;/flow-name&gt;
      &lt;instructions&gt;
        &lt;instruction&gt;
            &lt;order&gt;0&lt;/order&gt;
            &lt;apply-actions&gt;
                &lt;action&gt;
                    &lt;order&gt;0&lt;/order&gt;
                    &lt;output-action&gt;
                        &lt;output-node-connector&gt;CONTROLLER&lt;/output-node-connector&gt;
                        &lt;max-length&gt;65535&lt;/max-length&gt;
                    &lt;/output-action&gt;
                &lt;/action&gt;
                &lt;action&gt;
                    &lt;order&gt;1&lt;/order&gt;
                    &lt;output-action&gt;
                        &lt;output-node-connector&gt;NORMAL&lt;/output-node-connector&gt;
                        &lt;max-length&gt;65535&lt;/max-length&gt;
                    &lt;/output-action&gt;
                &lt;/action&gt;
            &lt;/apply-actions&gt;
        &lt;/instruction&gt;
      &lt;/instructions&gt;
      &lt;idle-timeout&gt;180&lt;/idle-timeout&gt;
      &lt;hard-timeout&gt;1800&lt;/hard-timeout&gt;
      &lt;cookie&gt;10&lt;/cookie&gt;
    &lt;/flow&gt;
&lt;/input&gt;</screen>
</para>
</formalpara>

<simpara>In the output, you can see that the table ID has been identified for the given
flow and two flow mods are created as a result of adjustment. The first one is
to catch ARP packets in Hardware table 100 with an action to goto table 200.
The second flow mod is in table 200 with actions: output normal and output
controller.</simpara>
<formalpara>
<title>adjust-flow output</title>
<para>
<screen>{
  "output": {
    "flow": [
      {
        "idle-timeout": 180,
        "instructions": {
          "instruction": [
            {
              "order": 0,
              "apply-actions": {
                "action": [
                  {
                    "order": 1,
                    "output-action": {
                      "output-node-connector": "NORMAL",
                      "max-length": 65535
                    }
                  },
                  {
                    "order": 0,
                    "output-action": {
                      "output-node-connector": "CONTROLLER",
                      "max-length": 65535
                    }
                  }
                ]
              }
            }
          ]
        },
        "strict": false,
        "table_id": 200,
        "flags": "SEND_FLOW_REM",
        "cookie": 10,
        "hard-timeout": 1800,
        "match": {
          "ethernet-match": {
            "ethernet-type": {
              "type": 2054
            }
          }
        },
        "flow-name": "ARP_FLOW",
        "priority": 0
      },
      {
        "idle-timeout": 180,
        "instructions": {
          "instruction": [
            {
              "order": 0,
              "go-to-table": {
                "table_id": 200
              }
            }
          ]
        },
        "strict": false,
        "table_id": 100,
        "flags": "SEND_FLOW_REM",
        "cookie": 10,
        "hard-timeout": 1800,
        "match": {},
        "flow-name": "ARP_FLOW",
        "priority": 0
      }
    ]
  }
}</screen>
</para>
</formalpara>

</section>
<section xml:id="_api_reference_documentation_4">
<title>API Reference Documentation</title>
<simpara>Go to <link xlink:href="http://${controller-ip}:8181/apidoc/explorer/index.html">http://${controller-ip}:8181/apidoc/explorer/index.html</link>, and look under DIDM section
to see all the available REST calls and tables</simpara>
</section>
</chapter>
<chapter xml:id="_dlux">
<title>DLUX</title>
<section xml:id="_setup_and_run">
<title>Setup and Run</title>
<section xml:id="_required_technology_stack">
<title>Required Technology Stack</title>
<itemizedlist>
<listitem>
<simpara>AngularJS (JavaScript client-side framework, <link xlink:href="http://www.angularjs.org">http://www.angularjs.org</link> )</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_run_dlux">
<title>Run DLUX</title>
<simpara>To turn on the DLUX UI, install DLUX core feature via running following command on the Karaf console -</simpara>

<literallayout class="monospaced">feature:install odl-dlux-core</literallayout>


<simpara>The above command will install odl-restconf and DLUX topology application internally, along with core DLUX components.
Once this feature is successfully installed, access the UI at <link xlink:href="http://localhost:8181/index.html">http://localhost:8181/index.html</link>.
The default credentials for login are admin/admin.</simpara>
<simpara>All the applications in DLUX are Karaf features. A user can install other dlux applications such as node and yang-ui from Karaf
console using commands such as -</simpara>
<screen>$ feature:install odl-dlux-node

$ feature:install odl-dlux-yangui</screen>

</section>
</section>
<section xml:id="_dlux_modules">
<title>DLUX Modules</title>
<simpara>DLUX modules are the individual features such as nodes and topology. Each module has a defined structure and you can find
all existing modules at <link xlink:href="https://github.com/opendaylight/dlux/tree/stable/lithium/modules">https://github.com/opendaylight/dlux/tree/stable/lithium/modules</link>.</simpara>
<section xml:id="_module_structure">
<title>Module Structure</title>
<itemizedlist>
<listitem>
<simpara>module_folder</simpara>
<itemizedlist>
<listitem>
<simpara>&lt;module_name&gt;.module.js</simpara>
</listitem>
<listitem>
<simpara>&lt;module_name&gt;.controller.js</simpara>
</listitem>
<listitem>
<simpara>&lt;module_name&gt;.services.js</simpara>
</listitem>
<listitem>
<simpara>&lt;module_name&gt;.directives.js</simpara>
</listitem>
<listitem>
<simpara>&lt;module_name&gt;.filter.js</simpara>
</listitem>
<listitem>
<simpara>index.tpl.html</simpara>
</listitem>
<listitem>
<simpara>&lt;a_stylesheet&gt;.css</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_create_new_module">
<title>Create New Module</title>
<section xml:id="_define_the_module">
<title>Define the module</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create an empty maven project and create your module folder under src/main/resources.</simpara>
</listitem>
<listitem>
<simpara>Create an empty file with pattern &lt;module_name&gt;.module.js.</simpara>
</listitem>
<listitem>
<simpara>Next, you need to surround the angular module with a define function. This allows RequireJs to see our module.js files.
The first argument is an array which contains all the module&#8217;s dependencies. The second argument is a callback function,
whose body contain the AngularJS code base. The function parameters correspond with the order of dependencies. Each dependency is injected into a parameter, if it is provided.</simpara>
</listitem>
<listitem>
<simpara>Finally, you will return the angular module to be able to inject it as a parameter in others modules.</simpara>
</listitem>
</orderedlist>

<simpara>For each new module, you must have at least these two dependencies :</simpara>
<itemizedlist>
<listitem>
<simpara>angularAMD : It&#8217;s a wrapper around AngularJS to provide an AMD (Asynchronous Module Definition) support, which is used by RequireJs. For more information see the <link xlink:href="https://github.com/amdjs/amdjs-api/blob/master/AMD.md">AMD documentation</link>.</simpara>
</listitem>
<listitem>
<simpara>app/core/core.services : This one is mandatory, if you want to add content in the navigation menu, the left bar or the top bar.</simpara>
</listitem>
</itemizedlist>

<simpara>The following are not mandatory, but very often used.</simpara>
<itemizedlist>
<listitem>
<simpara>angular-ui-router : A library to provide URL routing.</simpara>
</listitem>
<listitem>
<simpara>routingConfig : To set the level access to a page.</simpara>
</listitem>
</itemizedlist>

<simpara>Your module.js file might look like this:</simpara>

<literallayout class="monospaced">define(['angularAMD','app/routingConfig', 'angular-ui-router','app/core/core.services'], function(ng) {
   var module = angular.module('app.a_module', ['ui.router.state', 'app.core']);
   // module configuration
   module.config(function() {
       [...]
   });
  return module;
});</literallayout>


</section>
<section xml:id="_set_the_register_function">
<title>Set the register function</title>
<simpara>AngularJS allows lazy registration of a module&#8217;s components such as controller, factory etc. Once you will install your application,
DLUX will load your module javascript, but not your angular component during bootstrap phase. You have to register your angular components
to make sure they are available at the runtime.</simpara>
<simpara>Here is how to register your module&#8217;s component for lazy initialization -</simpara>

<literallayout class="monospaced">module.config(function($compileProvider, $controllerProvider, $provide) {
   module.register = {
     controller : $controllerProvider.register,
     directive : $compileProvider.directive,
     factory : $provide.factory,
     service : $provide.service
   };
});</literallayout>


</section>
<section xml:id="_set_the_route">
<title>Set the route</title>
<simpara>The next step is to set up the route for your module. This part is also done in the configuration method of the module. We have to add <emphasis role="strong">$stateProvider</emphasis> as a parameter.</simpara>

<literallayout class="monospaced">module.config(function($stateProvider) {
   var access = routingConfig.accessLevels;
   $stateProvider.state('main.module', {
     url: 'module',
     views : {
       'content' : {
         templateUrl: 'src/app/module/module.tpl.html',
         controller: 'ModuleCtrl'
       }
     }
   });
});</literallayout>


</section>
<section xml:id="_adding_element_to_the_navigation_menu">
<title>Adding element to the navigation menu</title>
<simpara>To be able to add item to the navigation menu, the module requires the <emphasis role="strong">NavHelperProvider</emphasis> parameter in the configuration method.
<emphasis role="strong">addToMenu</emphasis> method in <emphasis role="strong">NavMenuHelper</emphasis> helper allows an item  addition to the menu.</simpara>

<literallayout class="monospaced">var module = angular.module('app.a_module', ['app.core']);
module.config(function(NavMenuHelper) {
    NavMenuHelper.addToMenu('myFirstModule', {
        "link" : "#/module/index",
        "active" : "module",
        "title" : "My First Module",
        "icon" : "icon-sitemap",
        "page" : {
            "title" : "My First Module",
            "description" : "My first module"
        }
    });
});</literallayout>


<simpara>The first parameter is an ID that refers to the level of your menu and the second is a object. For now, The ID parameter supports two levels of depth.
If your ID looks like <emphasis>rootNode.childNode</emphasis>, the helper will look for a node named <emphasis>rootNode</emphasis> and it will append the <emphasis>childNode</emphasis> to it. If the root node doesn&#8217;t exist, it will create it.</simpara>
</section>
<section xml:id="_link_the_angularjs_module_s_controller_file">
<title>Link the AngularJS module&#8217;s controller file</title>
<simpara>To include the module&#8217;s controller file, you can use the NavHelperProvider. It contains a method that will load the given file.</simpara>

<literallayout class="monospaced">[...]
   NavHelperProvider.addControllerUrl('&lt;path_to_module_folder&gt;/&lt;module_name&gt;.controller');</literallayout>


<simpara>This completes your module.js file.</simpara>
</section>
</section>
<section xml:id="_create_the_controller_factory_directive_etc">
<title>Create the controller, factory, directive, etc</title>
<simpara>Creating the controller and other components is similar to the module.</simpara>
<itemizedlist>
<listitem>
<simpara>First, add the define method.</simpara>
</listitem>
<listitem>
<simpara>Second, add the relative path to the module definition.</simpara>
</listitem>
<listitem>
<simpara>Last, create your methods as you usually do it with AngularJS.</simpara>
</listitem>
</itemizedlist>

<simpara>For example -</simpara>

<literallayout class="monospaced">define(['&lt;relative_path_to_module&gt;/&lt;module_name&gt;.module'], function(module) {
   module.register.controller('ModuleCtrl', function($rootScope, $scope) {
   });
});</literallayout>


</section>
</section>
<section xml:id="_add_new_application_using_dlux_modularity">
<title>Add new application using DLUX modularity</title>
<simpara>DLUX works as a Karaf based UI platform, where you can create a new Karaf feature of your UI component and install that UI applications in DLUX using blueprint.
This page will help you to create and load a new application for DLUX. You don&#8217;t have to add new module in DLUX repository.</simpara>
<section xml:id="_add_a_new_osgi_blueprint_bundle">
<title>Add a new OSGi blueprint bundle</title>
<simpara>The OSGi Blueprint Container specification allows us to use dependency injection in our OSGi environment. Each DLUX application module registers itself via blueprint configuration. Each application will have its own blueprint.xml to place its configuration.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a maven project to place blueprint configuration. For reference, take a look at topology bundle, present at <link xlink:href="https://github.com/opendaylight/dlux/tree/stable/lithium/bundles/topology">https://github.com/opendaylight/dlux/tree/stable/lithium/bundles/topology</link>. All the existing DLUX modules' configurations are available under bundles directory of DLUX code.</simpara>
</listitem>
<listitem>
<simpara>In pom.xml, you have to add a maven plugin to unpack your module code under generated-resources of this project. For reference, you can check pom.xml of dlux/bundles/topology at <link xlink:href="https://github.com/opendaylight/dlux/tree/stable/lithium/bundles/topology">https://github.com/opendaylight/dlux/tree/stable/lithium/bundles/topology</link>. Your bundle will eventually get deployed in Karaf as feature, so your bundle should contain all your module code. If you want to combine module and bundle project, that should not be an issue either.</simpara>
</listitem>
<listitem>
<simpara>Create a blueprint.xml configuration file under src/main/resources/OSGI-INF/blueprint. Below is the content of the blueprint.xml taken from topology bundles&#8217;s blueprint.xml. Any new application should create a blueprint.xml in following format -</simpara>
</listitem>
</orderedlist>

<screen>&lt;blueprint xmlns="http://www.osgi.org/xmlns/blueprint/v1.0.0"&gt;
    &lt;reference id="httpService" availability="mandatory" activation="eager" interface="org.osgi.service.http.HttpService"/&gt;
    &lt;reference id="loader" availability="mandatory" activation="eager" interface="org.opendaylight.dlux.loader.DluxModuleLoader"/&gt;

    &lt;bean id="bundle" init-method="initialize" destroy-method="clean" class="org.opendaylight.dlux.loader.DluxModule"&gt;
      &lt;property name="httpService" ref="httpService"/&gt;
      &lt;property name="loader" ref="loader"/&gt;
      &lt;property name="moduleName" value="topology "/&gt;
      &lt;property name="url" value="/src/app/topology"/&gt;
      &lt;property name="directory" value="/topology"/&gt;
      &lt;property name="requireJs" value="app/topology/topology.module"/&gt;
      &lt;property name="angularJs" value="app.topology"/&gt;
      &lt;property name="cssDependencies"&gt;
          &lt;list&gt;
              &lt;value&gt;http://yui.yahooapis.com/3.18.1/build/cssreset/cssreset-min.css&lt;/value&gt;
              &lt;value&gt;src/app/topology/topology-custom.css&lt;/value&gt;
          &lt;/list&gt;
      &lt;/property&gt;
    &lt;/bean&gt;
&lt;/blueprint&gt;</screen>

<simpara>In above configuration, there are two references with id httpService and loader. These two beans will already be initialized by dlux-core, so any new application can use them. Without these two bean references, a new application will not be able to register.</simpara>
<simpara>Next is the initialization of your application bean, which will be an instance of class org.opendaylight.dlux.loader.DluxModule. There are 5 properties that you should provide in this bean besides the references of httpService and loader. Lets talk about those bean properties in little more detail.</simpara>
<simpara><emphasis role="strong">moduleName</emphasis> : Name of your module. This name should be unique in DLUX.</simpara>
<simpara><emphasis role="strong">url</emphasis>: This is the url via which RequireJS in DLUX will try to load your module JS/HTML files. Also, this is the url that browser will use to load the static HTML, JS or CSS files. RequireJS in DLUX has a base path of <emphasis role="strong">src</emphasis>, so all the url should start with /src so RequireJS and the browser can correctly find the files.</simpara>
<simpara><emphasis role="strong">directory</emphasis>: In your bundle&#8217;s pom.xml, you unpack your module code. This is the directory where your actual static files will reside. The above mentioned url is registered with httpService, so when browser makes a call to that url, it will be redirected to the directory mentioned here. In the above example, all the topology files are present under /topology directory and the browser/RequireJS can access those files with uri /src/app/topology.</simpara>
<simpara><emphasis role="strong">requireJS</emphasis>: This is the path to your RequireJS module. If you notice closely, you will see the initial path of RequireJS app/topology in the above example matches with the last part of url. This path will be be used by RequireJS. As mentioned above, we have kept <emphasis role="strong">src</emphasis> as base path in RequireJS, that is the exact reason that url start with /src.</simpara>
<simpara><emphasis role="strong">angularJS</emphasis>: name of your AngularJS module.</simpara>
<simpara><emphasis role="strong">cssDependencies</emphasis>: If the application has any external/internal css dependencies, then those can be added here. If you create your own css files, just point to those css files here. Use the url path that you mentioned above, so the browser can find your css file.</simpara>
<simpara>OSGi understands blueprint.xml, once you will deploy your bundle in karaf (or you can create a new feature for your application), karaf will read your blueprint.xml and it will try to register your application with dlux. Once successful, if you refresh your dlux UI, you will see your application in left hand navigation bar of dlux.</simpara>
</section>
</section>
<section xml:id="_yang_utils">
<title>Yang Utils</title>
<simpara>Yang Utils are used by UI to perform all CRUD operations. All of these utilities are present in yangutils.services.js file. It has following AngularJS factories -</simpara>
<itemizedlist>
<title>Factories</title>
<listitem>
<simpara><emphasis role="strong">arrayUtils</emphasis> – defines functions for working with arrays.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">pathUtils</emphasis> – defines functions for working with xpath (paths to APIs and subAPIs). It divides xpath string to array of elements, so this array can be later used for search functions.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">syncFact</emphasis> – provides synchronization between requests to and from OpenDaylight when it’s needed.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">custFunct</emphasis> – it is linked with apiConnector.createCustomFunctionalityApis in yangui controller in yangui.controller.js. That function makes it possible to create some custom function called by the click on button in index.tpl.html. All custom functions are stored in array and linked to specific subAPI. When particular subAPI is expanded and clicked, its  inputs (linked root node with its child nodes) are displayed in the bottom part of the page and its buttons with custom functionality are displayed also.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">reqBuilder</emphasis> – Builds object in JSON format from input fields of the UI page.  <emphasis role="strong">Show Preview</emphasis> button on Yang UI use this builder. This request is sent to OpenDaylight when button PUT or POST is clicked.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">yinParser</emphasis> – factory for reading .xml files of yang models and creating object hierarchy. Every statement from yang is represented by a node.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">nodeWrapper</emphasis> – adds functions to objects in tree hierarchy created with yinParser. These functions provide functionality for every type of node.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">apiConnector</emphasis> – the main functionality is filling the main structures and linking them. Structure of APIs and subAPIs which is two level array - first level is filled by main APIs, second level is filled by others sub APIs. Second main structure is array of root nodes, which are objects including root node and its children nodes. Linking these two structures is creating links between every subAPI (second level of APIs array) and its root node, which must be displayed like inputs when subAPI is expanded.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">yangUtils</emphasis> – some top level functions which are used by yangui controller for creating the main structures.</simpara>
</listitem>
</itemizedlist>

</section>
</chapter>
<chapter xml:id="_iotdm_developer_guide">
<title>IoTDM Developer Guide</title>
<section xml:id="_overview_11">
<title>Overview</title>
<simpara>The Internet of Things Data Management (IoTDM) on OpenDaylight
project is about developing a data-centric middleware
that will act as a oneM2M compliant IoT Data Broker and enable
authorized applications to retrieve IoT data uploaded by any
device. The OpenDaylight platform is used to implement the oneM2M
data store which models a hierarchical containment tree, where each
node in the tree represents an oneM2M resource. Typically, IoT
devices and applications interact with the resource tree over
standard protocols such as CoAP, MQTT, and HTTP.
Initially, the oneM2M resource tree is used by applications to
retrieve data. Possible applications are inventory or device
management systems or big data analytic systems designed to
make sense of the collected data. But, at some point,
applications will need to configure the devices. Features and
tools will have to be provided to enable configuration of the
devices based on applications responding to user input, network
conditions, or some set of programmable rules or policies possibly
triggered by the receipt of data collected from the devices.
The OpenDaylight platform, with its rich unique cross-section of SDN
capabilities, NFV, and now IoT device and application management,
can be bundled with a targeted set of features and deployed
anywhere in the network to give the network service provider
ultimate control. Depending on the use case, the OpenDaylight IoT
platform can be configured with only IoT data collection capabilities
where it is deployed near the IoT devices and its footprint needs to be
small, or it can be configured to run as a highly scaled up and
out distributed cluster with IoT, SDN and NFV functions enabled
and deployed in a high traffic data center.</simpara>
</section>
<section xml:id="_onem2m_architecture">
<title>oneM2M Architecture</title>
<simpara>The architecture provides a framework that enables the support of
the oneM2M resource containment tree. The onem2m-core implements
the MDSAL RPCs defined in the onem2m-api YANG files. These RPCs
enable oneM2M resources to be created, read, updated, and
deleted (CRUD), and also enables the management of subscriptions.
When resources are CRUDed, the onem2m-notifier issues oneM2M
notification events to interested subscribers. TS0001: oneM2M
Functional Architecture and TS0004: oneM2M Service Layer Protocol
are great reference documents to learn details of oneM2M resource
types, message flow, formats, and CRUD/N semantics.  Both of these
specifications can be found at
<link xlink:href="http://onem2m.org/technical/published-documents">http://onem2m.org/technical/published-documents</link></simpara>
<simpara>The oneM2M resource tree is modeled in YANG and essentially is a
meta-model for the tree.  The oneM2M wire protocols allow the
resource tree to be constructed via HTTP or CoAP messages that
populate nodes in the tree with resource specific attributes.
Each oneM2M resource type has semantic behaviour associated with
it.  For example: a container resource has attributes which
control quotas on how many and how big the collection of data or
content instance objects that can exist below it in the tree.
Depending on the resource type, the oneM2M core software
implements and enforces the resource type specific rules to
ensure a well-behaved resource tree.</simpara>
<simpara>The resource tree can be simultaneously accessed by many
concurrent applications wishing to manage or access the tree,
and also many devices can be reporting in new data or sensor
readings into their appropriate place in the tree.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_5">
<title>Key APIs and Interfaces</title>
<simpara>The API&#8217;s to access the oneM2M datastore are well documented
in TS0004 (referred above) found on onem2m.org</simpara>
<simpara>RESTCONF is available too but generally HTTP and CoAP are used to
access the oneM2M data tree.</simpara>
</section>
</chapter>
<chapter xml:id="_l2switch_developer_guide">
<title>L2Switch Developer Guide</title>
<section xml:id="_overview_12">
<title>Overview</title>
<simpara>The L2Switch project provides Layer2 switch functionality.</simpara>
</section>
<section xml:id="_l2switch_architecture">
<title>L2Switch Architecture</title>
<itemizedlist>
<listitem>
<simpara>Packet Handler</simpara>
<itemizedlist>
<listitem>
<simpara>Decodes the packets coming to the controller and dispatches them appropriately</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Loop Remover</simpara>
<itemizedlist>
<listitem>
<simpara>Removes loops in the network</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Arp Handler</simpara>
<itemizedlist>
<listitem>
<simpara>Handles the decoded ARP packets</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Address Tracker</simpara>
<itemizedlist>
<listitem>
<simpara>Learns the Addresses (MAC and IP) of entities in the network</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Host Tracker</simpara>
<itemizedlist>
<listitem>
<simpara>Tracks the locations of hosts in the network</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>L2Switch Main</simpara>
<itemizedlist>
<listitem>
<simpara>Installs flows on each switch based on network traffic</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_key_apis_and_interfaces_6">
<title>Key APIs and Interfaces</title>
<itemizedlist>
<listitem>
<simpara>Packet Handler</simpara>
</listitem>
<listitem>
<simpara>Loop Remover</simpara>
</listitem>
<listitem>
<simpara>Arp Handler</simpara>
</listitem>
<listitem>
<simpara>Address Tracker</simpara>
</listitem>
<listitem>
<simpara>Host Tracker</simpara>
</listitem>
<listitem>
<simpara>L2Switch Main</simpara>
</listitem>
</itemizedlist>

<section xml:id="_packet_dispatcher">
<title>Packet Dispatcher</title>
<section xml:id="_classes">
<title>Classes</title>
<itemizedlist>
<listitem>
<simpara>AbstractPacketDecoder</simpara>
<itemizedlist>
<listitem>
<simpara>Defines the methods that all decoders must implement</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>EthernetDecoder</simpara>
<itemizedlist>
<listitem>
<simpara>The base decoder which decodes the packet into an Ethernet packet</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>ArpDecoder, Ipv4Decoder, Ipv6Decoder</simpara>
<itemizedlist>
<listitem>
<simpara>Decodes Ethernet packets into the either an ARP or IPv4 or IPv6 packet</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_further_development">
<title>Further development</title>
<simpara>There is a need for more decoders.  A developer can write</simpara>
<itemizedlist>
<listitem>
<simpara>A decoder for another EtherType, i.e. LLDP.</simpara>
</listitem>
<listitem>
<simpara>A higher layer decoder for the body of the IPv4 packet or IPv6 packet, i.e. TCP and UDP.</simpara>
</listitem>
</itemizedlist>

<simpara>How to write a new decoder</simpara>
<itemizedlist>
<listitem>
<simpara>extends AbstractDecoder&lt;A, B&gt;</simpara>
<itemizedlist>
<listitem>
<simpara>A refers to the notification that the new decoder consumes</simpara>
</listitem>
<listitem>
<simpara>B refers to the notification that the new decoder produces</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>implements xPacketListener</simpara>
<itemizedlist>
<listitem>
<simpara>The new decoder must specify which notification it is listening to</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>canDecode method</simpara>
<itemizedlist>
<listitem>
<simpara>This method should examine the consumed notification to see whether the new decoder can decode the contents of the packet</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>decode method</simpara>
<itemizedlist>
<listitem>
<simpara>This method does the actual decoding of the packet</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_loop_remover">
<title>Loop Remover</title>
<section xml:id="_classes_2">
<title>Classes</title>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">LoopRemoverModule</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Reads config subsystem value for <emphasis>is-install-lldp-flow</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>If <emphasis>is-install-lldp-flow</emphasis> is true, then an <emphasis role="strong">InitialFlowWriter</emphasis> is created</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Creates and initializes the other LoopRemover classes</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">InitialFlowWriter</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-install-lldp-flow</emphasis> is true</simpara>
</listitem>
<listitem>
<simpara>Installs a flow, which forwards all LLDP packets to the controller, on each switch</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">TopologyLinkDataChangeHandler</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Listens to data change events on the Topology tree</simpara>
</listitem>
<listitem>
<simpara>When these changes occur, it waits <emphasis>graph-refresh-delay</emphasis> seconds and then tells <emphasis role="strong">NetworkGraphImpl</emphasis> to update</simpara>
</listitem>
<listitem>
<simpara>Writes an STP (Spanning Tree Protocol) status of "forwarding" or "discarding" to each link in the Topology data tree</simpara>
<itemizedlist>
<listitem>
<simpara>Forwarding links can forward packets.</simpara>
</listitem>
<listitem>
<simpara>Discarding links cannot forward packets.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">NetworkGraphImpl</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Creates a loop-free graph of the network</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_configuration">
<title>Configuration</title>
<itemizedlist>
<listitem>
<simpara>graph-refresh-delay</simpara>
<itemizedlist>
<listitem>
<simpara>Used in TopologyLinkDataChangeHandler</simpara>
</listitem>
<listitem>
<simpara>A higher value has the advantage of doing less graph updates, at the potential cost of losing some packets because the graph didn&#8217;t update immediately.</simpara>
</listitem>
<listitem>
<simpara>A lower value has the advantage of handling network topology changes quicker, at the cost of doing more computation.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>is-install-lldp-flow</simpara>
<itemizedlist>
<listitem>
<simpara>Used in LoopRemoverModule</simpara>
</listitem>
<listitem>
<simpara>"true" means a flow that sends all LLDP packets to the controller will be installed on each switch</simpara>
</listitem>
<listitem>
<simpara>"false" means this flow will not be installed</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>lldp-flow-table-id</simpara>
<itemizedlist>
<listitem>
<simpara>The LLDP flow will be installed on the specified flow table of each switch</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>lldp-flow-priority</simpara>
<itemizedlist>
<listitem>
<simpara>The LLDP flow will be installed with the specified priority</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>lldp-flow-idle-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The LLDP flow will timeout (removed from the switch) if the flow doesn&#8217;t forward a packet for <emphasis>x</emphasis> seconds</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>lldp-flow-hard-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The LLDP flow will timeout (removed from the switch) after <emphasis>x</emphasis> seconds, regardless of how many packets it is forwarding</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_further_development_2">
<title>Further development</title>
<simpara>No suggestions at the moment.</simpara>
</section>
<section xml:id="_validating_changes_to_loop_remover">
<title>Validating changes to Loop Remover</title>
<simpara>STP Status information is added to the Inventory data tree.</simpara>
<itemizedlist>
<listitem>
<simpara>A status of "forwarding" means the link is active and packets are flowing on it.</simpara>
</listitem>
<listitem>
<simpara>A status of "discarding" means the link is inactive and packets are not sent over it.</simpara>
</listitem>
</itemizedlist>

<simpara>The STP status of a link can be checked through a browser or a REST Client.</simpara>

<literallayout class="monospaced">http://10.194.126.91:8080/restconf/operational/opendaylight-inventory:nodes/node/openflow:1/node-connector/openflow:1:2</literallayout>


<simpara>The STP status should still be there after changes are made.</simpara>
</section>
</section>
<section xml:id="_arp_handler">
<title>Arp Handler</title>
<section xml:id="_classes_3">
<title>Classes</title>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">ArpHandlerModule</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Reads config subsystem value for <emphasis>is-proactive-flood-mode</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>If <emphasis>is-proactive-flood-mode</emphasis> is true, then a ProactiveFloodFlowWriter is created</simpara>
</listitem>
<listitem>
<simpara>If <emphasis>is-proactive-flood-mode</emphasis> is false, then an InitialFlowWriter is created</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">ProactiveFloodFlowWriter</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-proactive-flood-mode</emphasis> is true</simpara>
</listitem>
<listitem>
<simpara>Installs a flood flow on each switch.  With this flood flow, a packet that doesn&#8217;t match any other flows will be flooded/broadcast from that switch.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">InitialFlowWriter</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-proactive-flood-mode</emphasis> is false</simpara>
</listitem>
<listitem>
<simpara>Installs a flow, which sends all ARP packets to the controller, on each switch</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">ArpPacketHandler</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-proactive-flood-mode</emphasis> is false</simpara>
</listitem>
<listitem>
<simpara>Handles and processes the controller&#8217;s incoming ARP packets</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">PacketDispatcher</emphasis> to send the ARP packet back into the network</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">PacketDispatcher</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-proactive-flood-mode</emphasis> is false</simpara>
</listitem>
<listitem>
<simpara>Sends packets out to the network</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">InventoryReader</emphasis> to determine which node-connector to a send a packet on</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">InventoryReader</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-proactive-flood-mode</emphasis> is false</simpara>
</listitem>
<listitem>
<simpara>Maintains a list of each switch&#8217;s node-connectors</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_configuration_2">
<title>Configuration</title>
<itemizedlist>
<listitem>
<simpara>is-proactive-flood-mode</simpara>
<itemizedlist>
<listitem>
<simpara>"true" means that flood flows will be installed on each switch.  With this flood flow, each switch will flood a packet that doesn&#8217;t match any other flows.</simpara>
<itemizedlist>
<listitem>
<simpara>Advantage: Fewer packets are sent to the controller because those packets are flooded to the network.</simpara>
</listitem>
<listitem>
<simpara>Disadvantage: A lot of network traffic is generated.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>"false" means the previously mentioned flood flows will not be installed.  Instead an ARP flow will be installed on each switch that sends all ARP packets to the controller.</simpara>
<itemizedlist>
<listitem>
<simpara>Advantage: Less network traffic is generated.</simpara>
</listitem>
<listitem>
<simpara>Disadvantage: The controller handles more packets (ARP requests &amp; replies) and the ARP process takes longer than if there were flood flows.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>flood-flow-table-id</simpara>
<itemizedlist>
<listitem>
<simpara>The flood flow will be installed on the specified flow table of each switch</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>flood-flow-priority</simpara>
<itemizedlist>
<listitem>
<simpara>The flood flow will be installed with the specified priority</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>flood-flow-idle-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The flood flow will timeout (removed from the switch) if the flow doesn&#8217;t forward a packet for <emphasis>x</emphasis> seconds</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>flood-flow-hard-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The flood flow will timeout (removed from the switch) after <emphasis>x</emphasis> seconds, regardless of how many packets it is forwarding</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>arp-flow-table-id</simpara>
<itemizedlist>
<listitem>
<simpara>The ARP flow will be installed on the specified flow table of each switch</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>arp-flow-priority</simpara>
<itemizedlist>
<listitem>
<simpara>The ARP flow will be installed with the specified priority</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>arp-flow-idle-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The ARP flow will timeout (removed from the switch) if the flow doesn&#8217;t forward a packet for <emphasis>x</emphasis> seconds</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>arp-flow-hard-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The ARP flow will timeout (removed from the switch) after <emphasis>arp-flow-hard-timeout</emphasis> seconds, regardless of how many packets it is forwarding</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_further_development_3">
<title>Further development</title>
<simpara>The <emphasis role="strong">ProactiveFloodFlowWriter</emphasis> needs to be improved.  It does have the advantage of having less traffic come to the controller; however, it generates too much network traffic.</simpara>
</section>
</section>
<section xml:id="_address_tracker">
<title>Address Tracker</title>
<section xml:id="_classes_4">
<title>Classes</title>
<itemizedlist>
<listitem>
<simpara>AddressTrackerModule</simpara>
<itemizedlist>
<listitem>
<simpara>Reads config subsystem value for <emphasis>observe-addresses-from</emphasis></simpara>
</listitem>
<listitem>
<simpara>If <emphasis>observe-addresses-from</emphasis> contains "arp", then an AddressObserverUsingArp is created</simpara>
</listitem>
<listitem>
<simpara>If <emphasis>observe-addresses-from</emphasis> contains "ipv4", then an AddressObserverUsingIpv4 is created</simpara>
</listitem>
<listitem>
<simpara>If <emphasis>observe-addresses-from</emphasis> contains "ipv6", then an AddressObserverUsingIpv6 is created</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>AddressObserverUsingArp</simpara>
<itemizedlist>
<listitem>
<simpara>Registers for ARP packet notifications</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">AddressObservationWriter</emphasis> to write address observations from ARP packets</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>AddressObserverUsingIpv4</simpara>
<itemizedlist>
<listitem>
<simpara>Registers for IPv4 packet notifications</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">AddressObservationWriter</emphasis> to write address observations from IPv4 packets</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>AddressObserverUsingIpv6</simpara>
<itemizedlist>
<listitem>
<simpara>Registers for IPv6 packet notifications</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">AddressObservationWriter</emphasis> to write address observations from IPv6 packets</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>AddressObservationWriter</simpara>
<itemizedlist>
<listitem>
<simpara>Writes new Address Observations to the Inventory data tree</simpara>
</listitem>
<listitem>
<simpara>Updates existing Address Observations with updated "last seen" timestamps</simpara>
<itemizedlist>
<listitem>
<simpara>Uses the <emphasis>timestamp-update-intervval</emphasis> configuration variable to determine whether or not to update</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_configuration_3">
<title>Configuration</title>
<itemizedlist>
<listitem>
<simpara>timestamp-update-interval</simpara>
<itemizedlist>
<listitem>
<simpara>A last-seen timestamp is associated with each address.  This last-seen timestamp will only be updated after <emphasis>timestamp-update-interval</emphasis> milliseconds.</simpara>
</listitem>
<listitem>
<simpara>A higher value has the advantage of performing less writes to the database.</simpara>
</listitem>
<listitem>
<simpara>A lower value has the advantage of knowing how fresh an address is.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>observe-addresses-from</simpara>
<itemizedlist>
<listitem>
<simpara>IP and MAC addresses can be observed/learned from ARP, IPv4, and IPv6 packets.  Set which packets to make these observations from.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_further_development_4">
<title>Further development</title>
<simpara>Further improvements can be made to the <emphasis role="strong">AddressObservationWriter</emphasis> so that it (1) doesn&#8217;t make any unnecessary writes to the DB and
(2) is optimized for multi-threaded environments.</simpara>
</section>
<section xml:id="_validating_changes_to_address_tracker">
<title>Validating changes to Address Tracker</title>
<simpara>Address Observations are added to the Inventory data tree.</simpara>
<simpara>The Address Observations on a Node Connector can be checked through a browser or a REST Client.</simpara>

<literallayout class="monospaced">http://10.194.126.91:8080/restconf/operational/opendaylight-inventory:nodes/node/openflow:1/node-connector/openflow:1:1</literallayout>


<simpara>The Address Observations should still be there after changes.</simpara>
</section>
</section>
<section xml:id="_developer_s_guide_for_host_tracker">
<title>Developer&#8217;s Guide for Host Tracker</title>
<section xml:id="_validationg_changes_to_host_tracker">
<title>Validationg changes to Host Tracker</title>
<simpara>Host information is added to the Topology data tree.</simpara>
<itemizedlist>
<listitem>
<simpara>Host address</simpara>
</listitem>
<listitem>
<simpara>Attachment point (link) to a node/switch</simpara>
</listitem>
</itemizedlist>

<simpara>This host information and attachment point information can be checked through a browser or a REST Client.</simpara>

<literallayout class="monospaced">http://10.194.126.91:8080/restconf/operational/network-topology:network-topology/topology/flow:1/</literallayout>


<simpara>Host information should still be there after changes.</simpara>
</section>
</section>
<section xml:id="_l2switch_main">
<title>L2Switch Main</title>
<section xml:id="_classes_5">
<title>Classes</title>
<itemizedlist>
<listitem>
<simpara>L2SwitchMainModule</simpara>
<itemizedlist>
<listitem>
<simpara>Reads config subsystem value for <emphasis>is-install-dropall-flow</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>If <emphasis>is-install-dropall-flow</emphasis> is true, then an <emphasis role="strong">InitialFlowWriter</emphasis> is created</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Reads config subsystem value for <emphasis>is-learning-only-mode</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>If <emphasis>is-learning-only-mode</emphasis> is false, then a <emphasis role="strong">ReactiveFlowWriter</emphasis> is created</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>InitialFlowWriter</simpara>
<itemizedlist>
<listitem>
<simpara>Only created when <emphasis>is-install-dropall-flow</emphasis> is true</simpara>
</listitem>
<listitem>
<simpara>Installs a flow, which drops all packets, on each switch.  This flow has low priority and means that packets that don&#8217;t match any higher-priority flows will simply be dropped.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>ReactiveFlowWriter</simpara>
<itemizedlist>
<listitem>
<simpara>Reacts to network traffic and installs MAC-to-MAC flows on switches.  These flows have matches based on MAC source and MAC destination.</simpara>
</listitem>
<listitem>
<simpara>Uses <emphasis role="strong">FlowWriterServiceImpl</emphasis> to write these flows to the switches</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>FlowWriterService / FlowWriterServiceImpl</simpara>
<itemizedlist>
<listitem>
<simpara>Writes flows to switches</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_configuration_4">
<title>Configuration</title>
<itemizedlist>
<listitem>
<simpara>is-install-dropall-flow</simpara>
<itemizedlist>
<listitem>
<simpara>"true" means a drop-all flow will be installed on each switch, so the default action will be to drop a packet instead of sending it to the controller</simpara>
</listitem>
<listitem>
<simpara>"false" means this flow will not be installed</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>dropall-flow-table-id</simpara>
<itemizedlist>
<listitem>
<simpara>The dropall flow will be installed on the specified flow table of each switch</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-install-dropall-flow" is set to "true"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>dropall-flow-priority</simpara>
<itemizedlist>
<listitem>
<simpara>The dropall flow will be installed with the specified priority</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-install-dropall-flow" is set to "true"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>dropall-flow-idle-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The dropall flow will timeout (removed from the switch) if the flow doesn&#8217;t forward a packet for <emphasis>x</emphasis> seconds</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-install-dropall-flow" is set to "true"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>dropall-flow-hard-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The dropall flow will timeout (removed from the switch) after <emphasis>x</emphasis> seconds, regardless of how many packets it is forwarding</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-install-dropall-flow" is set to "true"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>is-learning-only-mode</simpara>
<itemizedlist>
<listitem>
<simpara>"true" means that the L2Switch will only be learning addresses.  No additional flows to optimize network traffic will be installed.</simpara>
</listitem>
<listitem>
<simpara>"false" means that the L2Switch will react to network traffic and install flows on the switches to optimize traffic.  Currently, MAC-to-MAC flows are installed.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>reactive-flow-table-id</simpara>
<itemizedlist>
<listitem>
<simpara>The reactive flow will be installed on the specified flow table of each switch</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-learning-only-mode" is set to "false"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>reactive-flow-priority</simpara>
<itemizedlist>
<listitem>
<simpara>The reactive flow will be installed with the specified priority</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-learning-only-mode" is set to "false"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>reactive-flow-idle-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The reactive flow will timeout (removed from the switch) if the flow doesn&#8217;t forward a packet for <emphasis>x</emphasis> seconds</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-learning-only-mode" is set to "false"</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>reactive-flow-hard-timeout</simpara>
<itemizedlist>
<listitem>
<simpara>The reactive flow will timeout (removed from the switch) after <emphasis>x</emphasis> seconds, regardless of how many packets it is forwarding</simpara>
</listitem>
<listitem>
<simpara>This field is only relevant when "is-learning-only-mode" is set to "false"</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_further_development_5">
<title>Further development</title>
<simpara>The <emphasis role="strong">ReactiveFlowWriter</emphasis> needs to be improved to install the MAC-to-MAC flows faster.  For the first ping, the ARP request and reply are successful.
However, then the ping packets are sent out.  The first ping packet is dropped sometimes because the MAC-to-MAC flow isn&#8217;t installed quickly enough.
The second, third, and following ping packets are successful though.</simpara>
</section>
</section>
</section>
<section xml:id="_api_reference_documentation_5">
<title>API Reference Documentation</title>
<simpara>Further documentation can be found by checking out the L2Switch project.</simpara>
</section>
<section xml:id="_checking_out_the_l2switch_project">
<title>Checking out the L2Switch project</title>

<literallayout class="monospaced">git clone https://git.opendaylight.org/gerrit/p/l2switch.git</literallayout>


<simpara>The above command will create a directory called "l2switch" with the project.</simpara>
</section>
<section xml:id="_testing_your_changes_to_the_l2switch_project">
<title>Testing your changes to the L2Switch project</title>
<section xml:id="_running_the_l2switch_project">
<title>Running the L2Switch project</title>
<simpara>To run the base distribution, you can use the following command</simpara>

<literallayout class="monospaced">./distribution/base/target/distributions-l2switch-base-0.1.0-SNAPSHOT-osgipackage/opendaylight/run.sh</literallayout>


<simpara>If you need additional resources, you can use these command line arguments:</simpara>

<literallayout class="monospaced">-Xms1024m -Xmx2048m -XX:PermSize=512m -XX:MaxPermSize=1024m'</literallayout>


<simpara>To run the karaf distribution, you can use the following command:</simpara>

<literallayout class="monospaced">./distribution/karaf/target/assembly/bin/karaf</literallayout>


</section>
<section xml:id="_create_a_network_using_mininet">
<title>Create a network using mininet</title>

<literallayout class="monospaced">sudo mn --controller=remote,ip=&lt;Controller IP&gt; --topo=linear,3 --switch ovsk,protocols=OpenFlow13
sudo mn --controller=remote,ip=127.0.0.1 --topo=linear,3 --switch ovsk,protocols=OpenFlow13</literallayout>


<simpara>The above command will create a virtual network consisting of 3 switches.
Each switch will connect to the controller located at the specified IP, i.e. 127.0.0.1</simpara>

<literallayout class="monospaced">sudo mn --controller=remote,ip=127.0.0.1 --mac --topo=linear,3 --switch ovsk,protocols=OpenFlow13</literallayout>


<simpara>The above command has the "mac" option, which makes it easier to distinguish between Host MAC addresses and Switch MAC addresses.</simpara>
</section>
<section xml:id="_generating_network_traffic_using_mininet">
<title>Generating network traffic using mininet</title>

<literallayout class="monospaced">h1 ping h2</literallayout>


<simpara>The above command will cause host1 (h1) to ping host2 (h2)</simpara>

<literallayout class="monospaced">pingall</literallayout>


<simpara><emphasis>pingall</emphasis> will cause each host to ping every other host.</simpara>
</section>
<section xml:id="_miscellaneous_mininet_commands">
<title>Miscellaneous mininet commands</title>

<literallayout class="monospaced">link s1 s2 down</literallayout>


<simpara>This will bring the link between switch1 (s1) and switch2 (s2) down</simpara>

<literallayout class="monospaced">link s1 s2 up</literallayout>


<simpara>This will bring the link between switch1 (s1) and switch2 (s2) up</simpara>

<literallayout class="monospaced">link s1 h1 down</literallayout>


<simpara>This will bring the link between switch1 (s1) and host1 (h1) down</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_lacp_developer_guide">
<title>LACP Developer Guide</title>
<section xml:id="_lacp_overview">
<title>LACP Overview</title>
<simpara>The OpenDaylight LACP (Link Aggregation Control Protocol) project can be used to
aggregate multiple links between OpenDaylight controlled network switches and
LACP enabled legacy switches or hosts operating in active LACP mode.</simpara>
<simpara>OpenDaylight LACP passively negotiates automatic bundling of multiple links to form
a single LAG (Link Aggregation Group). LAGs  are realised in the OpenDaylight controlled
switches using OpenFlow 1.3+ group table functionality.</simpara>
</section>
<section xml:id="_lacp_architecture">
<title>LACP Architecture</title>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">inventory</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Maintains list of OpenDaylight controlled switches and port information</simpara>
</listitem>
<listitem>
<simpara>List of LAGs created and physical ports that are part
of the LAG</simpara>
</listitem>
<listitem>
<simpara>Interacts with MD-SAL to update LACP related information</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">inventorylistener</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>This module interacts with MD-SAL for receiving node/node-connector notifications</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">flow</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Programs the switch to punt LACP PDU (Protocol Data Unit) to controller</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">packethandler</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Receives and transmits LACP PDUs to the LACP enabled endpoint</simpara>
</listitem>
<listitem>
<simpara>Provides infrastructure services for group table programming</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><emphasis role="strong">core</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Performs LACP state machine processing</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<section xml:id="_how_lag_programming_is_implemented">
<title>How LAG programming is implemented</title>
<simpara>The LAG representing the aggregated multiple physical ports
are realized in the OpenDaylight controlled switches by creating a
group table entry (Group table supported from OpenFlow 1.3 onwards).
The group table entry has a group type <emphasis role="strong">Select</emphasis> and action referring to
the aggregated physical ports.
Any data traffic to be sent out through the LAG can be sent
through the <emphasis role="strong">group entry</emphasis> available for the LAG.</simpara>
<simpara>Suppose there are ports P1-P8 in a node.
When LACP project is installed, a group table entry for handling broadcast traffic is automatically
created on all the switches that have registered to the controller.</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="33*"/>
    
    <colspec colname="col_2" colwidth="33*"/>
    
    <colspec colname="col_3" colwidth="33*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">GroupID</entry>
        
        <entry align="left" valign="top">GroupType</entry>
        
        <entry align="left" valign="top">EgressPorts</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;B&#8217;castgID&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ALL</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P1,P2,&#8230;P8</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>Now, assume P1 &amp; P2 are now part of LAG1. The group table would be programmed as follows:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="33*"/>
    
    <colspec colname="col_2" colwidth="33*"/>
    
    <colspec colname="col_3" colwidth="33*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">GroupID</entry>
        
        <entry align="left" valign="top">GroupType</entry>
        
        <entry align="left" valign="top">EgressPorts</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;B&#8217;castgID&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ALL</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P3,P4,&#8230;P8</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;LAG1&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>SELECT</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P1,P2</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>When a second LAG, LAG2, is formed with ports P3 and P4,</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="33*"/>
    
    <colspec colname="col_2" colwidth="33*"/>
    
    <colspec colname="col_3" colwidth="33*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">GroupID</entry>
        
        <entry align="left" valign="top">GroupType</entry>
        
        <entry align="left" valign="top">EgressPorts</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;B&#8217;castgID&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ALL</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P5,P6,&#8230;P8</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;LAG1&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>SELECT</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P1,P2</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>&lt;LAG2&gt;</simpara></entry>
        
        <entry align="left" valign="top"><simpara>SELECT</simpara></entry>
        
        <entry align="left" valign="top"><simpara>P3,P4</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_how_applications_can_program_openflow_flows_using_lacp_created_lag_groups">
<title>How applications can program OpenFlow flows using LACP-created LAG groups</title>
<simpara>OpenDaylight controller modules can get the information of LAG by listening/querying the LACP Aggregator datastore.</simpara>
<simpara>When any application receives packets, it can check, if the ingress port is part of a LAG by verifying the
LAG Aggregator reference (lacp-agg-ref) for the source nodeConnector that OpenFlow plugin provides.</simpara>
<simpara>When applications want to add flows to egress out of the LAG, they must use the group entry corresponding to the LAG.</simpara>
<simpara>From the above example, for a flow to egress out of LAG1,</simpara>
<simpara><emphasis role="strong">add-flow  eth_type=&lt;xxxx&gt;,ip_dst=&lt;x.x.x.x&gt;,actions=output:&lt;LAG1&gt;</emphasis></simpara>
<simpara>Similarly, when applications want traffic to be broadcasted, they should use the group table entries <emphasis role="strong">&lt;B&#8217;castgID&gt;,&lt;LAG1&gt;,&lt;LAG2&gt;</emphasis> in output action.</simpara>
<simpara>For all applications, the group table information is accessible from LACP Aggregator datastore.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_netconf_developer_guide">
<title>NETCONF Developer Guide</title>
<note>
<simpara>Reading the NETCONF section in the User Guide is likely useful as
      it contains an overview of NETCONF in OpenDaylight and a how-to
      for spawning and configuring NETCONF connectors.</simpara>
</note>

<simpara>This chapter is recommended for application developers who want to
interact with mounted NETCONF devices from their application code. It
tries to demonstrate all the use cases from user guide with
RESTCONF but now from the code level. One important difference would
be the demonstration of NETCONF notifications and notification
listeners. The notifications were not shown using RESTCONF because
<emphasis role="strong">RESTCONF does not support notifications from mounted NETCONF
devices.</emphasis></simpara>
<note>
<simpara>It may also be useful to read the generic
      <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:MD-SAL:MD-SAL_App_Tutorial">OpenDaylight
      MD-SAL app
      development tutorial</link> before diving into this chapter.
      This guide assumes awareness of basic OpenDaylight application
      development.</simpara>
</note>

<section xml:id="_sample_app_overview">
<title>Sample app overview</title>
<simpara>All the examples presented here are implemented by a sample OpenDaylight
application called <emphasis role="strong">ncmount</emphasis> in the <literal>coretutorials</literal> OpenDaylight project.
It can be found on the github mirror of OpenDaylight&#8217;s repositories:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://github.com/opendaylight/coretutorials/tree/stable/lithium/ncmount">https://github.com/opendaylight/coretutorials/tree/stable/lithium/ncmount</link></simpara>
</listitem>
</itemizedlist>

<simpara>or checked out from the official OpenDaylight repository:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://git.opendaylight.org/gerrit/#/admin/projects/coretutorials">https://git.opendaylight.org/gerrit/#/admin/projects/coretutorials</link></simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">The application was built using the
<link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:MD-SAL:Startup_Project_Archetype">project
startup maven archetype</link> and demonstrates how to:</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>preconfigure connectors to NETCONF devices</simpara>
</listitem>
<listitem>
<simpara>retrieve MountPointService (registry of available mount points)</simpara>
</listitem>
<listitem>
<simpara>listen and react to changing connection state of netconf-connector</simpara>
</listitem>
<listitem>
<simpara>add custom device YANG models to the app and work with them</simpara>
</listitem>
<listitem>
<simpara>read data from device in binding aware format (generated java APIs
from provided YANG models)</simpara>
</listitem>
<listitem>
<simpara>write data into device in binding aware format</simpara>
</listitem>
<listitem>
<simpara>trigger and listen to NETCONF notifications in binding aware format</simpara>
</listitem>
</itemizedlist>

<simpara>Detailed information about the structure of the application can be
found at:
<link xlink:href="https://wiki.opendaylight.org/view/Controller_Core_Functionality_Tutorials:Tutorials:Netconf_Mount">https://wiki.opendaylight.org/view/Controller_Core_Functionality_Tutorials:Tutorials:Netconf_Mount</link></simpara>
<note>
<simpara>The code in ncmount is fully <emphasis role="strong">binding aware</emphasis> (works with generated
java APIs from provided YANG models). However it is also possible to
perform the same operations in <emphasis role="strong">binding independent</emphasis> manner.</simpara>
</note>

<section xml:id="_ncmountprovider">
<title>NcmountProvider</title>
<simpara>The NcmountProvider class (found in NcmountProvider.java) is the central
point of the ncmount application and all the application logic is
contained there. The following sections will detail its most interesting
pieces.</simpara>
<section xml:id="_retrieve_mountpointservice">
<title>Retrieve MountPointService</title>
<simpara>The MountPointService is a central registry of all available mount points
in OpenDaylight. It is just another MD-SAL service and is available from the
<literal>session</literal> attribute passed by <literal>onSessionInitiated</literal> callback:</simpara>
<screen>@Override
public void onSessionInitiated(ProviderContext session) {
    LOG.info("NcmountProvider Session Initiated");

    // Get references to the data broker and mount service
    this.mountService = session.getSALService(MountPointService.class);

    ...

    }
}</screen>

</section>
<section xml:id="_listen_for_connection_state_changes">
<title>Listen for connection state changes</title>
<simpara>It is important to know when a mount point appears, when it is fully
connected and when it is disconnected or removed. The exact states of a
mount point are:</simpara>
<itemizedlist>
<listitem>
<simpara>Connected</simpara>
</listitem>
<listitem>
<simpara>Connecting</simpara>
</listitem>
<listitem>
<simpara>Unable to connect</simpara>
</listitem>
</itemizedlist>

<simpara>To receive this kind of information, an application has to register
itself as a notification listener for the preconfigured
netconf-topology subtree in MD-SAL&#8217;s datastore. This can be performed
in the <literal>onSessionInitiated</literal> callback as well:</simpara>
<screen>@Override
public void onSessionInitiated(ProviderContext session) {

    ...

    this.dataBroker = session.getSALService(DataBroker.class);

    // Register ourselves as the REST API RPC implementation
    this.rpcReg = session.addRpcImplementation(NcmountService.class, this);

    // Register ourselves as data change listener for changes on Netconf
    // nodes. Netconf nodes are accessed via "Netconf Topology" - a special
    // topology that is created by the system infrastructure. It contains
    // all Netconf nodes the Netconf connector knows about. NETCONF_TOPO_IID
    // is equivalent to the following URL:
    // .../restconf/operational/network-topology:network-topology/topology/topology-netconf
    if (dataBroker != null) {
        this.dclReg = dataBroker.registerDataChangeListener(LogicalDatastoreType.OPERATIONAL,
                NETCONF_TOPO_IID.child(Node.class),
                this,
                DataChangeScope.SUBTREE);
    }
}</screen>

<simpara>The implementation of the callback from MD-SAL when the data change can be
found in the
<literal>onDataChanged(AsyncDataChangeEvent&lt;InstanceIdentifier&lt;?&gt;, DataObject&gt;
change)</literal> callback of
<link xlink:href="https://github.com/opendaylight/coretutorials/blob/stable/lithium/ncmount/impl/src/main/java/ncmount/impl/NcmountProvider.java">NcmountProvider
class</link>.</simpara>
</section>
<section xml:id="_reading_data_from_the_device">
<title>Reading data from the device</title>
<simpara>The first step when trying to interact with the device is to get the exact
mount point instance (identified by an instance identifier) from the MountPointService:</simpara>
<screen>@Override
public Future&lt;RpcResult&lt;ShowNodeOutput&gt;&gt; showNode(ShowNodeInput input) {
    LOG.info("showNode called, input {}", input);

    // Get the mount point for the specified node
    // Equivalent to '.../restconf/&lt;config | operational&gt;/opendaylight-inventory:nodes/node/&lt;node-name&gt;/yang-ext:mount/'
    // Note that we can read both config and operational data from the same
    // mount point
    final Optional&lt;MountPoint&gt; xrNodeOptional = mountService.getMountPoint(NETCONF_TOPO_IID
            .child(Node.class, new NodeKey(new NodeId(input.getNodeName()))));

    Preconditions.checkArgument(xrNodeOptional.isPresent(),
            "Unable to locate mountpoint: %s, not mounted yet or not configured",
            input.getNodeName());
    final MountPoint xrNode = xrNodeOptional.get();

    ....
}</screen>

<note>
<simpara>The triggering method in this case is called <literal>showNode</literal>. It is a
YANG-defined RPC and NcmountProvider serves as an MD-SAL RPC
implementation among other things. This means that <literal>showNode</literal> an be
triggered using RESTCONF.</simpara>
</note>

<simpara>The next step is to retrieve an instance of the <literal>DataBroker</literal> API from the
mount point and start a read transaction:</simpara>
<screen>@Override
public Future&lt;RpcResult&lt;ShowNodeOutput&gt;&gt; showNode(ShowNodeInput input) {

    ...

    // Get the DataBroker for the mounted node
    final DataBroker xrNodeBroker = xrNode.getService(DataBroker.class).get();
    // Start a new read only transaction that we will use to read data
    // from the device
    final ReadOnlyTransaction xrNodeReadTx = xrNodeBroker.newReadOnlyTransaction();

    ...
}</screen>

<simpara>Finally, it is possible to perform the read operation:</simpara>
<screen>@Override
public Future&lt;RpcResult&lt;ShowNodeOutput&gt;&gt; showNode(ShowNodeInput input) {

    ...

    InstanceIdentifier&lt;InterfaceConfigurations&gt; iid =
            InstanceIdentifier.create(InterfaceConfigurations.class);

    Optional&lt;InterfaceConfigurations&gt; ifConfig;
    try {
        // Read from a transaction is asynchronous, but a simple
        // get/checkedGet makes the call synchronous
        ifConfig = xrNodeReadTx.read(LogicalDatastoreType.CONFIGURATION, iid).checkedGet();
    } catch (ReadFailedException e) {
        throw new IllegalStateException("Unexpected error reading data from " + input.getNodeName(), e);
    }

    ...
}</screen>

<simpara>The instance identifier is used here again to specify a subtree to read
from the device. At this point application can process the data as it sees
fit. The ncmount app transforms the data into its own format and returns
it from <literal>showNode</literal>.</simpara>
<note>
<simpara>More information can be found in the source code of ncmount
sample app + on wiki:
<link xlink:href="https://wiki.opendaylight.org/view/Controller_Core_Functionality_Tutorials:Tutorials:Netconf_Mount">https://wiki.opendaylight.org/view/Controller_Core_Functionality_Tutorials:Tutorials:Netconf_Mount</link></simpara>
</note>

</section>
</section>
</section>
</chapter>
<chapter xml:id="_network_intent_composition_nic_developer_guide">
<title>Network Intent Composition (NIC) Developer Guide</title>
<section xml:id="_overview_13">
<title>Overview</title>
<simpara>The Network Intent Composition (NIC) provides four features:</simpara>
<itemizedlist>
<listitem>
<simpara>odl-nic-core - the basic model and infrastructure for the NIC capabilities</simpara>
</listitem>
<listitem>
<simpara>odl-nic-cli - support for the Karaf console CLI NIC commands</simpara>
</listitem>
<listitem>
<simpara>odl-nic-renderer-vtn - a feature that transforms an intent to a network
modification using the VTN project</simpara>
</listitem>
<listitem>
<simpara>odl-nic-renderer-gbp - a feature that transforms an intent to a network
modification using the Group Policy project</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis>Only a single renderer feature should be installed at a time for the Lithium
release.</emphasis></simpara>
</section>
<section xml:id="_odl_nic_core">
<title>odl-nic-core</title>
<simpara>This feature supplies the base models for the Network Intent Composition (NIC)
capability. This includes the definition of intent as well as the configuration
and operational data trees.</simpara>
<simpara>This feature only provides an information model. The interface for NIC is to
modify the information model via the configuraiton data tree, which will
trigger the renderer to make the appropriate changes in the controlled
network.</simpara>
<section xml:id="_post_put_configuration">
<title>POST / PUT (configuration)</title>
<simpara>This operations create instances of an intent in the configuration data tree
and trigger the creation or modification of an intent.</simpara>
</section>
<section xml:id="_get_configuration_operational">
<title>GET (configuration / operational)</title>
<simpara>This operation lists all or fetches a single intent from the data tree.</simpara>
</section>
<section xml:id="_delete_configuration">
<title>DELETE (configuration)</title>
<simpara>This operation will cause an intent to be removed from the system and trigger
any configuration changes on the network rendered from this intent to be
removed.</simpara>
</section>
</section>
<section xml:id="_odl_nic_cli">
<title>odl-nic-cli</title>
<simpara>This feature provides karaf console CLI command to manipulate the intent
data model. The CLI essentailly invokes the equivalent data operations.</simpara>
<section xml:id="_intent_add">
<title>intent:add</title>
<simpara>Creates a new intent in the configuration data tree</simpara>
</section>
<section xml:id="_intent_update">
<title>intent:update</title>
<simpara>Updates an existing intent in the configuration data tree</simpara>
</section>
<section xml:id="_intent_delete">
<title>intent:delete</title>
<simpara>Removes an existing intent from the system</simpara>
</section>
<section xml:id="_intent_list">
<title>intent:list</title>
<simpara>Lists all the intents in the system</simpara>
</section>
<section xml:id="_intent_show">
<title>intent:show</title>
<simpara>Displayes the details of a single intent</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_network_modeling_nemo">
<title>NEtwork MOdeling (NEMO)</title>
<section xml:id="_overview_14">
<title>Overview</title>
<simpara>TBD: Overview of the NEMO feature, what logical functionality it
provides and why you might use it as a developer.</simpara>
</section>
<section xml:id="_nemo_architecture">
<title>NEMO Architecture</title>
<simpara>TBD: NEMO components and how they work together.
Also include information about how the feature integrates with
OpenDaylight and architecture.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_7">
<title>Key APIs and Interfaces</title>
<simpara>TBD: Document the key things a user would want to use.</simpara>
<section xml:id="_nemo_intent_api">
<title>NEMO Intent API</title>
<simpara>TBD: A description of NEMO Intent API.</simpara>
</section>
</section>
<section xml:id="_api_reference_documentation_6">
<title>API Reference Documentation</title>
<simpara>TBD: Provide links to JavaDoc, REST API documentation, etc.</simpara>
</section>
</chapter>
<chapter xml:id="_netide_developer_guide">
<title>NetIDE Developer Guide</title>
<section xml:id="_overview_15">
<title>Overview</title>
<simpara>The NetIDE Network Engine enables portability and cooperation inside a single
network by using a client/server multi-controller SDN architecture. Separate
"Client SDN Controllers" host the various SDN Applications with their access
to the actual physical network abstracted and coordinated through a single
"Server SDN Controller", in this instance OpenDaylight. This allows
applications written for Ryu/Floodlight/Pyretic to execute on OpenDaylight
managed infrastructure.</simpara>
<simpara>The "Network Engine" is modular by design:</simpara>
<itemizedlist>
<listitem>
<simpara>An OpenDaylight plugin, "shim", sends/receives messages to/from subscribed SDN
Client Controllers. This consumes the ODL OpenFlow Plugin</simpara>
</listitem>
<listitem>
<simpara>An initial suite of SDN Client Controller "Backends": Floodlight, Ryu, Pyretic.
Further controllers may be added over time as the engine is extensible.</simpara>
</listitem>
</itemizedlist>

<simpara>The Network Engine provides a compatibility layer capable of translating calls of
the network applications running on top of the client controllers, into calls for
the server controller framework. The communication between the client and the
server layers is achieved through the NetIDE intermediate protocol,
which is an application-layer protocol on top of TCP that transmits the network
control/management messages from the client to the server controller and vice-versa.
Between client and server controller sits the Core Layer which also "speaks" the
intermediate protocol. The core layer implements three main functions:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>interfacing with the client backends and server shim, controlling the lifecycle
of controllers as well as modules in them,</simpara>
</listitem>
<listitem>
<simpara>orchestrating the execution of individual modules (in one client controller)
or complete applications (possibly spread across multiple client controllers),</simpara>
</listitem>
<listitem>
<simpara>interfacing with the tools.</simpara>
</listitem>
</orderedlist>

<figure>
<title>NetIDE Network Engine Architecture</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/netide/arch-engine.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>arch engine</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_netide_intermediate_protocol">
<title>NetIDE Intermediate Protocol</title>
<simpara>The Intermediate Protocol serves several needs, it has to:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>carry control messages between core and shim/backend, e.g., to start up/take
down a particular module, providing unique identifiers for modules,</simpara>
</listitem>
<listitem>
<simpara>carry event and action messages between shim, core, and backend, properly
demultiplexing such messages to the right module based on identifiers,</simpara>
</listitem>
<listitem>
<simpara>encapsulate messages specific to a particular SBI protocol version (e.g.,
OpenFlow 1.X, NETCONF, etc.) towards the client controllers with proper information
to recognize these messages as such.</simpara>
</listitem>
</orderedlist>

<simpara>The NetIDE packages can be added as dependencies in Maven projects by putting the
following code in the <emphasis>pom.xml</emphasis> file.</simpara>

<literallayout class="monospaced">&lt;dependency&gt;
    &lt;groupId&gt;org.opendaylight.netide&lt;/groupId&gt;
    &lt;artifactId&gt;api&lt;/artifactId&gt;
    &lt;version&gt;${NETIDE_VERSION}&lt;/version&gt;
&lt;/dependency&gt;</literallayout>


<simpara>The current stable version for NetIDE is <literal>0.1.0-Beryllium</literal>.</simpara>
<section xml:id="_protocol_specification">
<title>Protocol specification</title>
<simpara>Messages of the NetIDE protocol contain two basic elements: the NetIDE header and
the data (or payload). The NetIDE header, described below, is placed
before the payload and serves as the communication and control link between the
different components of the Network Engine. The payload can contain management
messages, used by the components of the Network Engine to exchange relevant
information, or control/configuration messages (such as OpenFlow, NETCONF, etc.)
crossing the Network Engine generated by either network application modules or by
the network elements.</simpara>
<simpara>The NetIDE header is defined as follows:</simpara>

<literallayout class="monospaced"> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|   netide_ver  |      type     |             length            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                         xid                                   |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                       module_id                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                                                               |
+                     datapath_id                               +
|                                                               |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+</literallayout>


<simpara>where each tick mark represents one bit position. Alternatively, in a C-style coding
format, the NetIDE header can be represented with the following structure:</simpara>

<literallayout class="monospaced">struct netide_header {
    uint8_t netide_ver ;
    uint8_t type ;
    uint16_t length ;
    uint32_t xid
    uint32_t module_id
    uint64_t datapath_id
};</literallayout>


<itemizedlist>
<listitem>
<simpara><literal>netide_ver</literal> is the version of the NetIDE protocol (the current version is v1.2, which
is identified with value 0x03).</simpara>
</listitem>
<listitem>
<simpara><literal>length</literal> is the total length of the payload in bytes.</simpara>
</listitem>
<listitem>
<simpara><literal>type</literal> contains a code that indicates the type of the message according with the
following values:</simpara>

<literallayout class="monospaced">enum type {
    NETIDE_HELLO = 0x01 ,
    NETIDE_ERROR = 0x02 ,
    NETIDE_MGMT = 0x03 ,
    MODULE_ANNOUNCEMENT = 0x04 ,
    MODULE_ACKNOWLEDGE = 0x05 ,
    NETIDE_HEARTBEAT = 0x06 ,
    NETIDE_OPENFLOW = 0x11 ,
    NETIDE_NETCONF = 0x12 ,
    NETIDE_OPFLEX = 0x13
};</literallayout>


</listitem>
<listitem>
<simpara><literal>datapath_id</literal> is a 64-bit field that uniquely identifies the network elements.</simpara>
</listitem>
<listitem>
<simpara><literal>module_id</literal> is a 32-bits field that uniquely identifies Backends and application modules running
on top of each client controller. The composition mechanism in the core layer leverages
on this field to implement the correct execution flow of these modules.</simpara>
</listitem>
<listitem>
<simpara><literal>xid</literal> is the transaction identifier associated to the each message. Replies must use the same
value to facilitate the pairing.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_module_announcement">
<title>Module announcement</title>
<simpara>The first operation performed by a Backend is registering itself and the modules that
it is running to the Core. This is done by using the <literal>MODULE_ANNOUNCEMENT</literal> and
<literal>MODULE_ACKNOWLEDGE</literal> message types. As a result of this process, each Backend and
application module can be recognized by the Core through an identifier (the <literal>module_id</literal>)
placed in the NetIDE header. First, a Backend registers itself by using the following
schema: backend-&lt;platform name&gt;-&lt;pid&gt;.</simpara>
<simpara>For example,odule a Ryu Backend will register by using the following name in the message
backend-ryu-12345 where 12345 is the process ID of the registering instance of the
Ryu platform. The format of the message is the following:</simpara>

<literallayout class="monospaced">struct NetIDE_message {
    netide_ver = 0x03
    type = MODULE_ANNOUNCEMENT
    length = len(" backend -&lt; platform_name &gt;-&lt;pid &gt;")
    xid = 0
    module_id = 0
    datapath_id = 0
    data = " backend -&lt; platform_name &gt;-&lt;pid &gt;"
}</literallayout>


<simpara>The answer generated by the Core will include a <literal>module_id</literal> number and the Backend name in
the payload (the same indicated in the <literal>MODULE_ANNOUNCEMENT</literal> message):</simpara>

<literallayout class="monospaced">struct NetIDE_message {
    netide_ver = 0x03
    type = MODULE_ACKNOWLEDGE
    length = len(" backend -&lt; platform_name &gt;-&lt;pid &gt;")
    xid = 0
    module_id = MODULE_ID
    datapath_id = 0
    data = " backend -&lt; platform_name &gt;-&lt;pid &gt;"
}</literallayout>


<simpara>Once a Backend has successfully registered itself, it can start registering its modules with the same
procedure described above by indicating the name of the module in the data (e.g. data="Firewall").
From this point on, the Backend will insert its own <literal>module_id</literal> in the header of the messages it generates
 (e.g. heartbeat, hello messages, OpenFlow echo messages from the client controllers, etc.).
Otherwise, it will encapsulate the control/configuration messages (e.g. FlowMod, PacketOut,
FeatureRequest, NETCONF request, etc.) generated by network application modules with the specific
+module_id+s.</simpara>
</section>
<section xml:id="_heartbeat">
<title>Heartbeat</title>
<simpara>The heartbeat mechanism has been introduced after the adoption of the ZeroMQ messaging queuing
library to transmit the NetIDE messages. Unfortunately, the ZeroMQ library does not offer any
mechanism to find out about disrupted connections (and also completely unresponsive peers).
This limitation of the ZeroMQ library can be an issue for the Core&#8217;s composition mechanism and for
the tools connected to the Network Engine, as they cannot understand when an client controller
disconnects or crashes. As a consequence, Backends must periodically send (let&#8217;s say every 5
seconds) a "heartbeat" message to the Core. If the Core does not receive at least one "heartbeat"
message from the Backend within a certain timeframe, the Core considers it disconnected, removes
all the related data from its memory structures and informs the relevant tools. The format of the
message is the following:</simpara>

<literallayout class="monospaced">struct NetIDE_message {
    netide_ver = 0x03
    type = NETIDE_HEARTBEAT
    length = 0
    xid = 0
    module_id = backend -id
    datapath_id = 0
    data = 0
}</literallayout>


</section>
<section xml:id="_handshake">
<title>Handshake</title>
<simpara>Upon a successful connection with the Core, the client controller must immediately send a hello
message with the list of the control and/or management protocols needed by the applications
deployed on top of it.</simpara>

<literallayout class="monospaced">struct NetIDE_message {
    struct netide_header header ;
    uint8 data [0]
};</literallayout>


<simpara>The header contains the following values:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>netide ver=0x03</literal></simpara>
</listitem>
<listitem>
<simpara><literal>type=NETIDE_HELLO</literal></simpara>
</listitem>
<listitem>
<simpara><literal>length=2*NR_PROTOCOLS</literal></simpara>
</listitem>
<listitem>
<simpara><literal>data</literal> contains one 2-byte word (in big endian order) for each protocol, with the first
byte containing the code of the protocol according to the above enum, while the second byte in-
dictates the version of the protocol (e.g. according to the ONF specification, 0x01 for OpenFlow
v1.0, 0x02 for OpenFlow v1.1, etc.). NETCONF version is marked with 0x01 that refers to the
specification in the RFC6241, while OpFlex version is marked with 0x00 since this protocol is
still in work-in-progress stage.</simpara>
</listitem>
</itemizedlist>

<simpara>The Core relays hello messages to the server controller which responds with another hello message
containing the following:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>netide ver=0x03</literal></simpara>
</listitem>
<listitem>
<simpara><literal>type=NETIDE_HELLO</literal></simpara>
</listitem>
<listitem>
<simpara><literal>length=2*NR_PROTOCOLS</literal></simpara>
</listitem>
</itemizedlist>

<simpara>If at least one of the protocols requested by the client is supported. In particular, <literal>data</literal> contains the
codes of the protocols that match the client&#8217;s request (2-bytes words, big endian order). If the hand-
shake fails because none of the requested protocols is supported by the server controller, the header
of the answer is as follows:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>netide ver=0x03</literal></simpara>
</listitem>
<listitem>
<simpara><literal>type=NETIDE_ERROR</literal></simpara>
</listitem>
<listitem>
<simpara><literal>length=2*NR_PROTOCOLS</literal></simpara>
</listitem>
<listitem>
<simpara><literal>data</literal> contains the codes of all the protocols supported by the server
controller (2-bytes words, big endian order). In this case, the TCP session is terminated by the
server controller just after the answer is received by the client.
`</simpara>
</listitem>
</itemizedlist>

</section>
</section>
</chapter>
<chapter xml:id="_neutron_northbound">
<title>Neutron Northbound</title>
<section xml:id="_how_to_write_a_sb_neutron_consumer">
<title>How to Write a SB Neutron Consumer</title>
<simpara>In Lithium, there will be two options for SB Neutron Consumers:</simpara>
<itemizedlist>
<listitem>
<simpara>Using the legacy I*Aware interfaces</simpara>
</listitem>
<listitem>
<simpara>Listening for changes via the Neutron YANG model</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_how_to_use_the_legacy_i_aware_interfaces">
<title>How to use the legacy I*Aware interfaces</title>
<simpara>For each neutron data object, there is an I*Aware interface defined to allow
southbound providers that don&#8217;t want to use the MD-SAL to register with the
Neutron service to be made aware of potential operations on that type of
object.  For each modification operation (create, update and delete), the
I*Aware interface defines a pair of calls (The general template
is shown in the following table, please see javadoc of the specific interface
for specific details)</simpara>
<table frame="all"
    rowsep="1" colsep="1">
<title>I*Aware Methods</title>
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="33*"/>
    
    <colspec colname="col_2" colwidth="33*"/>
    
    <colspec colname="col_3" colwidth="33*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Create</entry>
        
        <entry align="left" valign="top">Update</entry>
        
        <entry align="left" valign="top">Delete</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>canCreate*()</simpara></entry>
        
        <entry align="left" valign="top"><simpara>canUpdate*()</simpara></entry>
        
        <entry align="left" valign="top"><simpara>canDelete*()</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>neutron*Created()</simpara></entry>
        
        <entry align="left" valign="top"><simpara>neutron*Updated()</simpara></entry>
        
        <entry align="left" valign="top"><simpara>neutron*Deleted()</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</table>

<section xml:id="_the_semantics_of_the_can_methods">
<title>The semantics of the can*() methods</title>
<simpara>Each of the can*() methods gives a southbound provider a vote on whether a
proposed change is acceptable or not. A southbound provider that implements
a particular can*() method is expected to return an HTTP response code as
its "vote" - values between 200 and 299 are a "yes" vote, other values are
a "no" vote.  The neutron white board pattern is an all or nothing affair:
if any one southbound provider votes no on a change, that change is rejected.</simpara>
<simpara>For the canCreate*() method, the southbound provider recieves the proposed
object.  In the case of canDelete*(), the southbound provider recieves the
current object that will be removed.  Lastly, the canUpdate*() method passed
the current object and the proposed delta.</simpara>
</section>
<section xml:id="_the_semantics_of_the_neutron_methods">
<title>The semantics of the neutron*() methods</title>
<simpara>Once all southbound providers vote yes for a particular change, the neutron
service transcribes the change into its caches/MD-SAL models and then calls
the appropriate neutron*() method on each registered southbound provider.
At this point, the southbound provider is expected to meet the request as
best they can and when they can, taking responsibility for any errors that
might be incurred (there is no back signalling of errors).  For these calls,
the modified object is provided in all cases, except for the neutron*Deleted()
method.  This passes an instance of the deleted object that will be garbage
collected once all the southbound providers are finished with it.</simpara>
</section>
<section xml:id="_how_to_register_your_consumer_with_the_neutron_service">
<title>How to register your consumer with the Neutron Service</title>
<simpara>A southbound provider that wants to register with the neutron service
via a particular I*Aware interface must first implement that interface.
Then, in the init class of its Activator method, it should add the name of
the implemented I*Aware class as an interface that is managed, along with
the class that implements the interface as the implementation via the
setInterface method.  The following example from the Neutron test dummy
provider shows it is registering for <emphasis role="strong">all</emphasis> I*Aware interfaces:</simpara>
<programlisting language="java" linenumbering="unnumbered">    @Override
    public void init(BundleContext context, DependencyManager manager) throws Exception {
       manager.add(createComponent().setInterface(new String[] {
           INeutronFirewallAware.class.getName()}, null)
           .setImplementation(NeutronFirewallDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronFirewallPolicyAware.class.getName()}, null)
           .setImplementation(NeutronFirewallPolicyDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronFirewallRuleAware.class.getName()}, null)
           .setImplementation(NeutronFirewallRuleDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronFloatingIPAware.class.getName()}, null)
           .setImplementation(NeutronFloatingIPDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronLoadBalancerAware.class.getName()}, null)
           .setImplementation(NeutronLoadBalancerDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronLoadBalancerHealthMonitorAware.class.getName()}, null)
           .setImplementation(NeutronLoadBalancerHealthMonitorDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronLoadBalancerListenerAware.class.getName()}, null)
           .setImplementation(NeutronLoadBalancerListenerDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronLoadBalancerPoolAware.class.getName()}, null)
           .setImplementation(NeutronLoadBalancerPoolDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronLoadBalancerPoolMemberAware.class.getName()}, null)
           .setImplementation(NeutronLoadBalancerPoolMemberDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronNetworkAware.class.getName()}, null)
           .setImplementation(NeutronNetworkDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronPortAware.class.getName()}, null)
           .setImplementation(NeutronPortDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronRouterAware.class.getName()}, null)
           .setImplementation(NeutronRouterDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronSecurityGroupAware.class.getName()}, null)
           .setImplementation(NeutronSecurityGroupDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronSecurityRuleAware.class.getName()}, null)
           .setImplementation(NeutronSecurityRuleDummyProvider.class));
       manager.add(createComponent().setInterface(new String[] {
           INeutronSubnetAware.class.getName()}, null)
           .setImplementation(NeutronSubnetDummyProvider.class));
    }</programlisting>

</section>
</section>
<section xml:id="_how_to_use_the_neutron_yang_model">
<title>How to use the Neutron YANG model</title>
<simpara>For each neutron data object, there is an Neutron*Interface defined within
the transcriber artifact that will write that object to the MD-SAL
configurational datastore.<?asciidoc-br?>
All Neutron*Interface extend AbstractNeutronInterface, in which two methods
are defined:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>one takes the neutron object as input, and will create a data object from it.<?asciidoc-br?></simpara>
</listitem>
<listitem>
<simpara>one takes an uuid as input, and will create a data object containing the uuid.</simpara>
</listitem>
</itemizedlist>

<screen>protected abstract T toMd(S neutronObject);
protected abstract T toMd(String uuid);</screen>

<simpara>In addition the AbstractNeutronInterface class provides several other
helper methods (addMd, updateMd, removeMd), which handle the actual
writing to the configuration datastore.</simpara>
<section xml:id="_the_semantics_of_the_tomd_methods">
<title>The semantics of the toMD() methods</title>
<simpara>Each of the Neutron YANG models defines structures containing data.
Further each YANG-modeled structures has it own builder.
A particular toMD() method instantiates an instance of the correct
builder, fills in the properties of the builder from the corresponding
values of the Neutron object and then creates the YANG-modeled structures
via the build() method.</simpara>
<simpara>As an example, one of the toMD code for Neutron Networks is
presented below:</simpara>
<screen>    protected Network toMd(NeutronNetwork network) {
        NetworkBuilder networkBuilder = new NetworkBuilder();
        networkBuilder.setAdminStateUp(network.getAdminStateUp());
        if (network.getNetworkName() != null) {
            networkBuilder.setName(network.getNetworkName());
        }
        if (network.getShared() != null) {
            networkBuilder.setShared(network.getShared());
        }
        if (network.getStatus() != null) {
            networkBuilder.setStatus(network.getStatus());
        }
        if (network.getSubnets() != null) {
            List&lt;Uuid&gt; subnets = new ArrayList&lt;Uuid&gt;();
            for( String subnet : network.getSubnets()) {
                subnets.add(toUuid(subnet));
            }
            networkBuilder.setSubnets(subnets);
        }
        if (network.getTenantID() != null) {
            networkBuilder.setTenantId(toUuid(network.getTenantID()));
        }
        if (network.getNetworkUUID() != null) {
            networkBuilder.setUuid(toUuid(network.getNetworkUUID()));
        } else {
            logger.warn("Attempting to write neutron network without UUID");
        }
        return networkBuilder.build();
    }</screen>

</section>
</section>
</chapter>
<chapter xml:id="_odl_sdni_developer_guide">
<title>ODL-SDNi Developer Guide</title>
<section xml:id="_overview_16">
<title>Overview</title>
<simpara>This project aims at enabling inter-SDN controller communication by developing SDNi (Software Defined Networking interface) as an application (ODL-SDNi App).</simpara>
</section>
<section xml:id="_odl_sdni_architecture">
<title>ODL-SDNi Architecture</title>
<itemizedlist>
<listitem>
<simpara>SDNi Aggregator: Northbound SDNi plugin acts as an aggregator for collecting network information such as topology, stats, host etc. This plugin can be evolving as per needs of network data requested to be shared across federated SDN controllers.</simpara>
</listitem>
<listitem>
<simpara>SDNi REST API: REST API view autogenerated and accessible through RESTCONF to fetch the aggregated information from the northbound plugin – SDNi aggregator.The RESTCONF protocol operates on a conceptual datastore defined with the YANG data modeling language.</simpara>
</listitem>
<listitem>
<simpara>SDNi Wrapper: SDNi BGP Wrapper will be responsible for the sharing and collecting information to/from federated controllers.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_sdni_aggregator">
<title>SDNi Aggregator</title>
<itemizedlist>
<listitem>
<simpara>SDNiAggregator connects with the Base Network Service Functions of the controller. Currently it is querying network topology through md-sal for creating SDNi network capability.</simpara>
</listitem>
<listitem>
<simpara>SDNiAggregator is customized to retrieve the host controller’s details, while running the controller in cluster mode. Rest of the northbound APIs of controller will retrieve the entire topology information of all the connected controllers.</simpara>
</listitem>
<listitem>
<simpara>The SDNiAggregator creates a topology structure.This structure is populated by the various network funtions.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_sdni_rest_api">
<title>SDNi REST API</title>
<simpara>ODL-SDNi REST API query SDNiAggregator to get the required information  through RESTCONF. Each request must start with URI /restconf</simpara>
<simpara><link xlink:href="http://${ipaddress}:8181/restconf/operations/opendaylight-sdni-topology-msg:getTopology">http://${ipaddress}:8181/restconf/operations/opendaylight-sdni-topology-msg:getTopology</link></simpara>
<simpara><emphasis role="strong">Topology Data:</emphasis> Controller IP Address, Links, Nodes, Link Bandwidths, MAC Address of switches, Latency, Host IP address.</simpara>
<simpara><link xlink:href="http://${ipaddress}:8181/restconf/operations/opendaylight-sdni-qos-msg:get-all-node-connectors-statistics">http://${ipaddress}:8181/restconf/operations/opendaylight-sdni-qos-msg:get-all-node-connectors-statistics</link></simpara>
<simpara><emphasis role="strong">QOS Data:</emphasis> Node, Port, Transmit Packets, Receive Packets, Collision Count, Receive Frame Error, Receive Over Run Error, Receive Crc Error</simpara>
</section>
<section xml:id="_sdni_wrapper">
<title>SDNi Wrapper</title>
<figure>
<title>SDNiWrapper</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/SDNiWrapper.png"/>
    </imageobject>
    <textobject><phrase>SDNiWrapper</phrase></textobject>
  </mediaobject>
</figure>

<itemizedlist>
<listitem>
<simpara>SDNiWrapper is an extension of ODL-BGPCEP where SDNi topology data is exchange along with the Update NLRI message. Refer <link xlink:href="http://tools.ietf.org/html/draft-ietf-idr-ls-distribution-04">http://tools.ietf.org/html/draft-ietf-idr-ls-distribution-04</link> for more information on NLRI.</simpara>
</listitem>
<listitem>
<simpara>SDNiWrapper gets the controller’s network capabilities through SDNi REST API and serialize it in Update NLRI message. This NLRI message will get exchange between the clustered controllers through BGP-UPDATE message. Similarly peer controller’s UPDATE message is received and unpacked then format to SDNi Network capability data, which will be stored for further purpose.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_api_reference_documentation_7">
<title>API Reference Documentation</title>
<simpara>Go to <link xlink:href="http://${ipaddress}:8181/apidoc/explorer/index.html">http://${ipaddress}:8181/apidoc/explorer/index.html</link>, sign in, and expand the opendaylight-sdni panel.  From there, users can execute various API calls to test their sdni deployment.</simpara>
</section>
</chapter>
<chapter xml:id="_openflow_protocol_library_developer_guide">
<title>OpenFlow Protocol Library Developer Guide</title>
<section xml:id="_introduction">
<title>Introduction</title>
<simpara>OpenFlow Protocol Library is component in OpenDaylight, that mediates communication
between OpenDaylight controller and hardware devices supporting OpenFlow protocol.
Primary goal is to provide user (or upper layers of OpenDaylight) communication
channel, that can be used for managing network hardware devices.</simpara>
</section>
<section xml:id="_features_overview">
<title>Features Overview</title>
<simpara>There are three features inside openflowjava:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">odl-openflowjava-protocol</emphasis> provides all openflowjava bundles, that are needed
for communication with openflow devices. It ensures message translation and
handles network connections. It also provides openflow protocol specific
model.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">odl-openflowjava-all</emphasis> currently contains only odl-openflowjava-protocol feature.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">odl-openflowjava-stats</emphasis> provides mechanism for message counting and reporting.
Can be used for performance analysis.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_odl_openflowjava_protocol_architecture">
<title>odl-openflowjava-protocol Architecture</title>
<simpara>Basic bundles contained in this feature are openflow-protocol-api,
openflow-protocol-impl, openflow-protocol-spi and util.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">openflow-protocol-api</emphasis> - contains openflow model, constants and keys used for
(de)serializer registration.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">openflow-protocol-impl</emphasis> - contains message factories, that translate binary
messages into DataObjects and vice versa. Bundle also contains network connection
handlers - servers, netty pipeline handlers, &#8230;</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">openflow-protocol-spi</emphasis> - entry point for openflowjava configuration,
startup and close. Basically starts implementation.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">util</emphasis> - utility classes for binary-Java conversions and to ease experimenter
key creation</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_odl_openflowjava_stats_feature">
<title>odl-openflowjava-stats Feature</title>
<simpara>Runs over odl-openflowjava-protocol. It counts various message types / events
and reports counts in specified time periods. Statistics collection can be
configured in openflowjava-config/src/main/resources/45-openflowjava-stats.xml</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_8">
<title>Key APIs and Interfaces</title>
<simpara>Basic API / SPI classes are ConnectionAdapter (Rpc/notifications) and
SwitchConnectionProcider (configure, start, shutdown)</simpara>
</section>
<section xml:id="_installation">
<title>Installation</title>
<simpara>Pull the code and import project into your IDE.</simpara>
<screen>git clone ssh://&lt;username&gt;@git.opendaylight.org:29418/openflowjava.git</screen>

</section>
<section xml:id="_configuration_5">
<title>Configuration</title>
<simpara>Current implementation allows to configure:</simpara>
<itemizedlist>
<listitem>
<simpara>listening port (mandatory)</simpara>
</listitem>
<listitem>
<simpara>transfer protocol (mandatory)</simpara>
</listitem>
<listitem>
<simpara>switch idle timeout (mandatory)</simpara>
</listitem>
<listitem>
<simpara>TLS configuration (optional)</simpara>
</listitem>
<listitem>
<simpara>thread count (optional)</simpara>
</listitem>
</itemizedlist>

<simpara>You can find exemplary Openflow Protocol Library instance configuration below:</simpara>
<screen>&lt;data xmlns="urn:ietf:params:xml:ns:netconf:base:1.0"&gt;
  &lt;modules xmlns="urn:opendaylight:params:xml:ns:yang:controller:config"&gt;
    &lt;!-- default OF-switch-connection-provider (port 6633) --&gt;
    &lt;module&gt;
      &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:openflow:switch:connection:provider:impl"&gt;prefix:openflow-switch-connection-provider-impl&lt;/type&gt;
      &lt;name&gt;openflow-switch-connection-provider-default-impl&lt;/name&gt;
      &lt;port&gt;6633&lt;/port&gt;
&lt;!--  Possible transport-protocol options: TCP, TLS, UDP --&gt;
      &lt;transport-protocol&gt;TCP&lt;/transport-protocol&gt;
      &lt;switch-idle-timeout&gt;15000&lt;/switch-idle-timeout&gt;
&lt;!--       Exemplary TLS configuration:
            - uncomment the &lt;tls&gt; tag
            - copy exemplary-switch-privkey.pem, exemplary-switch-cert.pem and exemplary-cacert.pem
              files into your virtual machine
            - set VM encryption options to use copied keys
            - start communication
           Please visit OpenflowPlugin or Openflow Protocol Library#Documentation wiki pages
           for detailed information regarding TLS --&gt;
&lt;!--       &lt;tls&gt;
             &lt;keystore&gt;/exemplary-ctlKeystore&lt;/keystore&gt;
             &lt;keystore-type&gt;JKS&lt;/keystore-type&gt;
             &lt;keystore-path-type&gt;CLASSPATH&lt;/keystore-path-type&gt;
             &lt;keystore-password&gt;opendaylight&lt;/keystore-password&gt;
             &lt;truststore&gt;/exemplary-ctlTrustStore&lt;/truststore&gt;
             &lt;truststore-type&gt;JKS&lt;/truststore-type&gt;
             &lt;truststore-path-type&gt;CLASSPATH&lt;/truststore-path-type&gt;
             &lt;truststore-password&gt;opendaylight&lt;/truststore-password&gt;
             &lt;certificate-password&gt;opendaylight&lt;/certificate-password&gt;
           &lt;/tls&gt; --&gt;
&lt;!--       Exemplary thread model configuration. Uncomment &lt;threads&gt; tag below to adjust default thread model --&gt;
&lt;!--       &lt;threads&gt;
             &lt;boss-threads&gt;2&lt;/boss-threads&gt;
             &lt;worker-threads&gt;8&lt;/worker-threads&gt;
           &lt;/threads&gt; --&gt;
    &lt;/module&gt;</screen>

<screen>    &lt;!-- default OF-switch-connection-provider (port 6653) --&gt;
    &lt;module&gt;
      &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:openflow:switch:connection:provider:impl"&gt;prefix:openflow-switch-connection-provider-impl&lt;/type&gt;
      &lt;name&gt;openflow-switch-connection-provider-legacy-impl&lt;/name&gt;
      &lt;port&gt;6653&lt;/port&gt;
&lt;!--  Possible transport-protocol options: TCP, TLS, UDP --&gt;
      &lt;transport-protocol&gt;TCP&lt;/transport-protocol&gt;
      &lt;switch-idle-timeout&gt;15000&lt;/switch-idle-timeout&gt;
&lt;!--       Exemplary TLS configuration:
            - uncomment the &lt;tls&gt; tag
            - copy exemplary-switch-privkey.pem, exemplary-switch-cert.pem and exemplary-cacert.pem
              files into your virtual machine
            - set VM encryption options to use copied keys
            - start communication
           Please visit OpenflowPlugin or Openflow Protocol Library#Documentation wiki pages
           for detailed information regarding TLS --&gt;
&lt;!--       &lt;tls&gt;
             &lt;keystore&gt;/exemplary-ctlKeystore&lt;/keystore&gt;
             &lt;keystore-type&gt;JKS&lt;/keystore-type&gt;
             &lt;keystore-path-type&gt;CLASSPATH&lt;/keystore-path-type&gt;
             &lt;keystore-password&gt;opendaylight&lt;/keystore-password&gt;
             &lt;truststore&gt;/exemplary-ctlTrustStore&lt;/truststore&gt;
             &lt;truststore-type&gt;JKS&lt;/truststore-type&gt;
             &lt;truststore-path-type&gt;CLASSPATH&lt;/truststore-path-type&gt;
             &lt;truststore-password&gt;opendaylight&lt;/truststore-password&gt;
             &lt;certificate-password&gt;opendaylight&lt;/certificate-password&gt;
           &lt;/tls&gt; --&gt;
&lt;!--       Exemplary thread model configuration. Uncomment &lt;threads&gt; tag below to adjust default thread model --&gt;
&lt;!--       &lt;threads&gt;
             &lt;boss-threads&gt;2&lt;/boss-threads&gt;
             &lt;worker-threads&gt;8&lt;/worker-threads&gt;
           &lt;/threads&gt; --&gt;
    &lt;/module&gt;</screen>

<screen>    &lt;module&gt;
      &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:openflow:common:config:impl"&gt;prefix:openflow-provider-impl&lt;/type&gt;
      &lt;name&gt;openflow-provider-impl&lt;/name&gt;
      &lt;openflow-switch-connection-provider&gt;
        &lt;type xmlns:ofSwitch="urn:opendaylight:params:xml:ns:yang:openflow:switch:connection:provider"&gt;ofSwitch:openflow-switch-connection-provider&lt;/type&gt;
        &lt;name&gt;openflow-switch-connection-provider-default&lt;/name&gt;
      &lt;/openflow-switch-connection-provider&gt;
      &lt;openflow-switch-connection-provider&gt;
        &lt;type xmlns:ofSwitch="urn:opendaylight:params:xml:ns:yang:openflow:switch:connection:provider"&gt;ofSwitch:openflow-switch-connection-provider&lt;/type&gt;
        &lt;name&gt;openflow-switch-connection-provider-legacy&lt;/name&gt;
      &lt;/openflow-switch-connection-provider&gt;
      &lt;binding-aware-broker&gt;
        &lt;type xmlns:binding="urn:opendaylight:params:xml:ns:yang:controller:md:sal:binding"&gt;binding:binding-broker-osgi-registry&lt;/type&gt;
        &lt;name&gt;binding-osgi-broker&lt;/name&gt;
      &lt;/binding-aware-broker&gt;
    &lt;/module&gt;
  &lt;/modules&gt;</screen>

<simpara>Possible transport-protocol options:</simpara>
<itemizedlist>
<listitem>
<simpara>TCP</simpara>
</listitem>
<listitem>
<simpara>TLS</simpara>
</listitem>
<listitem>
<simpara>UDP</simpara>
</listitem>
</itemizedlist>

<simpara>Switch-idle timeout specifies time needed to detect idle state of switch. When
no message is received from switch within this time, upper layers are notified
on switch idleness.
To be able to use this exemplary TLS configuration:</simpara>
<itemizedlist>
<listitem>
<simpara>uncomment the <literal>&lt;tls&gt;</literal> tag</simpara>
</listitem>
<listitem>
<simpara>copy <emphasis>exemplary-switch-privkey.pem</emphasis>, <emphasis>exemplary-switch-cert.pem</emphasis> and
<emphasis>exemplary-cacert.pem</emphasis> files into your virtual machine</simpara>
</listitem>
<listitem>
<simpara>set VM encryption options to use copied keys (please visit TLS support wiki page
for detailed information regarding TLS)</simpara>
</listitem>
<listitem>
<simpara>start communication</simpara>
</listitem>
</itemizedlist>

<simpara>Thread model configuration specifies how many threads are desired to perform
Netty&#8217;s I/O operations.</simpara>
<itemizedlist>
<listitem>
<simpara>boss-threads specifies the number of threads that register incoming connections</simpara>
</listitem>
<listitem>
<simpara>worker-threads specifies the number of threads performing read / write
(+ serialization / deserialization) operations.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_architecture">
<title>Architecture</title>
<section xml:id="_public_api_literal_openflow_protocol_api_literal">
<title>Public API <literal>(openflow-protocol-api)</literal></title>
<simpara>Set of interfaces and builders for immutable data transfer objects representing
Openflow Protocol structures.</simpara>
<simpara>Transfer objects and service APIs are infered from several YANG models
using code generator to reduce verbosity of definition and repeatibility of code.</simpara>
<simpara>The following YANG modules are defined:</simpara>
<itemizedlist>
<listitem>
<simpara>openflow-types - defines common Openflow specific types</simpara>
</listitem>
<listitem>
<simpara>openflow-instruction - defines base Openflow instructions</simpara>
</listitem>
<listitem>
<simpara>openflow-action - defines base Openflow actions</simpara>
</listitem>
<listitem>
<simpara>openflow-augments - defines object augmentations</simpara>
</listitem>
<listitem>
<simpara>openflow-extensible-match - defines Openflow OXM match</simpara>
</listitem>
<listitem>
<simpara>openflow-protocol - defines Openflow Protocol messages</simpara>
</listitem>
<listitem>
<simpara>system-notifications - defines system notification objects</simpara>
</listitem>
<listitem>
<simpara>openflow-configuration - defines structures used in ConfigSubsystem</simpara>
</listitem>
</itemizedlist>

<simpara>This modules also reuse types from following YANG modules:</simpara>
<itemizedlist>
<listitem>
<simpara>ietf-inet-types - IP adresses, IP prefixes, IP-protocol related types</simpara>
</listitem>
<listitem>
<simpara>ietf-yang-types - Mac Address, etc.</simpara>
</listitem>
</itemizedlist>

<simpara>The use of predefined types is to make APIs contracts more safe, better readable
and documented (e.g using MacAddress instead of byte array&#8230;)</simpara>
</section>
<section xml:id="_tcp_channel_pipeline_literal_openflow_protocol_impl_literal">
<title>TCP Channel pipeline <literal>(openflow-protocol-impl)</literal></title>
<simpara>Creates channel processing pipeline based on configuration and support.</simpara>
<formalpara>
<title>TCP Channel pipeline</title>
<para>imageopenflowjava/500px-TCPChannelPipeline.png[width=500]</para>
</formalpara>
<formalpara>
<title>Switch Connection Provider</title>
<para>Implementation of connection point for other projects. Library exposes its
functionality through this class.
Library can be configured, started and shutdowned here. There are also methods
for custom (de)serializer registration.</para>
</formalpara>
<formalpara>
<title>Tcp Connection Initializer</title>
<para>In order to initialize TCP connection to a device (switch), OF Plugin calls method
<literal>initiateConnection()</literal> in <literal>SwitchConnectionProvider</literal>. This method in turn initializes
(Bootstrap) server side channel towards the device.</para>
</formalpara>
<formalpara>
<title>TCP Handler</title>
<para>Represents single server that is handling incoming connections over TCP / TLS protocol.
TCP Handler creates a single instance of TCP Channel Initializer that will initialize
channels. After that it binds to configured InetAddress and port. When a new
device connects, TCP Handler registers its channel and passes control to
TCP Channel Initializer.</para>
</formalpara>
<formalpara>
<title>TCP Channel Initializer</title>
<para>This class is used for channel initialization / rejection and passing arguments.
After a new channel has been registered it calls Switch Connection Handler&#8217;s
(OF Plugin) accept method to decide if the library should keep the newly registered
channel or if the channel should be closed. If the channel has been accepted,
TCP Channel Initializer creates the whole pipeline with needed handlers and also
with ConnectionAdapter instance. After the channel pipeline is ready, Switch
Connection Handler is notified with <literal>onConnectionReady</literal> notification.
OpenFlow Plugin can now start sending messages downstream.</para>
</formalpara>
<formalpara>
<title>Idle Handler</title>
<para>If there are no messages received for more than time specified, this handler
triggers idle state notification.
The switch idle timeout is received as a parameter from ConnectionConfiguration
settings. Idle State Handler is inactive while there are messages received within
the switch idle timeout. If there are no messages received for more than timeout
specified, handler creates SwitchIdleEvent message and sends it upstream.</para>
</formalpara>
<formalpara>
<title>TLS Handler</title>
<para>It encrypts and decrypts messages over TLS protocol.
Engaging TLS Handler into pipeline is matter of configuration (<literal>&lt;tls&gt;</literal> tag).
TLS communication is either unsupported or required. TLS Handler is represented
as a Netty&#8217;s SslHandler.</para>
</formalpara>
<formalpara>
<title>OF Frame Decoder</title>
<para>Parses input stream into correct length message frames for further processing.
Framing is based on Openflow header length. If received message is shorter than
minimal length of OpenFlow message (8 bytes), OF Frame Decoder waits for more data.
After receiving at least 8 bytes the decoder checks length in OpenFlow header.
If there are still some bytes missing, the decoder waits for them. Else the OF
Frame Decoder sends correct length message to next handler in the channel pipeline.</para>
</formalpara>
<formalpara>
<title>OF Version Detector</title>
<para>Detects version of used OpenFlow Protocol and discards unsupported version messages.
If the detected version is supported, OF Version Detector creates
<literal>VersionMessageWrapper</literal> object containing the detected version and byte message
and sends this object upstream.</para>
</formalpara>
<formalpara>
<title>OF Decoder</title>
<para>Chooses correct deserilization factory (based on message type) and deserializes
messages into generated DTOs (Data Transfer Object).
OF Decoder receives <literal>VersionMessageWrapper</literal> object and passes it to
<literal>DeserializationFactory</literal> which will return translated DTO. <literal>DeserializationFactory</literal>
creates <literal>MessageCodeKey</literal> object with version and type of received message and
Class of object that will be the received message deserialized into. This object
is used as key when searching for appropriate decoder in <literal>DecoderTable</literal>.
<literal>DecoderTable</literal> is basically a map storing decoders. Found decoder translates
received message into DTO. If there was no decoder found, null is returned. After
returning translated DTO back to OF Decoder, the decoder checks if it is null or not.
When the DTO is null, the decoder logs this state and throws an Exception. Else it
passes the DTO further upstream. Finally, the OF Decoder releases ByteBuf containing
received and decoded byte message.</para>
</formalpara>
<formalpara>
<title>OF Encoder</title>
<para>Chooses correct serialization factory (based on type of DTO) and serializes DTOs
into byte messages.
OF Encoder does the opposite than the OF Decoder using the same principle.
OF Encoder receives DTO, passes it for translation and if the result is not null,
it sends translated DTO downstream as a ByteBuf. Searching for appropriate encoder
is done via MessageTypeKey, based on version and class of received DTO.</para>
</formalpara>
<formalpara>
<title>Delegating Inbound Handler</title>
<para>Delegates received DTOs to Connection Adapter.
It also reacts on channelInactive and channelUnregistered events. Upon one of
these events is triggered, DelegatingInboundHandler creates DisconnectEvent message
and sends it upstream, notifying upper layers about switch disconnection.</para>
</formalpara>
<formalpara>
<title>Channel Outbound Queue</title>
<para>Message flushing handler.
Stores outgoing messages (DTOs) and flushes them. Flush is performed based on time
expired and on the number of messages enqueued.</para>
</formalpara>
<formalpara>
<title>Connection Adapter</title>
<para>Provides a facade on top of pipeline, which hides netty.io specifics. Provides a
set of methods to register for incoming messages and to send messages to particular
channel / session.
ConnectionAdapterImpl basically implements three interfaces (unified in one
superinterface ConnectionFacade):</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>ConnectionAdapter</simpara>
</listitem>
<listitem>
<simpara>MessageConsumer</simpara>
</listitem>
<listitem>
<simpara>OpenflowProtocolService</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">ConnectionAdapter</emphasis> interface has methods for setting up listeners (message,
system and connection ready listener), method to check if all listeners are set,
checking if the channel is alive and disconnect method. Disconnect method clears
responseCache and disables consuming of new messages.</simpara>
<simpara><emphasis role="strong">MessageConsumer</emphasis> interface holds only one method: <literal>consume()</literal>. <literal>Consume()</literal> method
is called from DelegatingInboundHandler. This method processes received DTO&#8217;s based
on their type. There are three types of received objects:</simpara>
<itemizedlist>
<listitem>
<simpara>System notifications - invoke system notifications in OpenFlow Plugin
(systemListener set). In case of <literal>DisconnectEvent</literal> message, the Connection Adapter
clears response cache and disables consume() method processing,</simpara>
</listitem>
<listitem>
<simpara>OpenFlow asynchronous messages (from switch) - invoke corresponding notifications
in OpenFlow Plugin,</simpara>
</listitem>
<listitem>
<simpara>OpenFlow symmetric messages (replies to requests) - create <literal>RpcResponseKey</literal>
with XID and DTO&#8217;s class set. This <literal>RpcResponseKey</literal> is then used to find
corresponding future object in responseCache. Future object is set with success
flag, received message and errors (if any occurred). In case no corresponding
future was found in responseCache, Connection Adapter logs warning and discards
the message. Connection Adapter also logs warning when an unknown DTO is received.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">OpenflowProtocolService</emphasis> interface contains all rpc-methods for sending messages
from upper layers (OpenFlow Plugin) downstream and responding. Request messages
return Future filled with expected reply message, otherwise the expected Future
is of type Void.</simpara>
<simpara><emphasis role="strong">NOTE:</emphasis>
MultipartRequest message is the only exception. Basically it is request - reply
Message type, but it wouldn&#8217;t be able to process more following MultipartReply
messages if this was implemented as rpc (only one Future). This is why MultipartReply
is implemented as notification. OpenFlow Plugin takes care of correct message
processing.</simpara>
</section>
<section xml:id="_udp_channel_pipeline_openflow_protocol_impl">
<title>UDP Channel pipeline (openflow-protocol-impl)</title>
<simpara>Creates UDP channel processing pipeline based on configuration and support.
<emphasis role="strong">Switch Connection Provider</emphasis>, <emphasis role="strong">Channel Outbound Queue</emphasis> and <emphasis role="strong">Connection Adapter</emphasis>
fulfill the same role as in case of TCP connection / channel pipeline (please
see above).</simpara>
<figure>
<title>UDP Channel pipeline</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowjava/500px-UdpChannelPipeline.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>500px UdpChannelPipeline</phrase></textobject>
  </mediaobject>
</figure>

<formalpara>
<title>UDP Handler</title>
<para>Represents single server that is handling incoming connections over UDP (DTLS)
protocol.
UDP Handler creates a single instance of UDP Channel Initializer that will
initialize channels. After that it binds to configured InetAddress and port.
When a new device connects, UDP Handler registers its channel and passes control
to UDP Channel Initializer.</para>
</formalpara>
<formalpara>
<title>UDP Channel Initializer</title>
<para>This class is used for channel initialization and passing arguments.
After a new channel has been registered (for UDP there is always only one channel)
UDP Channel Initializer creates whole pipeline with needed handlers.</para>
</formalpara>
<formalpara>
<title>DTLS Handler</title>
<para>Haven&#8217;t been implemented yet. Will take care of secure DTLS connections.</para>
</formalpara>
<formalpara>
<title>OF Datagram Packet Handler</title>
<para>Combines functionality of OF Frame Decoder and OF Version Detector. Extracts
messages from received datagram packets and checks if message version is supported.
If there is a message received from yet unknown sender, OF Datagram Packet Handler
creates Connection Adapter for this sender and stores it under sender&#8217;s address in
<literal>UdpConnectionMap</literal>. This map is also used for sending the messages and for correct
Connection Adapter lookup - to delegate messages from one channel to multiple sessions.</para>
</formalpara>
<formalpara>
<title>OF Datagram Packet Decoder</title>
<para>Chooses correct deserilization factory (based on message type) and deserializes
messages into generated DTOs.
OF Decoder receives <literal>VersionMessageUdpWrapper</literal> object and passes it to
<literal>DeserializationFactory</literal> which will return translated DTO. <literal>DeserializationFactory</literal>
creates <literal>MessageCodeKey</literal> object with version and type of received message and
Class of object that will be the received message deserialized into. This object
is used as key when searching for appropriate decoder in <literal>DecoderTable</literal>.
<literal>DecoderTable</literal> is basically a map storing decoders. Found decoder translates
received message into DTO (DataTransferObject). If there was no decoder found,
null is returned. After returning translated DTO back to OF Datagram Packet Decoder,
the decoder checks if it is null or not. When the DTO is null, the decoder logs
this state. Else it looks up appropriate Connection Adapter in <literal>UdpConnectionMap</literal>
and passes the DTO to found Connection Adapter. Finally, the OF Decoder releases
<literal>ByteBuf</literal> containing received and decoded byte message.</para>
</formalpara>
<formalpara>
<title>OF Datagram Packet Encoder</title>
<para>Chooses correct serialization factory (based on type of DTO) and serializes DTOs
into byte messages.
OF Datagram Packet Encoder does the opposite than the OF Datagram Packet Decoder
using the same principle. OF Encoder receives DTO, passes it for translation and
if the result is not null, it sends translated DTO downstream as a datagram packet.
Searching for appropriate encoder is done via MessageTypeKey, based on version
and class of received DTO.</para>
</formalpara>
</section>
<section xml:id="_spi_openflow_protocol_spi">
<title>SPI (openflow-protocol-spi)</title>
<simpara>Defines interface for library&#8217;s connection point for other projects. Library
exposes its functionality through this interface.</simpara>
</section>
<section xml:id="_integration_test_openflow_protocol_it">
<title>Integration test (openflow-protocol-it)</title>
<simpara>Testing communication with simple client.</simpara>
</section>
<section xml:id="_simple_client_simple_client">
<title>Simple client(simple-client)</title>
<simpara>Lightweight switch simulator - programmable with desired scenarios.</simpara>
</section>
<section xml:id="_utility_util">
<title>Utility (util)</title>
<simpara>Contains utility classes, mainly for work with ByteBuf.</simpara>
</section>
</section>
<section xml:id="_library_s_lifecycle">
<title>Library&#8217;s lifecycle</title>
<simpara>Steps (after the library&#8217;s bundle is started):</simpara>
<itemizedlist>
<listitem>
<simpara>[1] Library is configured by ConfigSubsystem (adress, ports, encryption, &#8230;)</simpara>
</listitem>
<listitem>
<simpara>[2] Plugin injects its SwitchConnectionHandler into the Library</simpara>
</listitem>
<listitem>
<simpara>[3] Plugin starts the Library</simpara>
</listitem>
<listitem>
<simpara>[4] Library creates configured protocol handler (e.g. TCP Handler)</simpara>
</listitem>
<listitem>
<simpara>[5] Protocol Handler creates Channel Initializer</simpara>
</listitem>
<listitem>
<simpara>[6] Channel Initializer asks plugin whether to accept incoming connection on
each new switch connection</simpara>
</listitem>
<listitem>
<simpara>[7] Plugin responds:</simpara>
<itemizedlist>
<listitem>
<simpara>true - continue building pipeline</simpara>
</listitem>
<listitem>
<simpara>false - reject connection / disconnect channel</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>[8] Library notifies Plugin with onSwitchConnected(ConnectionAdapter)
notification, passing reference to ConnectionAdapter, that will handle the connection</simpara>
</listitem>
<listitem>
<simpara>[9] Plugin registers its system and message listeners</simpara>
</listitem>
<listitem>
<simpara>[10] FireConnectionReadyNotification() is triggered, announcing that pipeline
handlers needed for communication have been created and Plugin can start
communication</simpara>
</listitem>
<listitem>
<simpara>[11] Plugin shutdowns the Library when desired</simpara>
</listitem>
</itemizedlist>

<figure>
<title>Library lifecycle</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowjava/Library_lifecycle.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Library lifecycle</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_statistics_collection">
<title>Statistics collection</title>
<section xml:id="_introduction_2">
<title>Introduction</title>
<simpara>Statistics collection collects message statistics.
Current collected statistics (<literal>DS</literal> - downstream, <literal>US</literal> - upstream):</simpara>
<itemizedlist>
<listitem>
<simpara><literal>DS_ENTERED_OFJAVA</literal> - all messages that entered openflowjava (picked up from
openflowplugin)</simpara>
</listitem>
<listitem>
<simpara><literal>DS_ENCODE_SUCCESS</literal> - successfully encoded messages</simpara>
</listitem>
<listitem>
<simpara><literal>DS_ENCODE_FAIL</literal> - messages that failed during encoding (serialization) process</simpara>
</listitem>
<listitem>
<simpara><literal>DS_FLOW_MODS_ENTERED</literal> - all flow-mod messages that entered openflowjava</simpara>
</listitem>
<listitem>
<simpara><literal>DS_FLOW_MODS_SENT</literal> - all flow-mod messages that were successfully sent</simpara>
</listitem>
<listitem>
<simpara><literal>US_RECEIVED_IN_OFJAVA</literal> - messages received from switch</simpara>
</listitem>
<listitem>
<simpara><literal>US_DECODE_SUCCESS</literal> - successfully decoded messages</simpara>
</listitem>
<listitem>
<simpara><literal>US_DECODE_FAIL</literal> - messages that failed during decoding (deserialization) process</simpara>
</listitem>
<listitem>
<simpara><literal>US_MESSAGE_PASS</literal> - messages handed over to openflowplugin</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_karaf">
<title>Karaf</title>
<simpara>In orded to start statistics, it is needed to feature:install odl-openflowjava-stats.
To see the logs one should use log:set DEBUG org.opendaylight.openflowjava.statistics
and than probably log:display (you can log:list to see if the logging has been set).
To adjust collection settings it is enough to modify 45-openflowjava-stats.xml.</simpara>
</section>
<section xml:id="_jconsole">
<title>JConsole</title>
<simpara>JConsole provides two commands for the statistics collection:</simpara>
<itemizedlist>
<listitem>
<simpara>printing current statistics</simpara>
</listitem>
<listitem>
<simpara>resetting statistic counters</simpara>
</listitem>
</itemizedlist>

<simpara>After attaching JConsole to correct process, one only needs to go into MBeans
<literal>tab &#8594; org.opendaylight.controller &#8594; RuntimeBean &#8594; statistics-collection-service-impl
&#8594; statistics-collection-service-impl &#8594; Operations</literal>  to be able to use this commands.</simpara>
</section>
</section>
<section xml:id="_tls_support">
<title>TLS Support</title>
<note>
<simpara>see OpenFlow Plugin Developper Guide</simpara>
</note>

</section>
<section xml:id="_extensibility">
<title>Extensibility</title>
<section xml:id="_introduction_3">
<title>Introduction</title>
<simpara>Entry point for the extensibility is <literal>SwitchConnectionProvider</literal>.
<literal>SwitchConnectionProvider</literal> contains methods for (de)serializer registration.
To register deserializer it is needed to use .register*Deserializer(key, impl).
To register serializer one must use .register*Serializer(key, impl). Registration
can occur either during configuration or at runtime.</simpara>
<simpara><emphasis role="strong">NOTE</emphasis>: In case when experimenter message is received and no (de)serializer was
registered, the library will throw <literal>IllegalArgumentException</literal>.</simpara>
</section>
<section xml:id="_basic_principle">
<title>Basic Principle</title>
<simpara>In order to use extensions it is needed to augment existing model and register new (de)serializers.</simpara>
<simpara>Augmenting the model:
1. Create new augmentation</simpara>
<simpara>Register (de)serializers:
1. Create your (de)serializer
2. Let it implement <literal>OFDeserializer&lt;&gt;</literal> / <literal>OFSerializer&lt;&gt;</literal>
- in case the structure you are (de)serializing needs to be used in Multipart
TableFeatures messages, let it implement <literal>HeaderDeserializer&lt;&gt;</literal> / <literal>HeaderSerializer</literal>
3. Implement prescribed methods
4. Register your deserializer under appropriate key (in our case
<literal>ExperimenterActionDeserializerKey</literal>)
5. Register your serializer under appropriate key (in our case
<literal>ExperimenterActionSerializerKey</literal>)
6. Done, test your implementation</simpara>
<simpara><emphasis role="strong">NOTE</emphasis>: If you don&#8217;t know what key should be used with your (de)serializer
implementation, please visit <link linkend="registration_keys">Registration keys</link> page.</simpara>
</section>
<section xml:id="_example">
<title>Example</title>
<simpara>Let&#8217;s say we have vendor / experimenter action represented by this structure:</simpara>
<screen>struct foo_action {
    uint16_t type;
    uint16_t length;
    uint32_t experimenter;
    uint16_t first;
    uint16_t second;
    uint8_t  pad[4];
}</screen>

<simpara>First, we have to augment existing model. We create new module, which imports
"<literal>openflow-types.yang</literal>" (don&#8217;t forget to update your <literal>pom.xml</literal> with api dependency).
Now we create foo action identity:</simpara>
<screen>import openflow-types {prefix oft;}
identity foo {
    description "Foo action description";
    base oft:action-base;
}</screen>

<simpara>This will be used as type in our structure. Now we must augment existing action
structure, so that we will have the desired fields first and second. In order to
create new augmentation, our module has to import "<literal>openflow-action.yang</literal>". The
augment should look like this:</simpara>
<screen>import openflow-action {prefix ofaction;}
augment "/ofaction:actions-container/ofaction:action" {
    ext:augment-identifier "foo-action";
        leaf first {
            type uint16;
        }
        leaf second {
            type uint16;
        }
    }</screen>

<simpara>We are finished with model changes. Run mvn clean compile to generate sources.
After generation is done, we need to implement our (de)serializer.</simpara>
<simpara>Deserializer:</simpara>
<screen>public class FooActionDeserializer extends OFDeserializer&lt;Action&gt; {
   @Override
   public Action deserialize(ByteBuf input) {
       ActionBuilder builder = new ActionBuilder();
       input.skipBytes(SIZE_OF_SHORT_IN_BYTES); *// we know the type of action*
       builder.setType(Foo.class);
       input.skipBytes(SIZE_OF_SHORT_IN_BYTES); *// we don't need length*
       *// now create experimenterIdAugmentation - so that openflowplugin can
       differentiate correct vendor codec*
       ExperimenterIdActionBuilder expIdBuilder = new ExperimenterIdActionBuilder();
       expIdBuilder.setExperimenter(new ExperimenterId(input.readUnsignedInt()));
       builder.addAugmentation(ExperimenterIdAction.class, expIdBuilder.build());
       FooActionBuilder fooBuilder = new FooActionBuilder();
       fooBuilder.setFirst(input.readUnsignedShort());
       fooBuilder.setSecond(input.readUnsignedShort());
       builder.addAugmentation(FooAction.class, fooBuilder.build());
       input.skipBytes(4); *// padding*
       return builder.build();
   }
}</screen>

<simpara>Serializer:</simpara>
<screen>public class FooActionSerializer extends OFSerializer&lt;Action&gt; {
   @Override
   public void serialize(Action action, ByteBuf outBuffer) {
       outBuffer.writeShort(FOO_CODE);
       outBuffer.writeShort(16);
       *// we don't have to check for ExperimenterIdAction augmentation - our
       serializer*
       *// was called based on the vendor / experimenter ID, so we simply write
       it to buffer*
       outBuffer.writeInt(VENDOR / EXPERIMENTER ID);
       FooAction foo = action.getAugmentation(FooAction.class);
       outBuffer.writeShort(foo.getFirst());
       outBuffer.writeShort(foo.getSecond());
       outBuffer.writeZero(4); //write padding
   }
}</screen>

<simpara>Register both deserializer and serializer:
<literal>SwitchConnectionProvider.registerDeserializer(new
ExperimenterActionDeserializerKey(0x04, VENDOR / EXPERIMENTER ID),
new FooActionDeserializer());</literal>
<literal>SwitchConnectionProvider.registerSerializer(new
ExperimenterActionSerializerKey(0x04, VENDOR / EXPERIMENTER ID),
new FooActionSerializer());</literal></simpara>
<simpara>We are ready to test our implementation.</simpara>
<simpara><emphasis role="strong">NOTE:</emphasis> Vendor / Experimenter structures define only vendor / experimenter ID as
common distinguisher (besides action type). Vendor / Experimenter ID is unique
for all vendor messages - that&#8217;s why vendor is able to register only one class
under ExperimenterAction(De)SerializerKey. And that&#8217;s why vendor has to switch
/ choose between his subclasses / subtypes on his own.</simpara>
</section>
<section xml:id="_detailed_walkthrough_deserialization_extensibility">
<title>Detailed walkthrough: Deserialization extensibility</title>
<formalpara>
<title>External interface &amp; class description</title>
<para><emphasis role="strong">OFGeneralDeserializer:</emphasis></para>
</formalpara>
<itemizedlist>
<listitem>
<simpara><literal>OFDeserializer&lt;E extends DataObject&gt;</literal></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>deserialize(ByteBuf)</emphasis> - deserializes given ByteBuf</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><literal>HeaderDeserializer&lt;E extends DataObject&gt;</literal></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>deserializeHeaders(ByteBuf)</emphasis> - deserializes only E headers (used in Multipart
TableFeatures messages)</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara><emphasis role="strong">DeserializerRegistryInjector</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara><literal>injectDeserializerRegistry(DeserializerRegistry)</literal> - injects deserializer
registry into deserializer. Useful when custom deserializer needs access to
other deserializers.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">NOTE:</emphasis> DeserializerRegistryInjector is not OFGeneralDeserializer descendand.
It is a standalone interface.</simpara>
<simpara><emphasis role="strong">MessageCodeKey and its descendants</emphasis>
These keys are used as for deserializer lookup in DeserializerRegistry.
MessageCodeKey should is used in general, while its descendants are used in more
special cases. For Example ActionDeserializerKey is used for Action deserializer
lookup and (de)registration. Vendor is provided with special keys, which contain
only the most necessary fields. These keys usually start with "Experimenter"
prefix (MatchEntryDeserializerKey is an exception).</simpara>
<simpara>MessageCodeKey has these fields:</simpara>
<itemizedlist>
<listitem>
<simpara>short version - Openflow wire version number</simpara>
</listitem>
<listitem>
<simpara>int value - value read from byte message</simpara>
</listitem>
<listitem>
<simpara>Class&lt;?&gt; clazz - class of object being creating</simpara>
</listitem>
</itemizedlist>

<itemizedlist>
<title>Scenario walkthrough</title>
<listitem>
<simpara>[1] The scenario starts in a custom bundle which wants to extend library&#8217;s
functionality. The custom bundle creates deserializers which implement exposed
<literal>OFDeserializer</literal> / <literal>HeaderDeserializer</literal> interfaces (wrapped under
<literal>OFGeneralDeserializer</literal> unifying super interface).</simpara>
</listitem>
<listitem>
<simpara>[2] Created deserializers are paired with corresponding ExperimenterKeys,
which are used for deserializer lookup.
If you don&#8217;t know what key should be used with your (de)serializer implementation,
please visit <link linkend="registration_keys">Registration keys</link> page.</simpara>
</listitem>
<listitem>
<simpara>[3] Paired deserializers are passed to the OF Library
via <emphasis role="strong">SwitchConnectionProvider</emphasis>.<emphasis>registerCustomDeserializer(key, impl)</emphasis>.
Library registers the deserializer.</simpara>
<itemizedlist>
<listitem>
<simpara>While registering, Library checks if the deserializer is an instance of
<emphasis role="strong">DeserializerRegistryInjector</emphasis> interface. If yes, the DeserializerRegistry
(which stores all deserializer references) is injected into the deserializer.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara>This is particularly useful when the deserializer needs access to other
deserializers. For example <literal>IntructionsDeserializer</literal> needs access to
<literal>ActionsDeserializer</literal> in order to be able to process
OFPIT_WRITE_ACTIONS/OFPIT_APPLY_ACTIONS instructions.</simpara>
<figure>
<title>Deserialization scenario walkthrough</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowjava/800px-Extensibility.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>800px Extensibility</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_detailed_walkthrough_serialization_extensibility">
<title>Detailed walkthrough: Serialization extensibility</title>
<formalpara>
<title>External interface &amp; class description</title>
<para><emphasis role="strong">OFGeneralSerializer:</emphasis></para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>OFSerializer&lt;E extends DataObject&gt;</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>serialize(E,ByteBuf)</emphasis> - serializes E into given ByteBuf</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><literal>HeaderSerializer&lt;E extends DataObject&gt;</literal></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>serializeHeaders(E,ByteBuf)</emphasis> - serializes E headers (used in Multipart
TableFeatures messages)</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara><emphasis role="strong">SerializerRegistryInjector</emphasis>
* <literal>injectSerializerRegistry(SerializerRegistry)</literal> - injects serializer registry
into serializer. Useful when custom serializer needs access to other serializers.</simpara>
<simpara><emphasis role="strong">NOTE:</emphasis> SerializerRegistryInjector is not OFGeneralSerializer descendand.</simpara>
<simpara><emphasis role="strong">MessageTypeKey and its descendants</emphasis>
These keys are used as for serializer lookup in SerializerRegistry.
MessageTypeKey should is used in general, while its descendants are used in more
special cases. For Example ActionSerializerKey is used for Action serializer
lookup and (de)registration. Vendor is provided with special keys, which contain
only the most necessary fields. These keys usually start with "Experimenter"
prefix (MatchEntrySerializerKey is an exception).</simpara>
<simpara>MessageTypeKey has these fields:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>short version</emphasis> - Openflow wire version number</simpara>
</listitem>
<listitem>
<simpara><emphasis>Class&lt;E&gt; msgType</emphasis> - DTO class</simpara>
</listitem>
</itemizedlist>

<simpara>Scenario walkthrough</simpara>
<itemizedlist>
<listitem>
<simpara>[1] Serialization extensbility principles are similar to the deserialization
principles. The scenario starts in a custom bundle. The custom bundle creates
serializers which implement exposed OFSerializer / HeaderSerializer interfaces
(wrapped under OFGeneralSerializer unifying super interface).</simpara>
</listitem>
<listitem>
<simpara>[2] Created serializers are paired with their ExperimenterKeys, which are used
for serializer lookup.
If you don&#8217;t know what key should be used with your serializer implementation,
please visit <link linkend="registration_keys">Registration keys</link> page.</simpara>
</listitem>
<listitem>
<simpara>[3] Paired serializers are passed to the OF Library via
<emphasis role="strong">SwitchConnectionProvider</emphasis>.<emphasis>registerCustomSerializer(key, impl)</emphasis>. Library
registers the serializer.</simpara>
</listitem>
<listitem>
<simpara>While registering, Library checks if the serializer is an instance of
<emphasis role="strong">SerializerRegistryInjector</emphasis> interface. If yes, the SerializerRegistry (which
stores all serializer references) is injected into the serializer.</simpara>
</listitem>
</itemizedlist>

<simpara>This is particularly useful when the serializer needs access to other deserializers.
For example IntructionsSerializer needs access to ActionsSerializer in order to
be able to process OFPIT_WRITE_ACTIONS/OFPIT_APPLY_ACTIONS instructions.</simpara>
<figure>
<title>Serialization scenario walkthrough</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowjava/800px-Extensibility2.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>800px Extensibility2</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_internal_description">
<title>Internal description</title>
<simpara><emphasis role="strong">SwitchConnectionProvider</emphasis>
<literal>SwitchConnectionProvider</literal> constructs and initializes both deserializer and
serializer registries with default (de)serializers. It also injects the
<literal>DeserializerRegistry</literal> into the <literal>DeserializationFactory</literal>, the <literal>SerializerRegistry</literal>
into the <literal>SerializationFactory</literal>.
When call to register custom (de)serializer is made, <literal>SwitchConnectionProvider</literal>
calls register method on appropriate registry.</simpara>
<simpara><emphasis role="strong">DeserializerRegistry / SerializerRegistry</emphasis>
Both registries contain init() method to initialize default (de)serializers.
Registration checks if key or (de)serializer implementation are not <literal>null</literal>. If at
least one of the is <literal>null</literal>, <literal>NullPointerException</literal> is thrown. Else the
(de)serializer implementation is checked if it is <literal>(De)SerializerRegistryInjector</literal>
instance. If it is an instance of this interface, the registry is injected into
this (de)serializer implementation.</simpara>
<simpara><literal>GetSerializer(key)</literal> or <literal>GetDeserializer(key)</literal> performs registry lookup. Because
there are two separate interfaces that might be put into the registry, the
registry uses their unifying super interface. Get(De)Serializer(key) method casts
the super interface to desired type. There is also a null check for the
(de)serializer received from the registry. If the deserializer wasn&#8217;t found,
<literal>NullPointerException</literal> with key description is thrown.</simpara>
</section>
<section xml:id="registration_keys">
<title>Registration keys</title>
<formalpara>
<title>Deserialization</title>
<para><emphasis role="strong">Possible openflow extensions and their keys</emphasis></para>
</formalpara>
<simpara>There are three vendor specific extensions in Openflow v1.0 and eight in
Openflow v1.3. These extensions are registered under registration keys,
that are shown in table below:</simpara>
<table frame="all"
    rowsep="1" colsep="1">
<title><emphasis role="strong">Deserialization</emphasis></title>
  
  <tgroup cols="4">
    
    <colspec colname="col_1" colwidth="20*"/>
    
    <colspec colname="col_2" colwidth="10*"/>
    
    <colspec colname="col_3" colwidth="40*"/>
    
    <colspec colname="col_4" colwidth="30*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Extension type</entry>
        
        <entry align="left" valign="top">OpenFlow</entry>
        
        <entry align="left" valign="top">Registration key</entry>
        
        <entry align="left" valign="top">Utility class</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Vendor message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(1, experimenterId, ExperimenterMessage.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Action</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterActionDeserializerKey(1, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Stats message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterMultipartReplyMessageDeserializerKey(1, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Experimenter message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, ExperimenterMessage.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Match entry</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>MatchEntryDeserializerKey(4, (number) ${oxm_class}, (number) ${oxm_field});</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"></entry>
        
        <entry align="left" valign="top"></entry>
        
        <entry align="left" valign="top"><simpara>key.setExperimenterId(experimenter ID);</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Action</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterActionDeserializerKey(4, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Instruction</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterInstructionDeserializerKey(4, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Multipart</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, MultipartReplyMessage.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Multipart - Table features</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, TableFeatureProperties.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Error</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, ErrorMessage.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Queue property</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, QueueProperty.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Meter band type</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdDeserializerKey(4, experimenterId, MeterBandExperimenterCase.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterDeserializerKeyFactory</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</table>

<formalpara>
<title>Serialization</title>
<para><emphasis role="strong">Possible openflow extensions and their keys</emphasis></para>
</formalpara>
<simpara>There are three vendor specific extensions in Openflow v1.0 and seven Openflow
v1.3. These extensions are registered under registration keys, that are shown in
table below:</simpara>
<table frame="all"
    rowsep="1" colsep="1">
<title><emphasis role="strong">Serialization</emphasis></title>
  
  <tgroup cols="4">
    
    <colspec colname="col_1" colwidth="20*"/>
    
    <colspec colname="col_2" colwidth="10*"/>
    
    <colspec colname="col_3" colwidth="40*"/>
    
    <colspec colname="col_4" colwidth="30*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Extension type</entry>
        
        <entry align="left" valign="top">OpenFlow</entry>
        
        <entry align="left" valign="top">Registration key</entry>
        
        <entry align="left" valign="top">Utility class</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Vendor message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdSerializerKey&lt;&gt;(1, experimenterId, ExperimenterInput.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Action</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterActionSerializerKey(1, experimenterId, sub-type)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Stats message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.0</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterMultipartRequestSerializerKey(1, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Experimenter message</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdSerializerKey&lt;&gt;(4, experimenterId, ExperimenterInput.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Match entry</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>MatchEntrySerializerKey&lt;&gt;(4, (class) ${oxm_class}, (class) ${oxm_field});</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"></entry>
        
        <entry align="left" valign="top"></entry>
        
        <entry align="left" valign="top"><simpara>key.setExperimenterId(experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Action</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterActionSerializerKey(4, experimenterId, sub-type)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Instruction</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterInstructionSerializerKey(4, experimenter ID)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Multipart</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdSerializerKey&lt;&gt;(4, experimenterId, MultipartRequestExperimenterCase.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Multipart - Table features</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdSerializerKey&lt;&gt;(4, experimenterId, TableFeatureProperties.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Meter band type</simpara></entry>
        
        <entry align="left" valign="top"><simpara>1.3</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterIdSerializerKey&lt;&gt;(4, experimenterId, MeterBandExperimenterCase.class)</simpara></entry>
        
        <entry align="left" valign="top"><simpara>ExperimenterSerializerKeyFactory</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</table>

</section>
</section>
</chapter>
<chapter xml:id="openflow-plugin-project-developer-guide">
<title>OpenFlow Plugin Project Developer Guide</title>
<simpara>This section covers topics which are developer specific and which have not been
covered in the user guide. Please see the Lithium OpenFlow plugin user
guide first.</simpara>
<simpara>It can be found on <link xlink:href="https://www.opendaylight.org/downloads">the OpenDaylight software download page</link>.</simpara>
<section xml:id="_event_sequences">
<title>Event Sequences</title>
<section xml:id="_session_establishment">
<title>Session Establishment</title>
<simpara>The <link linkend="_openflow_protocol_library_developer_guide">OpenFlow Protocol Library</link> provides interface <emphasis role="strong">SwitchConnectionHandler</emphasis> which contains method <emphasis>onSwitchConnected</emphasis> (step 1). This event is raised in the OpenFlow Protocol Library when an OpenFlow device connects to OpenDaylight and caught in the <emphasis role="strong">ConnectionManagerImpl</emphasis> class in the OpenFlow plugin.</simpara>
<simpara>There the plugin creates a new instance of the <emphasis role="strong">ConnectionContextImpl</emphasis> class (step 1.1) and also instances of <emphasis role="strong">HandshakeManagerImpl</emphasis> (which uses <emphasis role="strong">HandshakeListenerImpl</emphasis>) and <emphasis role="strong">ConnectionReadyListenerImpl</emphasis>. <emphasis role="strong">ConnectionReadyListenerImpl</emphasis> contains method <emphasis>onConnectionReady()</emphasis> which is called when connection is prepared. This method starts the handshake with the OpenFlow device (switch) from the OpenFlow plugin side. Then handshake can be also started from device side. In this case method <emphasis>shake()</emphasis> from <emphasis role="strong">HandshakeManagerImpl</emphasis> is called (steps 1.1.1 and 2).</simpara>
<simpara>The handshake consists of an exchange of HELLO messages in addition to an exchange of device features (steps 2.1. and 3). The handshake is completed by <emphasis role="strong">HandshakeManagerImpl</emphasis>. After receiving device features, the <emphasis role="strong">HandshakeListenerImpl</emphasis> is notifed via the <emphasis>onHanshakeSuccessfull()</emphasis> method. After this, the device features, node id and connection state are stored in a <emphasis role="strong">ConnectionContext</emphasis> and the method <emphasis>deviceConnected()</emphasis> of <emphasis role="strong">DeviceManagerImpl</emphasis> is called.</simpara>
<simpara>When <emphasis>deviceConnected()</emphasis> is called, it does the following:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>creates a new transaction chain (step 4.1)</simpara>
</listitem>
<listitem>
<simpara>creates a new instance of <emphasis role="strong">DeviceContext</emphasis> (step 4.2.2)</simpara>
</listitem>
<listitem>
<simpara>initializes the device context: the static context of device is populated by calling <emphasis>createDeviceFeaturesForOF&lt;version&gt;()</emphasis> to populate table, group, meter features and port descriptions (step 4.2.1 and 4.2.1.1)</simpara>
</listitem>
<listitem>
<simpara>creates an instance of <emphasis role="strong">RequestContext</emphasis> for each type of feature</simpara>
</listitem>
</orderedlist>

<simpara>When the OpenFlow device responds to these requests (step 4.2.1.1) with multipart replies (step 5) they are processed and stored to MD-SAL operational datastore. The  <emphasis>createDeviceFeaturesForOF&lt;version&gt;()</emphasis> method returns a <emphasis role="strong">Future</emphasis> which is processed in the callback (step 5.1) (part of <emphasis>initializeDeviceContext()</emphasis> in the <emphasis>deviceConnected()</emphasis> method) by calling the method <emphasis>onDeviceCtxLevelUp()</emphasis> from <emphasis role="strong">StatisticsManager</emphasis> (step 5.1.1).</simpara>
<simpara>The call to <emphasis>createDeviceFeaturesForOF&lt;version&gt;()</emphasis>:
. creates a new instance of <emphasis role="strong">StatisticsContextImpl</emphasis> (step 5.1.1.1).</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>calls <emphasis>gatherDynamicStatistics()</emphasis> on that instance which returns a <emphasis role="strong">Future</emphasis> which will produce a value when done</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>this method calls methods to get dynamic data (flows, tables, groups) from the device (step 5.1.1.2, 5.1.1.2.1, 5.1.1.2.1.1)</simpara>
</listitem>
<listitem>
<simpara>if everything works, this data is also stored in the MD-SAL operational datastore</simpara>
</listitem>
</orderedlist>

</listitem>
</orderedlist>

<simpara>If the <emphasis role="strong">Future</emphasis> is successful, it is processed (step 6.1.1) in a callback in <emphasis role="strong">StatisticsManagerImpl</emphasis> which:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>schedules the next time to poll the device for statistics</simpara>
</listitem>
<listitem>
<simpara>sets the device state to synchronized (step 6.1.1.2)</simpara>
</listitem>
<listitem>
<simpara>calls <emphasis>onDeviceContextLevelUp()</emphasis> in <emphasis role="strong">RpcManagerImpl</emphasis></simpara>
</listitem>
</orderedlist>

<simpara>The <emphasis>onDeviceContextLevelUp()</emphasis> call:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>creates a new instance of <emphasis role="strong">RequestContextImpl</emphasis></simpara>
</listitem>
<listitem>
<simpara>registers implementation for supported services</simpara>
</listitem>
<listitem>
<simpara>calls <emphasis>onDeviceContextLevelUp()</emphasis> in <emphasis role="strong">DeviceManagerImpl</emphasis> (step 6.1.1.2.1.2) which causes the information about the new device be be written to the MD-SAL operational datastore (step 6.1.1.2.2)</simpara>
</listitem>
</orderedlist>

<figure>
<title>Session establishment</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowplugin/odl-ofp-session-establishment.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>SessionEstablishment</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_handshake_2">
<title>Handshake</title>
<simpara>The first thing that happens when an OpenFlow device connects to OpenDaylight is that the OpenFlow plugin gathers basic information about the device and establishes agreement on key facts like the version of OpenFlow which will be used. This process is called the handshake.</simpara>
<simpara>The handshake starts with HELLO message which can be sent either by the OpenFlow device or the OpenFlow plugin. After this, there are several scenarios which can happen:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>if the first HELLO message contains a <emphasis>version bitmap</emphasis>, it is possible to determine if there is a common version of OpenFlow or not:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>if there is a single common version use it and the <emphasis role="strong">VERSION IS SETTLED</emphasis></simpara>
</listitem>
<listitem>
<simpara>if there are more than one common versions, use the highest (newest) protocol and the <emphasis role="strong">VERSION IS SETTLED</emphasis></simpara>
</listitem>
<listitem>
<simpara>if there are no common versions, the device is <emphasis role="strong">DISCONNECTED</emphasis></simpara>
</listitem>
</orderedlist>

</listitem>
<listitem>
<simpara>if the first HELLO message does not contain a <emphasis>version bitmap</emphasis>, then STEB-BY-STEP negotiation is used</simpara>
</listitem>
<listitem>
<simpara>if second (or more) HELLO message is received, then STEP-BY-STEP negotiation is used</simpara>
</listitem>
</orderedlist>

<section xml:id="_step_by_step_negotiation">
<title>STEP-BY-STEP negotiation:</title>
<itemizedlist>
<listitem>
<simpara>if last version proposed by the OpenFlow plugin is the same as the version received from the OpenFlow device, then the <emphasis role="strong">VERSION IS SETTLED</emphasis></simpara>
</listitem>
<listitem>
<simpara>if the version received in the current HELLO message from the device is the same as from previous then negotiation has failed and the device is <emphasis role="strong">DISCONNECTED</emphasis></simpara>
</listitem>
<listitem>
<simpara>if the last version from the device is greater than the last version proposed from the plugin, wait for the next HELLO message in the hope that it will advertise support for a lower version</simpara>
</listitem>
<listitem>
<simpara>if the last version from the device is is less than the last version proposed from the plugin:</simpara>
<itemizedlist>
<listitem>
<simpara>propose the highest version the plugin supports that is less than or equal to the version received from the device and wait for the next HELLO message</simpara>
</listitem>
<listitem>
<simpara>if if the plugin doesn&#8217;t support a lower version, the device is <emphasis role="strong">DISCONNECTED</emphasis></simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara>After selecting of version we can say that the <emphasis role="strong">VERSION IS SETTLED</emphasis> and the OpenFlow plugin can ask device for its features. At this point handshake ends.</simpara>
<figure>
<title>Handshake process</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowplugin/odl-ofp-handshake.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Handshake process</phrase></textobject>
  </mediaobject>
</figure>

</section>
</section>
<section xml:id="_adding_a_flow">
<title>Adding a Flow</title>
<simpara>There are two ways to add a flow in in the OpenFlow plugin: adding it to the MD-SAL config datastore or calling an RPC. Both of these can either be done using the native MD-SAL interfaces or using RESTCONF. This discussion focuses on calling the RPC.</simpara>
<simpara>If user send flow via REST interface (step 1) it will cause that <emphasis>invokeRpc()</emphasis> is called on <emphasis role="strong">RpcBroker</emphasis>. The <emphasis role="strong">RpcBroker</emphasis> then looks for an appropriate implementation of the interface. In the case of the OpenFlow plugin, this is the <emphasis>addFlow()</emphasis> method of <emphasis role="strong">SalFlowServiceImpl</emphasis> (step 1.1). The same thing happens if the RPC is called directly from the native MD-SAL interfaces.</simpara>
<simpara>The <emphasis>addFlow()</emphasis> method then</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>calls the <emphasis>commitEntry()</emphasis> method (step 2) from the OpenFlow Protocol Library which is responsible for sending the flow to the device</simpara>
</listitem>
<listitem>
<simpara>creates a new <emphasis role="strong">RequestContext</emphasis> by calling <emphasis>createRequestContext()</emphasis> (step 3)</simpara>
</listitem>
<listitem>
<simpara>creates a callback to handle any events that happen because of sending the flow to the device</simpara>
</listitem>
</orderedlist>

<simpara>The callback method is triggered when a barrier reply message (step 2.1) is received from the device indicating that the flow was either installed or an appropriate error message was sent. If the flow was successfully sent to the device, the RPC result is set to success (step 5). // <emphasis role="strong">SalFlowService</emphasis> contains inside method <emphasis>addFlow()</emphasis> other callback which caught notification from callback for barrier message.</simpara>
<simpara>At this point, no information pertaining to the flow has been added to the MD-SAL operational datastore. That is accomplished by the periodic gathering of statistics from OpenFlow devices.</simpara>
<simpara>The <emphasis role="strong">StatisticsContext</emphasis> for each given OpenFlow device periodically polls it using <emphasis>gatherStatistics()</emphasis> of <emphasis role="strong">StatisticsGatheringUtil</emphasis> which issues an OpenFlow OFPT_MULTIPART_REQUEST - OFPMP_FLOW. The response to this request (step 7) is processed in <emphasis role="strong">StatisticsGatheringUtil</emphasis> class where flow data is written to the MD-SAL operational datastore via the <emphasis>writeToTransaction()</emphasis> method of <emphasis role="strong">DeviceContext</emphasis>.</simpara>
<figure>
<title>Add flow</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowplugin/odl-ofp-add-flow.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Add flow</phrase></textobject>
  </mediaobject>
</figure>

</section>
</section>
<section xml:id="_internal_message_statistics_api">
<title>Internal message statistics API</title>
<simpara>To aid in testing and diagnosis, the OpenFlow plugin provides information about the number and rate of different internal events.</simpara>
<simpara>The implementation does two things: collects event counts and exposes counts. Event counts are grouped by message type, e.g., <emphasis role="strong">PacketInMessage</emphasis>, and checkpoint, e.g., <emphasis>TO_SWITCH_ENQUEUED_SUCCESS</emphasis>. Once gathered, the results are logged as well as being exposed using OSGi command line (deprecated) and JMX.</simpara>
<section xml:id="collect">
<title>Collect</title>
<simpara>Each message is counted as it passes through various processing checkpoints. The following checkpoints are defined as a Java enum and tracked:</simpara>
<programlisting language="java" linenumbering="unnumbered">  /**
    * statistic groups overall in OFPlugin
    */
  enum STATISTIC_GROUP {
       /** message from switch, enqueued for processing */
       FROM_SWITCH_ENQUEUED,
       /** message from switch translated successfully - source */
       FROM_SWITCH_TRANSLATE_IN_SUCCESS,
       /** message from switch translated successfully - target */
       FROM_SWITCH_TRANSLATE_OUT_SUCCESS,
       /** message from switch where translation failed - source */
       FROM_SWITCH_TRANSLATE_SRC_FAILURE,
       /** message from switch finally published into MD-SAL */
       FROM_SWITCH_PUBLISHED_SUCCESS,
       /** message from switch - publishing into MD-SAL failed */
       FROM_SWITCH_PUBLISHED_FAILURE,

       /** message from MD-SAL to switch via RPC enqueued */
       TO_SWITCH_ENQUEUED_SUCCESS,
       /** message from MD-SAL to switch via RPC NOT enqueued */
       TO_SWITCH_ENQUEUED_FAILED,
       /** message from MD-SAL to switch - sent to OFJava successfully */
       TO_SWITCH_SUBMITTED_SUCCESS,
       /** message from MD-SAL to switch - sent to OFJava but failed*/
       TO_SWITCH_SUBMITTED_FAILURE
  }</programlisting>

<simpara>When a message passes through any of those checkpoints then counter assigned to
corresponding checkpoint and message is incremented by 1.</simpara>
</section>
<section xml:id="expose-results">
<title>Expose statistics</title>
<simpara>As described above, there are three ways to access the statistics:</simpara>
<itemizedlist>
<listitem>
<simpara>OSGi command line (this is considered deprecated)</simpara>
<variablelist>
<varlistentry>
<term></term>
<listitem>
<simpara><literal>osgi&gt; dumpMsgCount</literal></simpara>
</listitem>
</varlistentry>
</variablelist>

</listitem>
<listitem>
<simpara>OpenDaylight logging console (statistics are logged here every 10 seconds)</simpara>
<variablelist>
<varlistentry>
<term></term>
<listitem>
<simpara>required logback settings :
<literal>&lt;logger name="org.opendaylight.openflowplugin.openflow.md.queue.MessageSpyCounterImpl" level="DEBUG"\/&gt;</literal></simpara>
</listitem>
</varlistentry>
</variablelist>

</listitem>
<listitem>
<simpara>JMX (via JConsole)</simpara>
<variablelist>
<varlistentry>
<term></term>
<listitem>
<simpara>start OpenFlow plugin with the <literal>-jmx</literal> parameter</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term></term>
<listitem>
<simpara>start JConsole by running <literal>jconsole</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term></term>
<listitem>
<simpara>the JConsole MBeans tab should contain org.opendaylight.controller</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term></term>
<listitem>
<simpara>RuntimeBean has a msg-spy-service-impl</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term></term>
<listitem>
<simpara>Operations provides makeMsgStatistics report functionality</simpara>
</listitem>
</varlistentry>
</variablelist>

</listitem>
</itemizedlist>

<section xml:id="example-result">
<title>Example results</title>
<figure>
<title>OFplugin Debug stats.png</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowplugin/odl-ofp-ofplugin-debug-stats.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>OFplugin Debug stats.png</phrase></textobject>
  </mediaobject>
</figure>

<screen>DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_ENQUEUED: MSG[PortStatusMessage] -&gt; +0 | 1
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_ENQUEUED: MSG[MultipartReplyMessage] -&gt; +24 | 81
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_ENQUEUED: MSG[PacketInMessage] -&gt; +8 | 111
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_IN_SUCCESS: MSG[PortStatusMessage] -&gt; +0 | 1
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_IN_SUCCESS: MSG[MultipartReplyMessage] -&gt; +24 | 81
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_IN_SUCCESS: MSG[PacketInMessage] -&gt; +8 | 111
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[QueueStatisticsUpdate] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[NodeUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[NodeConnectorStatisticsUpdate] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[GroupDescStatsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[FlowsStatisticsUpdate] -&gt; +3 | 19
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[PacketReceived] -&gt; +8 | 111
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[MeterFeaturesUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[GroupStatisticsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[GroupFeaturesUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[MeterConfigStatsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[MeterStatisticsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[NodeConnectorUpdated] -&gt; +0 | 12
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_OUT_SUCCESS: MSG[FlowTableStatisticsUpdate] -&gt; +3 | 8
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_TRANSLATE_SRC_FAILURE: no activity detected
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[QueueStatisticsUpdate] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[NodeUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[NodeConnectorStatisticsUpdate] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[GroupDescStatsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[FlowsStatisticsUpdate] -&gt; +3 | 19
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[PacketReceived] -&gt; +8 | 111
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[MeterFeaturesUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[GroupStatisticsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[GroupFeaturesUpdated] -&gt; +0 | 3
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[MeterConfigStatsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[MeterStatisticsUpdated] -&gt; +3 | 7
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[NodeConnectorUpdated] -&gt; +0 | 12
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_SUCCESS: MSG[FlowTableStatisticsUpdate] -&gt; +3 | 8
DEBUG o.o.o.s.MessageSpyCounterImpl - FROM_SWITCH_PUBLISHED_FAILURE: no activity detected
DEBUG o.o.o.s.MessageSpyCounterImpl - TO_SWITCH_ENQUEUED_SUCCESS: MSG[AddFlowInput] -&gt; +0 | 12
DEBUG o.o.o.s.MessageSpyCounterImpl - TO_SWITCH_ENQUEUED_FAILED: no activity detected
DEBUG o.o.o.s.MessageSpyCounterImpl - TO_SWITCH_SUBMITTED_SUCCESS: MSG[AddFlowInput] -&gt; +0 | 12
DEBUG o.o.o.s.MessageSpyCounterImpl - TO_SWITCH_SUBMITTED_FAILURE: no activity detected</screen>

</section>
</section>
</section>
<section xml:id="yang-models-ans-api">
<title>Yang models and API</title>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <?dbhtml table-width="100%"?>
  <?dbfo table-width="100%"?>
  <?dblatex table-width="100%"?>
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="319*"/>
    
    <colspec colname="col_2" colwidth="106*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Model</entry>
        
        <entry align="left" valign="top">DOC</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top" namest="col_1" nameend="col_2"><simpara><emphasis><emphasis role="strong">Openflow basic types</emphasis></emphasis></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-table-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-table-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-table-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-action-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-action-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-action-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-flow-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-flow-types.yan</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-flow-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-meter-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-meter-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-meter-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-group-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-group-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-group-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-match-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-match-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-match-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-port-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-port-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-port-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-base/src/main/yang/opendaylight-queue-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-queue-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-base/target/site/models/opendaylight-queue-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top" namest="col_1" nameend="col_2"><simpara><emphasis><emphasis role="strong">Openflow services</emphasis></emphasis></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-table.yang;a=blob;hb=refs/heads/stable/boron">sal-table.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-table.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-group.yang;a=blob;hb=refs/heads/stable/boron">sal-group.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-group.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-queue.yang;a=blob;hb=refs/heads/stable/boron">sal-queue.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-queue.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/flow-errors.yang;a=blob;hb=refs/heads/stable/boron">flow-errors.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/flow-errors.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/flow-capable-transaction.yang;a=blob;hb=refs/heads/stable/boron">flow-capable-transaction.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/flow-capable-transaction.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-flow.yang;a=blob;hb=refs/heads/stable/boron">sal-flow.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-flow.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-meter.yang;a=blob;hb=refs/heads/stable/boron">sal-meter.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-meter.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/flow-topology-discovery.yang;a=blob;hb=refs/heads/stable/boron">flow-topology-discovery.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/flow-topology-discovery.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/node-errors.yang;a=blob;hb=refs/heads/stable/boron">node-errors.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/node-errors.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/node-config.yang;a=blob;hb=refs/heads/stable/boron">node-config.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/node-config.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-echo.yang;a=blob;hb=refs/heads/stable/boron">sal-echo.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-echo.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/sal-port.yang;a=blob;hb=refs/heads/stable/boron">sal-port.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/sal-port.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/packet-processing.yang;a=blob;hb=refs/heads/stable/boron">packet-processing.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/packet-processing.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-service/src/main/yang/flow-node-inventory.yang;a=blob;hb=refs/heads/stable/boron">flow-node-inventory.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-service/target/site/models/flow-node-inventory.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top" namest="col_1" nameend="col_2"><simpara><emphasis><emphasis role="strong">Openflow statistics</emphasis></emphasis></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-queue-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-queue-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-queue-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-flow-table-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-flow-table-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-flow-table-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-port-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-port-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-port-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-statistics-types.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-statistics-types.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-statistics-types.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-group-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-group-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-group-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-flow-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-flow-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-flow-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;f=model/model-flow-statistics/src/main/yang/opendaylight-meter-statistics.yang;a=blob;hb=refs/heads/stable/boron">opendaylight-meter-statistics.yang</link></simpara></entry>
        
        <entry align="left" valign="top"><simpara><link xlink:href="https://jenkins.opendaylight.org/releng/view/openflowplugin/job/openflowplugin-merge-boron/lastSuccessfulBuild/artifact/model/model-flow-statistics/target/site/models/opendaylight-meter-statistics.html">YangDOC</link></simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_karaf_feature_tree">
<title>Karaf feature tree</title>
<figure>
<title>Openflow plugin karaf feature tree</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/openflowplugin/odl-ofp-feature-tree.png" contentwidth="600"/>
    </imageobject>
    <textobject><phrase>Karaf feature tree</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Short <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_OpenFlow_Plugin:FeatureTreeHowto">HOWTO</link> create such a tree.</simpara>
</section>
<section xml:id="_wiring_up_notifications">
<title>Wiring up notifications</title>
<section xml:id="_introduction_4">
<title>Introduction</title>
<simpara>We need to translate OpenFlow messages coming up from the
<link linkend="_openflow_protocol_library_developer_guide">OpenFlow Protocol Library</link>
into MD-SAL Notification objects and then publish them to the
MD-SAL.</simpara>
</section>
<section xml:id="mechanics">
<title>Mechanics</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a Translator class</simpara>
</listitem>
<listitem>
<simpara>Register the Translator</simpara>
</listitem>
<listitem>
<simpara>Register the notificationPopListener to handle your Notification
Objects</simpara>
</listitem>
</orderedlist>

<section xml:id="create-a-translator-class">
<title>Create a Translator class</title>
<simpara>You can see an example in
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;a=blob;f=openflowplugin/src/main/java/org/opendaylight/openflowplugin/openflow/md/core/translator/PacketInTranslator.java;hb=refs/heads/stable/boron">PacketInTranslator.java</link>.</simpara>
<simpara>First, simply create the class</simpara>
<screen>public class PacketInTranslator implements IMDMessageTranslator&lt;OfHeader, List&lt;DataObject&gt;&gt; {</screen>

<simpara>Then implement the translate function:</simpara>
<screen>public class PacketInTranslator implements IMDMessageTranslator&lt;OfHeader, List&lt;DataObject&gt;&gt; {

    protected static final Logger LOG = LoggerFactory
            .getLogger(PacketInTranslator.class);
    @Override
    public PacketReceived translate(SwitchConnectionDistinguisher cookie,
            SessionContext sc, OfHeader msg) {
            ...
    }</screen>

<simpara>Make sure to check that you are dealing with the expected type and cast
it:</simpara>
<screen>if(msg instanceof PacketInMessage) {
    PacketInMessage message = (PacketInMessage)msg;
    List&lt;DataObject&gt; list = new CopyOnWriteArrayList&lt;DataObject&gt;();</screen>

<simpara>Do your transation work and return</simpara>
<screen>PacketReceived pktInEvent = pktInBuilder.build();
list.add(pktInEvent);
return list;</screen>

</section>
<section xml:id="register-your-translator-class">
<title>Register your Translator Class</title>
<simpara>Next you need to go to
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=openflowplugin.git;a=blob;f=openflowplugin/src/main/java/org/opendaylight/openflowplugin/openflow/md/core/MDController.java;hb=refs/heads/stable/boron">MDController.java</link>
and in init() add register your Translator:</simpara>
<screen>public void init() {
        LOG.debug("Initializing!");
        messageTranslators = new ConcurrentHashMap&lt;&gt;();
        popListeners = new ConcurrentHashMap&lt;&gt;();
        //TODO: move registration to factory
        addMessageTranslator(ErrorMessage.class, OF10, new ErrorTranslator());
        addMessageTranslator(ErrorMessage.class, OF13, new ErrorTranslator());
        addMessageTranslator(PacketInMessage.class,OF10, new PacketInTranslator());
        addMessageTranslator(PacketInMessage.class,OF13, new PacketInTranslator());</screen>

<simpara>Notice that there is a separate registration for each of OpenFlow 1.0 and OpenFlow 1.3.
Basically, you indicate the type of OpenFlow Protocol Library message you wish to
translate for, the OpenFlow version, and an instance of your Translator.</simpara>
</section>
<section xml:id="register-your-md-sal-message-for-notification-to-the-md-sal">
<title>Register your MD-SAL Message for Notification to the MD-SAL</title>
<simpara>Now, also in MDController.init() register to have the
notificationPopListener handle your MD-SAL Message:</simpara>
<screen>addMessagePopListener(PacketReceived.class, new NotificationPopListener&lt;DataObject&gt;());</screen>

</section>
<section xml:id="you-are-done">
<title>You are done</title>
<simpara>That&#8217;s all there is to it. Now when a message comes up from the
OpenFlow Protocol Library, it will be translated and published to the MD-SAL.</simpara>
</section>
</section>
</section>
<section xml:id="_message_order_preservation">
<title>Message Order Preservation</title>
<simpara>While the Helium release of OpenFlow Plugin relied on queues to ensure messages were delivered in order, subsequent releases instead ensure that all the messages from a given device are delivered using the same thread and thus message order is guaranteed without queues. The OpenFlow plugin allocates a number of threads equal to twice the number of processor cores on machine it is run, e.g., 8 threads if the machine has 4 cores.</simpara>
<note>
<simpara>While each device is assigned to one thread, multiple devices can be assigned to the same thread.</simpara>
</note>

</section>
</chapter>
<chapter xml:id="_opflex_agent_ovs_developer_guide">
<title>OpFlex agent-ovs Developer Guide</title>
<section xml:id="_overview_17">
<title>Overview</title>
<simpara>agent-ovs is a policy agent that works with OVS to enforce a
group-based policy networking model with locally attached virtual
machines or containers. The policy agent is designed to work well with
orchestration tools like OpenStack.</simpara>
</section>
<section xml:id="_agent_ovs_architecture">
<title>agent-ovs Architecture</title>
<simpara>agent-ovs uses libopflex to communicate with an OpFlex-based policy
repository to enforce policy on network endpoints attached to OVS by
an orchestration system.</simpara>
<simpara>The key components are:</simpara>
<itemizedlist>
<listitem>
<simpara>Agent - coordinates startup and configuration</simpara>
</listitem>
<listitem>
<simpara>Renderers - Renderers are responsible for rendering policy.  This is
a very general mechanism but the currently-implemented renderer is
the stitched-mode renderer that can work along with with hardware
fabrics such as ACI that support policy enforcement.</simpara>
</listitem>
<listitem>
<simpara>EndpointManager - Keep track of network endpoints and declare them
to the endpoint repository</simpara>
</listitem>
<listitem>
<simpara>PolicyManager - Keep track of and index policies</simpara>
</listitem>
<listitem>
<simpara>FlowManager - render policies to OVS</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_api_reference_documentation_8">
<title>API Reference Documentation</title>
<simpara>Internal API documentation can be found here:
<link xlink:href="https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/agent-ovs/doc/html/index.html">https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/agent-ovs/doc/html/index.html</link></simpara>
</section>
</chapter>
<chapter xml:id="_opflex_genie_developer_guide">
<title>OpFlex genie Developer Guide</title>
<section xml:id="_overview_18">
<title>Overview</title>
<simpara>Genie is a tool for code generation from a model.  It supports
generating C++ and Java code.  C++ can be generated suitable for use
with libopflex. C++ and Java can be generated as a plain set of
objects.</simpara>
</section>
<section xml:id="_group_based_policy_model">
<title>Group-based Policy Model</title>
<simpara>The group-based policy model is included with the genie tool and can
be found under the MODEL directory.  By running mvn exec:java,
libmodelgbp will be generated as a library project that, when built
and installed, will work with libopflex.  This model is used by the
OVS agent.</simpara>
</section>
<section xml:id="_api_reference_documentation_9">
<title>API Reference Documentation</title>
<simpara>Complete API documentation for the generated libmodelgbp can be found here:
<link xlink:href="https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/libopflex/doc/html/index.html">https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/libopflex/doc/html/index.html</link></simpara>
</section>
</chapter>
<chapter xml:id="_opflex_libopflex_developer_guide">
<title>OpFlex libopflex Developer Guide</title>
<section xml:id="_overview_19">
<title>Overview</title>
<simpara>The OpFlex framework allows you to develop agents that can communicate
using the OpFlex protocol and act as a policy element in an
OpFlex-based distributed control system. The OpFlex architecture
provides a distributed control system based on a declarative policy
information model. The policies are defined at a logically centralized
policy repository and enforced within a set of distributed policy
elements. The policy repository communicates with the subordinate
policy elements using the OpFlex control protocol. This protocol
allows for bidirectional communication of policy, events, statistics,
and faults.</simpara>
<simpara>Rather than simply providing access to the OpFlex protocol, this
framework allows you to directly manipulate a management information
tree containing a hierarchy of managed objects. This tree is kept in
sync as needed with other policy elements in the system, and you are
automatically notified when important changes to the model
occur. Additionally, we can ensure that only those managed objects
that are important to the local policy element are synchronized
locally.</simpara>
<section xml:id="_object_model">
<title>Object Model</title>
<simpara>Interactions with the OpFlex framework happen through the management
information tree. This is a tree of managed objects defined by an
object model specific to your application. There are a few important
major category of objects that can appear in the model.</simpara>
<itemizedlist>
<listitem>
<simpara>First, there is the policy object. A policy object represents some
data related to a policy that describes a user intent for how the
system should behave. A policy object is stored in the policy
repository which is the source of "truth" for this object.</simpara>
</listitem>
<listitem>
<simpara>Second, there is an endpoint object. A endpoint represents an entity
in the system to which we want to apply policy, which could be a
network interface, a storage array, or other relevent policy
endpoint. Endpoints are discovered and reported by policy elements
locally, and are synchronized into the endpoint repository. The
originating policy element is the source of truth for the endpoints
it discovers. Policy elements can retrieve information about
endpoints discovered by other policy elements by resolving endpoints
from the endpoint repository.</simpara>
</listitem>
<listitem>
<simpara>Third, there is the observable object. An observable object
represents some state related to the operational status or health of
the policy element. Observable objects will be reported to the
observer.</simpara>
</listitem>
<listitem>
<simpara>Finally, there is the local-only object. This is the simplest object
because it exists only local to a particular policy element. These
objects can be used to store state specific to that policy element,
or as helpers to resolve other objects. Read on to learn more.</simpara>
</listitem>
</itemizedlist>

<simpara>You can use the genie tool that is included with the framework to
produce your application model along with a set of generated accessor
classes that can work with this framework library. You should refer to
the documentation that accompanies the genie tool for information on
how to use to to generate your object model. Later in this guide,
we&#8217;ll go through examples of how to use the generated managed object
accessor classes.</simpara>
</section>
<section xml:id="_programming_by_side_effect">
<title>Programming by Side Effect</title>
<simpara>When developing software on the OpFlex framework, you&#8217;ll need to think
in a slightly different way. Rather than calling an API function that
would perform some specific action, you&#8217;ll need to write a managed
object to the managed object database. Writing that object to the
store will trigger the side effect of performing the action that you
want.</simpara>
<simpara>For example, a policy element will need to have a component
responsible for discovering policy endpoints. When it discovers a
policy endpoint, it would write an endpoint object into the managed
object database. That endpoint object will contain a reference to
policy that is relevant to the endpoint object. This will trigger a
whole cascade of events. First, the framework will notice that an
endpoint object has been created and it will write it to the endpoint
repository. Second, the framework to will attempt to resolve the
unresolved reference to the relevent policy object. There might be a
whole chain of policy resolutions that will be automatically performed
to download all the relevent policy until there are no longer any
dangling references.</simpara>
<simpara>As long as there is a locally-created object in the system with a
reference to that policy, the framework will continually ensure that
the policy and any transitive policies are kept up to date. The policy
element can subscribe to updates to these policy classes that will be
invoked either the first time the policy is resolved or any time the
policy changes.</simpara>
<simpara>A consequence of this design is that the managed object database can
be temporarily in an inconsistent state with unresolved dangling
references. Eventually, however, the inconsistency will be fully
resolved. The policy element must be able to cleanly handle
partially-resolved or inconsistent state and eventually reach the
correct state as it receives these update notifications. Note that, in
the OpFlex architecture, when there is no policy that specifically
allows a particular action, that action must be prevented.</simpara>
<simpara>Let&#8217;s cover one slightly more complex example. If a policy element
needs to discover information about an endpoint that is not local to
that policy element, it will need to retrieve that information from
the endpoint repository. However, just as there is no API call to
retrieve a policy object from the policy repository, there is no API
call to retrieve an endpoint from the endpoint repository.</simpara>
<simpara>To get this information, the policy element needs to create a
local-only object that references the endpoint. Once it creates this
local-only object, if the endpoint is not already resolved, the
framework will notice the dangling reference and automatically resolve
the endpoint from the endpoint respository. When the endpoint
resolution completes, the framework deliver an update notification to
the policy element. The policy element will continue to receive any
updates related to that endpoint until the policy element remove the
local-only reference to the object. Once this occurs, the framework
can garbage-collect any unreferenced objects.</simpara>
</section>
<section xml:id="_threading_and_ownership">
<title>Threading and Ownership</title>
<simpara>The OpFlex framework uses a somewhat unique threading model. Each
managed object in the system belongs to a particular owner. An owner
would typically be a single thread that is reponsible for all updates
to objects with that owner. Though anything can read the state of a
managed object, only the owner of a managed object is permitted to
write to it. Though this is not strictly required for correctness, the
performance of the system wil be best if you ensure that only one
thread at a time is writing to objects with a particular owner.</simpara>
<simpara>Change notifications are delivered in a serialized fashion by a single
thread. Blocking this thread from a notification callback will stall
delivery of all notifications. It is therefore best practice to ensure
that you do not block or perform long-running operations from a
notification callback.</simpara>
</section>
</section>
<section xml:id="_key_apis_and_interfaces_9">
<title>Key APIs and Interfaces</title>
<section xml:id="_basic_usage_and_initialization">
<title>Basic Usage and Initialization</title>
<simpara>The primary interface point into the framework is
opflex::ofcore::OFFramework. You can choose to instantiate your own
copy of the framework, or you can use the static default instance.</simpara>
<simpara>Before you can use the framework, you must initialize it by installing
your model metadata. The model metadata is accessible through the
generated model library. In this case, it assumes your model is called
"mymodel":</simpara>
<programlisting language="cpp" linenumbering="unnumbered">#include &lt;opflex/ofcore/OFFramework.h&gt;
#include &lt;mymodel/metadata/metadata.hpp&gt;
// ...
using opflex::ofcore::OFFramework;
OFFramework::defaultInstance().setModel(mymodel::getMetadata());</programlisting>

<simpara>The other critical piece of information required for initialization is
the OpFlex identity information. The identity information is required
in order to successfully connect to OpFlex peers. In OpFlex, each
component has a unique name within its policy domain, and each policy
domain is identified by a globally unique domain name. You can set
this identity information by calling:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">OFFramework::defaultInstance()
    .setOpflexIdentity("[component name]", "[unique domain]");</programlisting>

<simpara>You can then start the framework simply by calling:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">OFFramework::defaultInstance().start();</programlisting>

<simpara>Finally, you can add peers after the framework is started by calling
the <literal>opflex::ofcore::OFFramework::addPeer</literal> method:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">OFFramework::defaultInstance().addPeer("192.168.1.5", 1234);</programlisting>

<simpara>When connecting to the peer, that peer may provide an additional list
of peers to connect to, which will be automatically added as peers. If
the peer does not include itself in the list, then the framework will
disconnect from that peer and add the peers in the list. In this way,
it is possible to automatically bootstrap the correct set of peers
using a known hostname or IP address or a known, fixed anycast IP
address.</simpara>
<simpara>To cleanly shut down, you can call:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">OFFramework::defaultInstance().stop();</programlisting>

</section>
<section xml:id="_working_with_data_in_the_tree">
<title>Working with Data in the Tree</title>
<section xml:id="_reading_from_the_tree">
<title>Reading from the Tree</title>
<simpara>You can access data in the managed tree using the generated accessor
classes. The details of exactly which classes you&#8217;ll use will depend
on the model you&#8217;re using, but let&#8217;s assume that we have a simple
model called "simple" with the following classes:</simpara>
<itemizedlist>
<listitem>
<simpara>root - The root node. The URI for the root node is "/"</simpara>
</listitem>
<listitem>
<simpara>foo - A policy object, and a child of root, with a scalar string
property called "bar", and a unsigned 64-bit integer property called
baz. The bar property is the naming property for foo. The URI for a
foo object would be "/foo/[value of bar]/"</simpara>
</listitem>
<listitem>
<simpara>fooref - A local-only child of root, with a reference to a foo, and
a scalar string property called "bar". The bar property is the
naming property for foo. The URI for a fooref object would be
"/fooref/[value of bar]/"</simpara>
</listitem>
</itemizedlist>

<simpara>In this example, we&#8217;ll have a generated class for each of the
objects. There are two main ways to get access to an object in the
tree.</simpara>
<simpara>First, we can get instantiate an accessor class to any node in the
tree by calling one of its static resolve functions. The resolve
functions can take either an already-built URI that represents the
object, or you can call the version that will locate the object by its
naming properties.</simpara>
<simpara>Second, we can access the object also from its parent object using the
appropriate child resolver member functions.</simpara>
<simpara>However we read it, the object we get back is an immutable view into
the object it references. The properties set locally on that object
will not change even though the underlying object may have been
updated in the store. Note, however, that its children can change
between when you first retrieve the object and when you resolve any
children.</simpara>
<simpara>Another thing that is critical to note again is that when you attempt
to resolve an object, you can get back nothing, even if the object
actually does exist on another OpFlex node. You must ensure that some
object in the managed object database references the remote managed
object you want before it will be visible to you.</simpara>
<simpara>To get access to the root node using the default framework instance,
we can simply call:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">using boost::shared_ptr;
using boost::optional;
optional&lt;shared_ptr&lt;simple::root&gt; &gt; r(simple::root::resolve());</programlisting>

<simpara>Note that whenever we can a resolve function, we get back our data in
the form of an optional shared pointer to the object instance. If the
node does not exist, then the optional will be set to
boost::none. Note that if you dereference an optional that has not
been set, you&#8217;ll trigger an assert, so you must check the return as
follows:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">if (!r) {
   // handle missing object
}</programlisting>

<simpara>Now let&#8217;s get a child node of the root in three different ways:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">// Get foo1 by constructing its URI from the root
optional&lt;shared_ptr&lt;simple::foo&gt; &gt; foo1(simple::foo::resolve("test"));
// get foo1 by constructing its URI relative to its parent
foo1 = r.get()-&gt;resolveFoo("test");
// get foo1 by manually building its URI
foo1 = simple::foo::resolve(opflex::modb::URIBuilder()
                               .addElement("foo")
                               .addElement("test")
                               .build());</programlisting>

<simpara>All three of these calls will give us the same object, which is the
"foo" object located at "/foo/test/".</simpara>
<simpara>The foo class has a single string property called "bar". We can easily
access it as follows:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">const std::string&amp; barv = foo1.getBar();</programlisting>

</section>
<section xml:id="_writing_to_the_tree">
<title>Writing to the Tree</title>
<simpara>Writing to the tree is nearly as easy as reading from it. The key
concept to understand is the mutator object. If you want to make
changes to the tree, you must allocate a mutator object. The mutator
will register itself in some thread-local storage in the framework
instance you&#8217;re using. The mutator is specific to a single "owner" for
the data, so you can only make changes to data associated with that
owner.</simpara>
<simpara>Whenever you modify one of the accessor classes, the change is
actually forwarded to the currently-active mutator. You won&#8217;t see any
of the changes you make until you call the commit member function on
the mutator. When you do that, all the changes you made are written
into the store.</simpara>
<simpara>Once the changes are written into the store, you will need to call the
appropriate resolve function again to see the changes.</simpara>
<simpara>Allocating a mutator is simple. To create a mutator for the default
framework instance associated with the owner "owner1", just allocate
the mutator on the stack. Be sure to call commit() before it goes out
of scope or you&#8217;ll lose your changes.</simpara>
<programlisting language="cpp" linenumbering="unnumbered">{
    opflex::modb::Mutator mutator("owner1");
    // make changes here
    mutator.commit();
}</programlisting>

<simpara>Note that if an exception is thrown while making changes but before
committing, the mutator will go out of scope and the changes will be
discarded.</simpara>
<simpara>To create a new node, you must call the appropriate add[Child] member
function on its parent. This function takes parameters for each of the
naming properties for the object:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">shared_ptr&lt;simple::foo&gt; newfoo(root-&gt;addFoo("test"));</programlisting>

<simpara>This will return a shared pointer to a new foo object that has been
registered in the active mutator but not yet committed. The "bar"
naming property will be set automatically, but if you want to set the
"baz" property now, you can do so by calling:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">newfoo-&gt;setBaz(42);</programlisting>

<simpara>Note that creating the root node requires a call to the special static
class method createRootElement:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">shared_ptr&lt;simple::root&gt; newroot(simple::root::createRootElement());</programlisting>

<simpara>Here&#8217;s a complete example that ties this all together:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">{
    opflex::modb::Mutator mutator("owner1");
    shared_ptr&lt;simple::root&gt; newroot(simple::root::createRootElement());
    shared_ptr&lt;simple::root&gt; newfoo(newroot-&gt;addFoo("test"));
    newfoo-&gt;setBaz(42);

    mutator.commit();
}</programlisting>

</section>
</section>
<section xml:id="_update_notifications">
<title>Update Notifications</title>
<simpara>When using the OpFlex framework, you&#8217;re likely to find that most of
your time is spend responding to changes in the managed object
database. To get these notifications, you&#8217;re going to need to register
some number of listeners.</simpara>
<simpara>You can register an object listener to see all changes related to a
particular class by calling a static function for that class. You&#8217;ll
then get notifications whenever any object in that class is added,
updated, or deleted. The listener should queue a task to read the new
state and perform appropriate processing. If this function blocks or
peforms a long-running operation, then the dispatching of update
notifications will be stalled, but there will not be any other
deleterious effects.</simpara>
<simpara>If multiple changes happen to the same URI, then at least one
notification will be delivered but some events may be consolidated.</simpara>
<simpara>The update you get will tell you the URI and the Class ID of the
changed object. The class ID is a unique ID for each class. When you
get the update, you&#8217;ll need to call the appropriate resolve function
to retrieve the new value.</simpara>
<simpara>You&#8217;ll need to create your own object listener derived from
opflex::modb::ObjectListener:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">class MyListener : public ObjectListener {
public:
    MyListener() { }
    virtual void objectUpdated(class_id_t class_id, const URI&amp; uri) {
        // Your handler here
    }
};</programlisting>

<simpara>To register your listener with the default framework instance, just
call the appropriate class static method:</simpara>
<programlisting language="cpp" linenumbering="unnumbered">MyListener listener;
simple::foo::registerListener(&amp;listener);
// main loop
simple::foo::unregisterListener(&amp;listener);</programlisting>

<simpara>The listener will now recieve notifications whenever any foo or any
children of any foo object changes.</simpara>
<simpara>Note that you must ensure that you unregister your listeners before
deallocating them.</simpara>
</section>
</section>
<section xml:id="_api_reference_documentation_10">
<title>API Reference Documentation</title>
<simpara>Complete API documentation can be found through doxygen here:
<link xlink:href="https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/libopflex/doc/html/index.html">https://jenkins.opendaylight.org/opflex/job/opflex-merge/ws/libopflex/doc/html/index.html</link></simpara>
</section>
</chapter>
<chapter xml:id="_ovsdb_netvirt">
<title>OVSDB NetVirt</title>
<section xml:id="_ovsdb_integration">
<title>OVSDB Integration</title>
<simpara>The Open vSwitch database (OVSDB) Southbound Plugin component for OpenDaylight implements
the OVSDB  <link xlink:href="https://tools.ietf.org/html/rfc7047">RFC 7047</link> management protocol
that allows the southbound configuration of switches that support OVSDB. The
component comprises a library and a plugin. The OVSDB protocol
uses JSON-RPC calls to manipulate a physical or virtual switch that supports OVSDB.
Many vendors support OVSDB on various hardware platforms.
The OpenDaylight controller uses the library project to interact with an OVS
instance.</simpara>
<note>
<simpara>Read the OVSDB User Guide before you begin development.</simpara>
</note>

<section xml:id="_opendaylight_ovsdb_integration">
<title>OpenDaylight OVSDB integration</title>
<simpara>The OpenStack integration architecture uses the following technologies:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://tools.ietf.org/html/rfc7047">RFC 7047</link> - The Open vSwitch Database Management Protocol</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://www.opennetworking.org/images/stories/downloads/sdn-resources/onf-specifications/openflow/openflow-switch-v1.3.4.pdf">OpenFlow v1.3</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.openstack.org/wiki/Neutron/ML2">OpenStack Neutron ML2 Plugin</link></simpara>
</listitem>
</itemizedlist>

<section xml:id="_opendaylight_mechanism_driver_for_openstack_neutron_ml2">
<title>OpenDaylight Mechanism Driver for Openstack Neutron ML2</title>
<simpara>This code is a part of OpenStack and is available at: <link xlink:href="https://github.com/openstack/neutron/blob/master/neutron/plugins/ml2/drivers/mechanism_odl.py">https://github.com/openstack/neutron/blob/master/neutron/plugins/ml2/drivers/mechanism_odl.py</link></simpara>
<simpara>The ODL neutron driver implementation can be found at: <link xlink:href="https://github.com/openstack/networking-odl">https://github.com/openstack/networking-odl</link></simpara>
<simpara>To make changes to this code, please read about <link xlink:href="https://wiki.openstack.org/wiki/NeutronDevelopment">Neutron Development</link>.</simpara>
<simpara>Before submitting the code, run the following tests:</simpara>
<screen>tox -e py27
tox -e pep8</screen>

</section>
<section xml:id="_importing_the_code_in_to_eclipse_or_intellij">
<title>Importing the code in to Eclipse or IntelliJ</title>
<simpara>To import code, look at either of the following pages:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/Eclipse_Setup">Getting started with Eclipse</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:Developing_With_Intellij">Developing with Intellij</link></simpara>
</listitem>
</itemizedlist>

<figure>
<title>Avoid conflicting project names</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/OVSDB_Eclipse.png"/>
    </imageobject>
    <textobject><phrase>OVSDB Eclipse</phrase></textobject>
  </mediaobject>
</figure>

<itemizedlist>
<listitem>
<simpara>To ensure that a project in Eclipse does not have a conflicting name in the workspace, select Advanced &gt; Name Template &gt; [groupId].[artifactId] when importing the project.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_browsing_the_code">
<title>Browsing the code</title>
<simpara>The code is mirrored to <link xlink:href="https://github.com/opendaylight/ovsdb">GitHub</link> to make reading code online easier.</simpara>
</section>
<section xml:id="_source_code_organization">
<title>Source code organization</title>
<simpara>The OVSDB project generates the following Karaf modules:</simpara>
<itemizedlist>
<listitem>
<simpara>ovsdb.karaf &#8201;&#8212;&#8201;all openstack netvirt related artifacts</simpara>
</listitem>
<listitem>
<simpara>ovsdb.library-karaf&#8201;&#8212;&#8201;the OVSDB library reference implementation</simpara>
</listitem>
<listitem>
<simpara>ovsdb.openstack.net-virt-sfc-karaf &#8201;&#8212;&#8201;openflow service function chaining</simpara>
</listitem>
<listitem>
<simpara>ovsdb.hwvtepsouthbound-karaf&#8201;&#8212;&#8201;the hw_vtep schema southbound plugin</simpara>
</listitem>
<listitem>
<simpara>ovsdb.southbound-karaf - the Open_vSwitch schema plugin</simpara>
</listitem>
</itemizedlist>

<simpara>Following are a brief descriptions on directories you will find a the root ovsdb/ directory:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis>commons</emphasis> contains the parent POM file for Maven project which is used to get consistency of settings across the project.</simpara>
</listitem>
<listitem>
<simpara><emphasis>features</emphasis> contains all the Karaf related feature files.</simpara>
</listitem>
<listitem>
<simpara><emphasis>hwvtepsouthbound</emphasis> contains the hw_vtep southbound plugin.</simpara>
</listitem>
<listitem>
<simpara><emphasis>karaf</emphasis> contains the ovsdb library and southbound and OpenStack bundles for the OpenStack integration.</simpara>
</listitem>
<listitem>
<simpara><emphasis>library</emphasis> contains a schema-independent library that is a reference implementation for RFC 7047.</simpara>
</listitem>
<listitem>
<simpara><emphasis>openstack</emphasis> contains the northbound handlers for Neutron used by OVSDB, as well as their providers. The NetVirt SFC implementation is also located here.</simpara>
</listitem>
<listitem>
<simpara><emphasis>ovsdb-ui</emphasis> contains the DLUX implementation for displaying network virtualization.</simpara>
</listitem>
<listitem>
<simpara><emphasis>resources</emphasis> contains useful scripts, how-tos, demos and other resources.</simpara>
</listitem>
<listitem>
<simpara><emphasis>schemas</emphasis> contains the OVSDB schemas that are implemented in OpenDaylight.</simpara>
</listitem>
<listitem>
<simpara><emphasis>southbound</emphasis> contains the plugin for converting from the OVSDB protocol to MD-SAL and vice-versa.</simpara>
</listitem>
<listitem>
<simpara><emphasis>utils</emphasis> contains a collection of utilities for using the OpenFlow plugin, southbound, Neutron and other helper methods.</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_building_and_running_ovsdb">
<title>Building and running OVSDB</title>
<simpara><emphasis role="strong">Prerequisites</emphasis><?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>JDK 1.7+</simpara>
</listitem>
<listitem>
<simpara>Maven 3+</simpara>
</listitem>
</itemizedlist>

<section xml:id="ovsdbBuildSteps">
<title>Building a Karaf feature and deploying it in an Opendaylight Karaf distribution<?asciidoc-br?></title>
<orderedlist numeration="arabic">
<listitem>
<simpara>From the root ovsdb/ directory, run <emphasis role="strong">mvn clean install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Unzip the karaf-&lt;VERSION_NUMBER&gt;-SNAPSHOT.zip file created from step 1 in the directory ovsdb/karaf/target/:</simpara>
</listitem>
</orderedlist>

<screen>unzip karaf-&lt;VERSION_NUMBER&gt;-SNAPSHOT.zip</screen>

</section>
<section xml:id="_downloading_ovsdb_s_karaf_distribution_asciidoc_br">
<title>Downloading OVSDB&#8217;s Karaf distribution<?asciidoc-br?></title>
<simpara>Instead of building, you can download the latest OVSDB distribution from the Nexus server. The link for that is:</simpara>
<screen>https://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/org/opendaylight/ovsdb/karaf/1.3.0-SNAPSHOT/</screen>

</section>
<section xml:id="_running_karaf_feature_from_ovsdb_s_karaf_distribution_asciidoc_br">
<title>Running Karaf feature from OVSDB&#8217;s Karaf distribution<?asciidoc-br?></title>
<orderedlist xml:id="ovsdbStartingOdl" numeration="arabic">
<listitem>
<simpara>Start ODL, from the unzipped directory</simpara>
</listitem>
</orderedlist>

<screen>bin/karaf</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Once karaf has started, and you see the Opendaylight ascii art in the console, the last step is to start the OVSDB plugin framework with the following command in the karaf console:</simpara>
</listitem>
</orderedlist>

<screen>feature:install odl-ovsdb-openstack</screen>

<section xml:id="_sample_output_from_the_karaf_console">
<title>Sample output from the Karaf console</title>
<screen>opendaylight-user@root&gt;feature:list | grep -i ovsdb
opendaylight-user@root&gt;feature:list -i | grep ovsdb
odl-ovsdb-southbound-api          | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: api
odl-ovsdb-southbound-impl         | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: impl
odl-ovsdb-southbound-impl-rest    | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: impl :: REST
odl-ovsdb-southbound-impl-ui      | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: impl :: UI
odl-ovsdb-library                 | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-library-1.2.1-SNAPSHOT        | OpenDaylight :: library
odl-ovsdb-openstack               | 1.2.1-SNAPSHOT   | x         | ovsdb-1.2.1-SNAPSHOT                    | OpenDaylight :: OVSDB :: OpenStack Network Virtual</screen>

</section>
</section>
<section xml:id="_testing_patches">
<title>Testing patches</title>
<simpara>It is recommended that you test your patches locally before submission.</simpara>
</section>
<section xml:id="_neutron_integration">
<title>Neutron integration</title>
<simpara>To test patches to the Neutron integration, you need a <link xlink:href="http://devstack.org/guides/multinode-lab.html">Multi-Node Devstack Setup</link>. The ``resources`` folder contains sample ``local.conf`` files.</simpara>
</section>
<section xml:id="_open_vswitch">
<title>Open vSwitch</title>
<simpara>To test patches to the library, you will need a working <link xlink:href="http://openvswitch.org/">Open vSwitch</link>. Packages are available for most Linux distributions. If you would like to run multiple versions of Open vSwitch for testing you can use <link xlink:href="https://github.com/dave-tucker/docker-ovs">docker-ovs</link> to run Open vSwitch in <link xlink:href="https://www.docker.com/">Docker</link> containers.</simpara>
</section>
<section xml:id="_mininet">
<title>Mininet</title>
<simpara><link xlink:href="http://mininet.org/">Mininet</link> is another useful resource for testing patches. Mininet creates multiple Open vSwitches connected in a configurable topology.</simpara>
</section>
<section xml:id="_vagrant">
<title>Vagrant</title>
<simpara>The Vagrant file in the root of the OVSDB source code provides an easy way to create VMs for tests.</simpara>
<itemizedlist>
<listitem>
<simpara>To install Vagrant on your machine, follow the steps at: <link xlink:href="https://docs.vagrantup.com/v2/installation/">Installing Vagrant</link>.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Testing with Devstack</emphasis></simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Start the controller.</simpara>
</listitem>
</orderedlist>

<screen>vagrant up devstack-control
vagrant ssh devstack-control
cd devstack
./stack.sh</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Run the following:</simpara>
</listitem>
</orderedlist>

<screen>vagrant up devstack-compute-1
vagrant ssh devstack-compute-1
cd devstack
./stack.sh</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>To start testing, create a new VM.</simpara>
</listitem>
</orderedlist>

<screen>nova boot --flavor m1.tiny --image $(nova image-list | grep 'cirros-0.3.1-x86_64-uec\s' | awk '{print $2}') --nic net-id=$(neutron net-list | grep private | awk '{print $2}') test</screen>

<simpara>To create three, use the following:</simpara>
<screen>nova boot --flavor m1.tiny --image $(nova image-list | grep 'cirros-0.3.1-x86_64-uec\s' | awk '{print $2}') --nic net-id=$(neutron net-list | grep private | awk '{print $2}') --num-instances 3 test</screen>

<formalpara>
<title>To get a mininet installation for testing:</title>
<para>
<screen>vagrant up mininet
vagrant ssh mininet</screen>
</para>
</formalpara>

<orderedlist numeration="arabic">
<listitem>
<simpara>Use the following to clean up when finished:</simpara>
</listitem>
</orderedlist>

<screen>vagrant destroy</screen>

</section>
</section>
<section xml:id="_ovsdb_integration_design">
<title>OVSDB integration design</title>
<section xml:id="_resources">
<title>Resources</title>
<simpara>See the following:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="http://networkheresy.com/2012/09/15/remembering-the-management-plane/">Network Heresy</link></simpara>
</listitem>
</itemizedlist>

<simpara>See the OVSDB YouTube Channel for getting started videos and other tutorials:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="http://www.youtube.com/channel/UCMYntfZ255XGgYFrxCNcAzA">ODL OVSDB Youtube Channel</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/OVSDB_Integration:Mininet_OVSDB_Tutorial">Mininet OVSDB Tutorial</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/OVSDB_Integration:Main#Getting_Started_with_OpenDaylight_OVSDB_Plugin_Network_Virtualization">OVSDB Getting Started</link></simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_opendaylight_ovsdb_southbound_plugin_architecture_and_design">
<title>OpenDaylight OVSDB southbound plugin architecture and design</title>
<simpara>OpenVSwitch (OVS) is generally accepted as the unofficial standard for Virtual Switching in the Open hypervisor based solutions. Every other Virtual Switch implementation, properietery or otherwise, uses OVS in some form.
For information on OVS, see <link xlink:href="http://openvswitch.org/">Open vSwitch</link>.</simpara>
<simpara>In Software Defined Networking (SDN), controllers and applications interact using two channels: OpenFlow and OVSDB. OpenFlow addresses the forwarding-side of the OVS functionality. OVSDB, on the other hand, addresses the management-plane.
A simple and concise overview of Open Virtual Switch Database(OVSDB) is available at: <link xlink:href="http://networkstatic.net/getting-started-ovsdb/">http://networkstatic.net/getting-started-ovsdb/</link></simpara>
<section xml:id="_overview_of_opendaylight_controller_architecture">
<title>Overview of OpenDaylight Controller architecture</title>
<simpara>The OpenDaylight controller platform is designed as a highly modular and plugin based middleware that serves various network applications in a variety of use-cases. The modularity is achieved through the Java OSGi framework. The controller consists of many Java OSGi bundles that work together to provide the required
 controller functionalities.</simpara>
<simpara>The bundles can be placed in the following broad categories:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Network Service Functional Modules (Examples: Topology Manager, Inventory Manager, Forwarding Rules Manager,and others)</simpara>
</listitem>
<listitem>
<simpara>NorthBound API Modules (Examples: Topology APIs, Bridge Domain APIs, Neutron APIs, Connection Manager APIs, and others)</simpara>
</listitem>
<listitem>
<simpara>Service Abstraction Layer(SAL)- (Inventory Services, DataPath Services, Topology Services, Network Config, and others)</simpara>
</listitem>
<listitem>
<simpara>SouthBound Plugins (OpenFlow Plugin, OVSDB Plugin, OpenDove Plugin, and others)</simpara>
</listitem>
<listitem>
<simpara>Application Modules (Simple Forwarding, Load Balancer)</simpara>
</listitem>
</itemizedlist>

<simpara>Each layer of the Controller architecture performs specified tasks, and hence aids in modularity.
While the Northbound API layer addresses all the REST-Based application needs, the SAL layer takes care of abstracting the SouthBound plugin protocol specifics from the Network Service functions.</simpara>
<simpara>Each of the SouthBound Plugins serves a different purpose, with some overlapping.
For example, the OpenFlow plugin might serve the Data-Plane needs of an OVS element, while the OVSDB plugin can serve the management plane needs of the same OVS element.
As the Openflow Plugin talks OpenFlow protocol with the OVS element, the OVSDB plugin will use OVSDB schema over JSON-RPC transport.</simpara>
</section>
</section>
<section xml:id="_ovsdb_southbound_plugin">
<title>OVSDB southbound plugin</title>
<simpara>The <link xlink:href="http://tools.ietf.org/html/draft-pfaff-ovsdb-proto-02">Open vSwitch Database Management Protocol-draft-02</link> and <link xlink:href="http://openvswitch.org/ovs-vswitchd.conf.db.5.pdf">Open vSwitch Manual</link> provide theoretical information about OVSDB.
The OVSDB protocol draft is generic enough to lay the groundwork on Wire Protocol and Database Operations, and the OVS Manual currently covers 13 tables leaving space for future OVS expansion, and vendor expansions on proprietary implementations.
The OVSDB Protocol is a database records transport protocol using JSON RPC1.0. For information on the protocol structure, see <link xlink:href="http://networkstatic.net/getting-started-ovsdb/">Getting Started with OVSDB</link>.
The OpenDaylight OVSDB southbound plugin consists of one or more OSGi bundles addressing the following services or functionalities:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Connection Service - Based on Netty</simpara>
</listitem>
<listitem>
<simpara>Network Configuration Service</simpara>
</listitem>
<listitem>
<simpara>Bidirectional JSON-RPC Library</simpara>
</listitem>
<listitem>
<simpara>OVSDB Schema definitions and Object mappers</simpara>
</listitem>
<listitem>
<simpara>Overlay Tunnel management</simpara>
</listitem>
<listitem>
<simpara>OVSDB to OpenFlow plugin mapping service</simpara>
</listitem>
<listitem>
<simpara>Inventory Service</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_connection_service">
<title>Connection service</title>
<simpara>One of the primary services that most southbound plugins provide in Opendaylight a Connection Service. The service provides protocol specific connectivity to network elements, and supports the connectivity management services as specified by the OpenDaylight Connection Manager.
The connectivity services include:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Connection to a specified element given IP-address, L4-port, and other connectivity options (such as authentication,&#8230;)</simpara>
</listitem>
<listitem>
<simpara>Disconnection from an element</simpara>
</listitem>
<listitem>
<simpara>Handling Cluster Mode change notifications to support the OpenDaylight Clustering/High-Availability feature</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_network_configuration_service">
<title>Network Configuration Service</title>
<simpara>The goal of the OpenDaylight Network Configuration services is to provide complete management plane solutions needed to successfully install, configure, and deploy the various SDN based network services. These are generic services which can be implemented in part or full by any south-bound protocol plugin.
The south-bound plugins can be either of the following:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>The new network virtualization protocol plugins such as OVSDB JSON-RPC</simpara>
</listitem>
<listitem>
<simpara>The traditional management protocols such as SNMP or any others in the middle.</simpara>
</listitem>
</itemizedlist>

<simpara>The above definition, and more information on Network Configuration Services, is available at : <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Controller:NetworkConfigurationServices">https://wiki.opendaylight.org/view/OpenDaylight_Controller:NetworkConfigurationServices</link></simpara>
<section xml:id="_bidirectional_json_rpc_library">
<title>Bidirectional JSON-RPC library</title>
<simpara>The OVSDB plugin implements a Bidirectional JSON-RPC library.  It is easy to design the library as a module that manages the Netty connection towards the Element.</simpara>
<simpara>The main responsibilities of this Library are:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Demarshal and marshal JSON Strings to JSON objects</simpara>
</listitem>
<listitem>
<simpara>Demarshal and marshal JSON Strings from and to the Network Element.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_ovsdb_schema_definitions_and_object_mappers">
<title>OVSDB Schema definitions and Object mappers</title>
<simpara>The OVSDB Schema definitions and Object Mapping layer sits above the JSON-RPC library. It maps the generic JSON objects to OVSDB schema POJOs (Plain Old Java Object) and vice-versa. This layer mostly provides the Java Object definition for the corresponding OVSDB schema (13 of them) and also will provide much more friendly API abstractions on top of these object data. This helps in hiding the JSON semantics from the functional modules such as Configuration Service and Tunnel management.</simpara>
<simpara>On the demarshaling side the mapping logic differentiates the Request and Response messages as follows :<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>Request messages are mapped by its "method"</simpara>
</listitem>
<listitem>
<simpara>Response messages are mapped by their IDs which were originally populated by the Request message.
The JSON semantics of these OVSDB schema is quite complex.
The following figures summarize two of the end-to-end scenarios:<?asciidoc-br?></simpara>
</listitem>
</itemizedlist>

<figure>
<title>End-to-end handling of a Create Bridge request</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ConfigurationService-example1.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ConfigurationService example1</phrase></textobject>
  </mediaobject>
</figure>

<figure>
<title>End-to-end handling of a monitor response</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/MonitorResponse.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>MonitorResponse</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_overlay_tunnel_management">
<title>Overlay tunnel management</title>
<simpara>Network Virtualization using OVS is achieved through Overlay Tunnels. The actual Type of the Tunnel may be GRE, VXLAN, or STT. The differences in the encapsulation and configuration decide the tunnel types. Establishing a tunnel using configuration service requires just the sending of OVSDB messages towards the ovsdb-server. However, the scaling issues that would arise on the state management at the data-plane (using OpenFlow) can get challenging. Also, this module can assist in various optimizations in the presence of Gateways. It can also help in providing Service guarantees for the VMs using these overlays with the help of underlay orchestration.</simpara>
</section>
<section xml:id="_ovsdb_to_openflow_plugin_mapping_service">
<title>OVSDB to OpenFlow plugin mapping service</title>
<simpara>The connect() of the ConnectionService  would result in a Node that represents an ovsdb-server. The CreateBridgeDomain() Configuration on the above Node would result in creating an OVS bridge. This OVS Bridge is an OpenFlow Agent for the OpenDaylight OpenFlow plugin with its own Node represented as (example) OF|xxxx.yyyy.zzzz.
Without any help from the OVSDB plugin, the Node Mapping Service of the Controller platform would not be able to map the following:<?asciidoc-br?></simpara>
<screen>{OVSDB_NODE + BRIDGE_IDENTFIER} &lt;---&gt; {OF_NODE}.</screen>

<simpara>Without such mapping, it would be extremely difficult for the applications to manage and maintain such nodes. This Mapping Service provided by the OVSDB plugin would essentially help in providing more value added services to the orchestration layers that sit atop the Northbound APIs (such as OpenStack).</simpara>
</section>
</section>
<section xml:id="_opendaylight_ovsdb_developer_getting_started_video_series">
<title>OpenDaylight OVSDB Developer Getting Started Video Series</title>
<simpara>The video series were started to help developers bootstrap into OVSDB development.</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="http://www.youtube.com/watch?v=ieB645oCIPs">OpenDaylight OVSDB Developer Getting Started</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://www.youtube.com/watch?v=xgevyaQ12cg">OpenDaylight OVSDB Developer Getting Started - Northbound API Usage</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://www.youtube.com/watch?v=xgevyaQ12cg">OpenDaylight OVSDB Developer Getting Started - Java APIs</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://www.youtube.com/watch?v=NayuY6J-AMA">OpenDaylight OVSDB Developer Getting Started - OpenStack Integration OpenFlow v1.0</link></simpara>
</listitem>
</itemizedlist>

<section xml:id="_other_developer_tutorials">
<title>Other developer tutorials</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://docs.google.com/presentation/d/1KIuNDuUJGGEV37Zk9yzx9OSnWExt4iD2Z7afycFLf_I/edit?usp=sharing">OVSDB NetVirt Tutorial</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://www.youtube.com/watch?v=2axNKHvt5MY&amp;list=PL8F5jrwEpGAiJG252ShQudYeodGSsks2l&amp;index=43">Youtube of OVSDB NetVirt tutorial</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/OVSDB:OVSDB_OpenStack_Guide">OVSDB OpenFlow v1.3 Neutron ML2 Integration</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://networkstatic.net/getting-started-ovsdb/">Open vSwitch Database Table Explanations and Simple Jackson Tutorial</link></simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_ovsdb_integration_new_features">
<title>OVSDB integration: New features</title>
<section xml:id="_schema_independent_library">
<title>Schema independent library</title>
<simpara>The OVS connection is a node which can have multiple databases. Each database is represented by a schema. A single connection can have multiple schemas.
OSVDB supports multiple schemas. Currently, these are two schemas available in the
OVSDB, but there is no restriction on the number of schemas. Owing to the Northbound v3 API, no code changes in ODL are needed for supporting additional schemas.</simpara>
<simpara>Schemas:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>openvswitch : Schema wrapper that represents <link xlink:href="http://openvswitch.org/ovs-vswitchd.conf.db.5.pdf">http://openvswitch.org/ovs-vswitchd.conf.db.5.pdf</link></simpara>
</listitem>
<listitem>
<simpara>hardwarevtep: Schema wrapper that represents <link xlink:href="http://openvswitch.org/docs/vtep.5.pdf">http://openvswitch.org/docs/vtep.5.pdf</link></simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_port_security">
<title>Port security</title>
<simpara>Based on the fact that security rules can be obtained from a port object, OVSDB can apply Open Flow rules. These rules will match on what types of traffic the Openstack tenant VM is allowed to use.</simpara>
<simpara>Support for security groups is very experimental. There are limitations in determining the state of flows in the Open vSwitch. See <link xlink:href="http://%20https//www.youtube.com/watch?v=DSop2uLJZS8">Open vSwitch and the Intelligent Edge</link> from Justin Petit for a deep dive into the challenges we faced creating a flow based port security implementation. The current set of rules that will be installed only supports filtering of the TCP protocol. This is because via a Nicira TCP_Flag read we can match on a flows TCP_SYN flag, and permit or deny the flow based on the Neutron port security rules. If rules are requested for ICMP and UDP, they are ignored until greater visibility from the Linux kernel is available as outlined in the OpenStack presentation mentioned earlier.</simpara>
<simpara>Using the port security groups of Neutron, one can add rules that restrict the network access of the tenants. The OVSDB Neutron integration checks the port security rules configured, and apply them by means of openflow rules.</simpara>
<simpara>Through the ML2 interface, Neutron security rules are available in the port object, following this scope: Neutron Port &#8594; Security Group &#8594; Security Rules.</simpara>
<simpara>The current rules are applied on the basis of the following attributes: ingress/egress, tcp protocol, port range, and prefix.</simpara>
<section xml:id="_openstack_workflow">
<title>OpenStack workflow</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a stack.</simpara>
</listitem>
<listitem>
<simpara>Add the network and subnet.</simpara>
</listitem>
<listitem>
<simpara>Add the Security Group and Rules.</simpara>
</listitem>
</orderedlist>

<note>
<simpara>This is no different than what users normally do in regular openstack deployments.</simpara>
</note>

<screen>neutron security-group-create group1 --description "Group 1"
neutron security-group-list
neutron security-group-rule-create --direction ingress --protocol tcp group1</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Start the tenant, specifying the security-group.</simpara>
</listitem>
</orderedlist>

<screen>nova boot --flavor m1.tiny \
--image $(nova image-list | grep 'cirros-0.3.1-x86_64-uec\s' | awk '{print $2}') \
--nic net-id=$(neutron net-list | grep 'vxlan2' | awk '{print $2}') vxlan2 \
--security-groups group1</screen>

</section>
<section xml:id="_examples_rules_supported">
<title>Examples: Rules supported</title>
<screen>neutron security-group-create group2 --description "Group 2"
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 54 group2
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 80 group2
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 1633 group2
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 22 group2</screen>

<screen>neutron security-group-create group3 --description "Group 3"
neutron security-group-rule-create --direction ingress --protocol tcp --remote-ip-prefix 10.200.0.0/16 group3</screen>

<screen>neutron security-group-create group4 --description "Group 4"
neutron security-group-rule-create --direction ingress --remote-ip-prefix 172.24.0.0/16 group4</screen>

<screen>neutron security-group-create group5 --description "Group 5"
neutron security-group-rule-create --direction ingress --protocol tcp group5
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 54 group5
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 80 group5
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 1633 group5
neutron security-group-rule-create --direction ingress --protocol tcp --port-range-min 22 group5</screen>

<screen>neutron security-group-create group6 --description "Group 6"
neutron security-group-rule-create --direction ingress --protocol tcp --remote-ip-prefix 0.0.0.0/0 group6</screen>

<screen>neutron security-group-create group7 --description "Group 7"
neutron security-group-rule-create --direction egress --protocol tcp --port-range-min 443 --remote-ip-prefix 172.16.240.128/25 group7</screen>

<simpara><emphasis role="strong">Reference gist</emphasis>:https://gist.github.com/anonymous/1543a410d57f491352c8[Gist]</simpara>
</section>
<section xml:id="_security_group_rules_supported_in_odl">
<title>Security group rules supported in ODL</title>
<simpara>The following rules formata are supported in the current implementation. The direction (ingress/egress) is always expected. Rules are implemented such that tcp-syn packets that do not satisfy the rules are dropped.</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <?dbhtml table-width="60%"?>
  <?dbfo table-width="60%"?>
  <?dblatex table-width="60%"?>
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="84*"/>
    
    <colspec colname="col_2" colwidth="84*"/>
    
    <colspec colname="col_3" colwidth="84*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Proto</entry>
        
        <entry align="left" valign="top">Port</entry>
        
        <entry align="left" valign="top">IP Prefix</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TCP</simpara></entry>
        
        <entry align="left" valign="top"><simpara>x</simpara></entry>
        
        <entry align="left" valign="top"><simpara>x</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Any</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Any</simpara></entry>
        
        <entry align="left" valign="top"><simpara>x</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TCP</simpara></entry>
        
        <entry align="left" valign="top"><simpara>x</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Any</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TCP</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Any</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Any</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_limitations">
<title>Limitations</title>
<itemizedlist>
<listitem>
<simpara>Soon, conntrack will be supported by OVS. Until then, TCP flags are used as way of checking for connection state. Specifically, that is done by matching on the TCP-SYN flag.</simpara>
</listitem>
<listitem>
<simpara>The param <emphasis>--port-range-max</emphasis> in <emphasis>security-group-rule-create</emphasis> is not used until the implementation uses contrack.</simpara>
</listitem>
<listitem>
<simpara>No UDP/ICMP specific match support is provided.</simpara>
</listitem>
<listitem>
<simpara>No IPv6 support is provided.</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_l3_forwarding">
<title>L3 forwarding</title>
<simpara>OVSDB extends support for the usage of an ODL-Neutron-driver so that OVSDB can configure OF 1.3 rules to route IPv4 packets. The driver eliminates the need for the router of the L3 Agent. In order to accomplish that, OVS 2.1 or a newer version is required.
OVSDB also supports inbound/outbound NAT, floating IPs.</simpara>
<section xml:id="_starting_ovsdb_and_openstack">
<title>Starting OVSDB and OpenStack</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Build or download OVSDB distribution, as mentioned in <link linkend="ovsdbBuildSteps">building a Karaf feature section</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://docs.vagrantup.com/v2/installation/index.html">Install Vagrant</link>.</simpara>
</listitem>
</orderedlist>

<orderedlist numeration="arabic">
<listitem>
<simpara>Enable the L3 Forwarding feature:</simpara>
</listitem>
</orderedlist>

<screen>echo 'ovsdb.l3.fwd.enabled=yes' &gt;&gt; ./opendaylight/configuration/config.ini
echo 'ovsdb.l3gateway.mac=${GATEWAY_MAC}' &gt;&gt; ./configuration/config.ini</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Run the following commands to get the odl neutron drivers:</simpara>
</listitem>
</orderedlist>

<screen>git clone https://github.com/dave-tucker/odl-neutron-drivers.git
cd odl-neutron-drivers
vagrant up devstack-control devstack-compute-1</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Use ssh to go to the control node, and clone odl-neutron-drivers again:</simpara>
</listitem>
</orderedlist>

<screen>vagrant ssh devstack-control
git clone https://github.com/dave-tucker/odl-neutron-drivers.git
cd odl-neutron-drivers
sudo python setup.py install
*leave this shell open*</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Start odl, as mentioned in <link linkend="ovsdbStartingOdl">running Karaf feature section</link>.</simpara>
</listitem>
<listitem>
<simpara>To see processing of neutron event related to L3, do this from prompt:</simpara>
</listitem>
</orderedlist>

<screen>log:set debug org.opendaylight.ovsdb.openstack.netvirt.impl.NeutronL3Adapter</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>From shell, do one of the following: open on ssh into control node or vagrant ssh devstack-control.</simpara>
</listitem>
</orderedlist>

<screen>cd ~/devstack &amp;&amp; ./stack.sh</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>From a new shell in the host system, run the following:</simpara>
</listitem>
</orderedlist>

<screen>cd odl-neutron-drivers
vagrant ssh devstack-compute-1
cd ~/devstack &amp;&amp; ./stack.sh</screen>

</section>
<section xml:id="_openstack_workflow_2">
<title>OpenStack workflow</title>
<figure>
<title>Sample workflow</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/L3FwdSample.png" contentdepth="250"/>
    </imageobject>
    <textobject><phrase>L3FwdSample</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Use the following steps to set up a workflow like the one shown in figure above.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Set up authentication. From shell on stack control or vagrant ssh devstack-control:</simpara>
</listitem>
</orderedlist>

<screen>source openrc admin admin</screen>

<screen>rm -f id_rsa_demo* ; ssh-keygen -t rsa -b 2048 -N  -f id_rsa_demo
 nova keypair-add --pub-key  id_rsa_demo.pub  demo_key
 # nova keypair-list</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Create two networks and two subnets.</simpara>
</listitem>
</orderedlist>

<screen>neutron net-create net1 --tenant-id $(keystone tenant-list | grep '\s'admin | awk '{print $2}') \
 --provider:network_type gre --provider:segmentation_id 555</screen>

<screen>neutron subnet-create --tenant-id $(keystone tenant-list | grep '\s'admin | awk '{print $2}') \
net1 10.0.0.0/16 --name subnet1 --dns-nameserver 8.8.8.8</screen>

<screen>neutron net-create net2 --tenant-id $(keystone tenant-list | grep '\s'admin | awk '{print $2}') \
 --provider:network_type gre --provider:segmentation_id 556</screen>

<screen>neutron subnet-create --tenant-id $(keystone tenant-list | grep '\s'admin | awk '{print $2}') \
 net2 20.0.0.0/16 --name subnet2 --dns-nameserver 8.8.8.8</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Create a router, and add an interface to each of the two subnets.</simpara>
</listitem>
</orderedlist>

<screen>neutron router-create demorouter --tenant-id $(keystone tenant-list | grep '\s'admin | awk '{print $2}')
 neutron router-interface-add demorouter subnet1
 neutron router-interface-add demorouter subnet2
 # neutron router-port-list demorouter</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Create two tenant instances.</simpara>
</listitem>
</orderedlist>

<screen>nova boot --poll --flavor m1.nano --image $(nova image-list | grep 'cirros-0.3.2-x86_64-uec\s' | awk '{print $2}') \
 --nic net-id=$(neutron net-list | grep -w net1 | awk '{print $2}'),v4-fixed-ip=10.0.0.10 \
 --availability-zone nova:devstack-control \
 --key-name demo_key host10</screen>

<screen>nova boot --poll --flavor m1.nano --image $(nova image-list | grep 'cirros-0.3.2-x86_64-uec\s' | awk '{print $2}') \
 --nic net-id=$(neutron net-list | grep -w net2 | awk '{print $2}'),v4-fixed-ip=20.0.0.20 \
 --availability-zone nova:devstack-compute-1 \
 --key-name demo_key host20</screen>

</section>
<section xml:id="_limitations_2">
<title>Limitations</title>
<itemizedlist>
<listitem>
<simpara>To use this feature, you need OVS 2.1 or newer version.</simpara>
</listitem>
<listitem>
<simpara>Owing to OF limitations, icmp responses due to routing failures, like ttl expired or host unreacheable, are not generated.</simpara>
</listitem>
<listitem>
<simpara>The MAC address of the default route is not automatically mapped. In order to route to L3 destinations outside the networks of the tenant, the manual configuration of the default route is necessary. To provide the MAC address of the default route, use ovsdb.l3gateway.mac in file configuration/config.ini ;</simpara>
</listitem>
<listitem>
<simpara>This feature is Tech preview, which depends on later versions of OpenStack to be used without the provided neutron-driver.</simpara>
</listitem>
<listitem>
<simpara>No IPv6 support is provided.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">More information on L3 forwarding</emphasis>:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara>odl-neutron-driver: <link xlink:href="https://github.com/dave-tucker/odl-neutron-drivers">https://github.com/dave-tucker/odl-neutron-drivers</link></simpara>
</listitem>
<listitem>
<simpara>OF rules example: <link xlink:href="http://dtucker.co.uk/hack/building-a-router-with-openvswitch.html">http://dtucker.co.uk/hack/building-a-router-with-openvswitch.html</link></simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_lbaas">
<title>LBaaS</title>
<simpara>Load-Balancing-as-a-Service (LBaaS) creates an Open vSwitch powered L3-L4 stateless load-balancer in a virtualized network environment so that individual TCP connections destined to a designated virtual IP (VIP) are sent to the appropriate servers (that is to say, serving app VMs). The load-balancer works in a session-preserving, proactive manner without involving the controller during flow setup.</simpara>
<simpara>A Neutron northbound interface is provided to create a VIP which will map to a pool of servers (that is to say, members) within a subnet. The pools consist of members identified by an IP address. The goal is to closely match the API to the OpenStack LBaaS v2 API: <link xlink:href="http://docs.openstack.org/api/openstack-network/2.0/content/lbaas_ext.html">http://docs.openstack.org/api/openstack-network/2.0/content/lbaas_ext.html</link>.</simpara>
<section xml:id="_creating_an_openstack_workflow">
<title>Creating an OpenStack workflow</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a subnet.</simpara>
</listitem>
<listitem>
<simpara>Create a floating VIP <emphasis>A</emphasis> that maps to a private VIP <emphasis>B</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Create a Loadbalancer pool <emphasis>X</emphasis>.</simpara>
</listitem>
</orderedlist>

<screen>neutron lb-pool-create --name http-pool --lb-method ROUND_ROBIN --protocol HTTP --subnet-id XYZ</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Create a Loadbalancer pool member <emphasis>Y</emphasis> and associate with pool <emphasis>X</emphasis>.</simpara>
</listitem>
</orderedlist>

<screen>neutron lb-member-create --address 10.0.0.10 --protocol-port 80 http-pool
neutron lb-member-create --address 10.0.0.11 --protocol-port 80 http-pool
neutron lb-member-create --address 10.0.0.12 --protocol-port 80 http-pool
neutron lb-member-create --address 10.0.0.13 --protocol-port 80 http-pool</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Create a Loadbalancer instance <emphasis>Z</emphasis>, and associate pool <emphasis>X</emphasis> and VIP <emphasis>B</emphasis> with it.</simpara>
</listitem>
</orderedlist>

<screen>neutron lb-vip-create --name http-vip --protocol-port 80 --protocol HTTP --subnet-id XYZ http-pool</screen>

</section>
<section xml:id="_implementation">
<title>Implementation</title>
<simpara>The current implementation of the proactive stateless load-balancer was made using "multipath" action in the Open vSwitch. The "multipath" action takes a max_link parameter value (which is same as the number of pool members) as input, and performs a hash of the fields to get a value between (0, max_link). The value of the hash is used as an index to select a pool member to handle that session.</simpara>
</section>
</section>
<section xml:id="_open_vswitch_rules">
<title>Open vSwitch rules</title>
<simpara>Assuming that table=20 contains all the rules to forward the traffic destined for a specific destination MAC address, the following are the rules needed to be programmed in the LBaaS service table=10. The programmed rules makes the translation from the VIP to a different pool member for every session.</simpara>
<itemizedlist>
<listitem>
<simpara>Proactive forward rules:</simpara>
</listitem>
</itemizedlist>

<screen>sudo ovs-ofctl -O OpenFlow13 add-flow s1 "table=10,reg0=0,ip,nw_dst=10.0.0.5,actions=load:0x1-&gt;NXM_NX_REG0[[]],multipath(symmetric_l4, 1024, modulo_n, 4, 0, NXM_NX_REG1[0..12]),resubmit(,10)"
sudo ovs-ofctl -O OpenFlow13 add-flow s1 table=10,reg0=1,nw_dst=10.0.0.5,ip,reg1=0,actions=mod_dl_dst:00:00:00:00:00:10,mod_nw_dst:10.0.0.10,goto_table:20
sudo ovs-ofctl -O OpenFlow13 add-flow s1 table=10,reg0=1,nw_dst=10.0.0.5,ip,reg1=1,actions=mod_dl_dst:00:00:00:00:00:11,mod_nw_dst:10.0.0.11,goto_table:20
sudo ovs-ofctl -O OpenFlow13 add-flow s1 table=10,reg0=1,nw_dst=10.0.0.5,ip,reg1=2,actions=mod_dl_dst:00:00:00:00:00:12,mod_nw_dst:10.0.0.12,goto_table:20
sudo ovs-ofctl -O OpenFlow13 add-flow s1 table=10,reg0=1,nw_dst=10.0.0.5,ip,reg1=3,actions=mod_dl_dst:00:00:00:00:00:13,mod_nw_dst:10.0.0.13,goto_table:20</screen>

<itemizedlist>
<listitem>
<simpara>Proactive reverse rules:</simpara>
</listitem>
</itemizedlist>

<screen>sudo ovs-ofctl -O OpenFlow13 add-flow s1 table=10,ip,tcp,tp_src=80,actions=mod_dl_src:00:00:00:00:00:05,mod_nw_src:10.0.0.5,goto_table:20</screen>

<section xml:id="_ovsdb_project_code">
<title>OVSDB project code</title>
<simpara>The current implementation handles all neutron calls in the net-virt/LBaaSHandler.java code, and makes calls to the net-virt-providers/LoadBalancerService to program appropriate flowmods. The rules are updated whenever there is a change in the Neutron LBaaS settings. There is no cache of state kept in the net-virt or providers.</simpara>
</section>
<section xml:id="_limitations_3">
<title>Limitations</title>
<simpara>Owing to the inflexibility of the multipath action, the existing LBaaS implementation comes with some limitations:</simpara>
<itemizedlist>
<listitem>
<simpara>TCP, HTTP or HTTPS are supported protocols for the pool. (Caution: You can lose access to the members if you assign {Proto:TCP, Port:22} to LB)</simpara>
</listitem>
<listitem>
<simpara>Member weights are ignored.</simpara>
</listitem>
<listitem>
<simpara>The update of an LB instance is done as a delete + add, and not an actual delta.</simpara>
</listitem>
<listitem>
<simpara>The update of an LB member is not supported (because weights are ignored).</simpara>
</listitem>
<listitem>
<simpara>Deletion of an LB member leads to the reprogramming of the LB on all nodes (because of the way multipath does link hash).</simpara>
</listitem>
<listitem>
<simpara>There is only a single LB instance per subnet because the pool-id is not reported in the create load-balancer call.</simpara>
</listitem>
</itemizedlist>

</section>
</section>
</section>
</section>
<section xml:id="ovsdb-library-developer-guide">
<title>OVSDB Library Developer Guide</title>
<section xml:id="overview">
<title>Overview</title>
<simpara>The OVSDB library manages the Netty connections to network nodes and
handles bidirectional JSON-RPC messages. It not only provides OVSDB
protocol functionality to OpenDaylight OVSDB plugin but also can be used
as standalone JAVA library for OVSDB protocol.</simpara>
<simpara>The main responsibilities of OVSDB library include:</simpara>
<itemizedlist>
<listitem>
<simpara>Manage connections to peers</simpara>
</listitem>
<listitem>
<simpara>Marshal and unmarshal JSON Strings to JSON objects.</simpara>
</listitem>
<listitem>
<simpara>Marshal and unmarshal JSON Strings from and to the Network Element.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="connection-service">
<title>Connection Service</title>
<simpara>The OVSDB library provides connection management through the OvsdbConnection
interface. The OvsdbConnection interface provides OVSDB connection
management APIs which include both active and passive connections. From
the library perspective, active OVSDB connections are initiated from the
controller to OVS nodes while passive OVSDB connections are initiated
from OVS nodes to the controller. In the active connection scenario
an application needs to provide the IP address and listening port of OVS nodes
to the library management API. On the other hand, the library management API
only requires the info of the controller listening port in the passive
connection scenario.</simpara>
<simpara>For a passive connection scenario, the library also provides a connection
event listener through the OvsdbConnectionListener interface. The listener
interface has connected() and disconnected() methods to notify an
application when a new passive connection is established or an existing
connection is terminated.</simpara>
</section>
<section xml:id="ssl-connection">
<title>SSL Connection</title>
<simpara>In addition to a regular TCP connection, the OvsdbConnection interface
also provides a connection management API for an SSL connection. To start
an OVSDB connection with SSL, an application will need to provide a Java
SSLContext object to the management API. There are different ways
to create a Java SSLContext, but in most cases a Java KeyStore with
certificate and private key provided by the application is required.
Detailed steps about how to create a Java SSLContext is out of the scope of
this document and can be found in the Java documentation for
<link xlink:href="http://goo.gl/5svszT">JAVA Class SSlContext</link>.</simpara>
<simpara>In the active connection scenario, the library uses the given SSLContext to
create a Java SSLEngine and configures the SSL engine with the client mode for
SSL handshaking. Normally clients are not required to authenticate
themselves.</simpara>
<simpara>In the passive connection scenario, the library uses the given SSLContext to
create a Java SSLEngine which will operate in server mode for SSL
handshaking. For security reasons, the SSLv3 protocol and some cipher suites
are disabled. Currently the OVSDB server only supports the
TLS_RSA_WITH_AES_128_CBC_SHA cipher suite and the following protocols:
SSLv2Hello, TLSv1, TLSv1.1, TLSv1.2.</simpara>
<simpara>The SSL engine is also configured to operate on two-way authentication
mode for passive connection scenarios, i.e., the OVSDB server (controller)
will authenticate clients (OVS nodes) and clients (OVS nodes) are also
required to authenticate the server (controller). In the two-way
authentication mode, an application should keep a trust manager to store
the certificates of trusted clients and initialize a Java SSLContext with this
trust manager. Thus during the SSL handshaking process the OVSDB server
(controller) can use the trust manager to verify clients and only accept
connection requests from trusted clients. On the other hand, users should
also configure OVS nodes to authenticate the controller. Open vSwitch
already supports this functionality in the ovsdb-server command with option
<literal>--ca-cert=cacert.pem</literal> and <literal>--bootstrap-ca-cert=cacert.pem</literal>. On the OVS
node, a user can use the option <literal>--ca-cert=cacert.pem</literal> to specify a controller
certificate directly and the node will only allow connections to the
controller with the specified certificate. If the OVS node runs ovsdb-server
with option <literal>--bootstrap-ca-cert=cacert.pem</literal>, it will authenticate the
controller with the specified certificate cacert.pem. If the certificate
file doesn’t exist, it will attempt to obtain a certificate from the
peer (controller) on its first SSL connection and save it to the named
PEM file <literal>cacert.pem</literal>. Here is an example of ovsdb-server with
<literal>--bootstrap-ca-cert=cacert.pem</literal> option:</simpara>
<simpara><literal>ovsdb-server --pidfile --detach --log-file --remote punix:/var/run/openvswitch/db.sock --remote=db:hardware_vtep,Global,managers --private-key=/etc/openvswitch/ovsclient-privkey.pem -- certificate=/etc/openvswitch/ovsclient-cert.pem --bootstrap-ca-cert=/etc/openvswitch/vswitchd.cacert</literal></simpara>
</section>
<section xml:id="ovsdb-protocol-transactions">
<title>OVSDB protocol transactions</title>
<simpara>The OVSDB protocol defines the RPC transaction methods in RFC 7047.
The following RPC methods are supported in OVSDB protocol:</simpara>
<itemizedlist>
<listitem>
<simpara>List databases</simpara>
</listitem>
<listitem>
<simpara>Get schema</simpara>
</listitem>
<listitem>
<simpara>Transact</simpara>
</listitem>
<listitem>
<simpara>Cancel</simpara>
</listitem>
<listitem>
<simpara>Monitor</simpara>
</listitem>
<listitem>
<simpara>Update notification</simpara>
</listitem>
<listitem>
<simpara>Monitor cancellation</simpara>
</listitem>
<listitem>
<simpara>Lock operations</simpara>
</listitem>
<listitem>
<simpara>Locked notification</simpara>
</listitem>
<listitem>
<simpara>Stolen notification</simpara>
</listitem>
<listitem>
<simpara>Echo</simpara>
</listitem>
</itemizedlist>

<simpara>According to RFC 7047, an OVSDB server must implement all methods, and
an OVSDB client is only required to implement the "Echo" method and
otherwise free to implement whichever methods suit its needs. However,
the OVSDB library currently doesn’t support all RPC methods. For the "Echo"
method, the library can handle "Echo" messages from a peer and send a JSON
response message back, but the library doesn’t support actively sending an
"Echo" JSON request to a peer. Other unsupported RPC methods are listed
below:</simpara>
<itemizedlist>
<listitem>
<simpara>Cancel</simpara>
</listitem>
<listitem>
<simpara>Lock operations</simpara>
</listitem>
<listitem>
<simpara>Locked notification</simpara>
</listitem>
<listitem>
<simpara>Stolen notification</simpara>
</listitem>
</itemizedlist>

<simpara>In the OVSDB library the RPC methods are defined in the Java interface OvsdbRPC.
The library also provides a high-level interface OvsdbClient as the main
interface to interact with peers through the OVSDB protocol. In the passive
connection scenario, each connection will have a corresponding
OvsdbClient object, and the application can obtain the OvsdbClient
object through connection listener callback methods. In other words, if
the application implements the OvsdbConnectionListener interface, it will
get notifications of connection status changes with the corresponding
OvsdbClient object of that connection.</simpara>
</section>
<section xml:id="ovsdb-database-operations">
<title>OVSDB database operations</title>
<simpara>RFC 7047 also defines database operations, such as insert, delete, and
update, to be performed as part of a "transact" RPC request. The OVSDB
library defines the data operations in Operations.java and provides
the TransactionBuilder class to help build "transact" RPC requests. To build
a JSON-RPC transact request message, the application can obtain
the TransactionBuilder object through a transactBuilder() method in
the OvsdbClient interface.</simpara>
<simpara>The TransactionBuilder class provides the following methods to help build
transactions:</simpara>
<itemizedlist>
<listitem>
<simpara>getOperations(): Get the list of operations in this transaction.</simpara>
</listitem>
<listitem>
<simpara>add(): Add data operation to this transaction.</simpara>
</listitem>
<listitem>
<simpara>build(): Return the list of operations in this transaction. This is the
same as the getOperations() method.</simpara>
</listitem>
<listitem>
<simpara>execute(): Send the JSON RPC transaction to peer.</simpara>
</listitem>
<listitem>
<simpara>getDatabaseSchema(): Get the database schema of this transaction.</simpara>
</listitem>
</itemizedlist>

<simpara>If the application wants to build and send a "transact" RPC request to
modify OVSDB tables on a peer, it can take the following steps:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Statically import parameter "op" in Operations.java</simpara>
<simpara><literal>import static org.opendaylight.ovsdb.lib.operations.Operations.op;</literal></simpara>
</listitem>
<listitem>
<simpara>Obtain transaction builder through transacBuilder() method in
OvsdbClient:</simpara>
<simpara><literal>TransactionBuilder transactionBuilder = ovsdbClient.transactionBuilder(dbSchema);</literal></simpara>
</listitem>
<listitem>
<simpara>Add operations to transaction builder:</simpara>
<simpara><literal>transactionBuilder.add(op.insert(schema, row));</literal></simpara>
</listitem>
<listitem>
<simpara>Send transaction to peer and get JSON RPC response:</simpara>
<simpara><literal>operationResults = transactionBuilder.execute().get();</literal></simpara>
<note>
<simpara>Although the "select" operation is supported in the OVSDB library, the
library implementation is a little different from RFC 7047. In RFC 7047,
section 5.2.2 describes the "select" operation as follows:</simpara>
</note>

<simpara>“The "rows" member of the result is an array of objects. Each object
corresponds to a matching row, with each column specified in "columns"
as a member, the column&#8217;s name as the member name, and its value as the
member value. If "columns" is not specified, all the table&#8217;s columns are
included (including the internally generated "_uuid" and "_version"
columns).”</simpara>
<simpara>The OVSDB library implementation always requires the column’s name in the
"columns" field of a JSON message. If the "columns" field is not
specified, none of the table’s columns are included. If the application
wants to get the table entry with all columns, it needs to specify all
the columns’ names in the "columns" field.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="reference-documentation">
<title>Reference Documentation</title>
<simpara>RFC 7047 The Open vSwitch Databse Management Protocol
<link xlink:href="https://tools.ietf.org/html/rfc7047">https://tools.ietf.org/html/rfc7047</link></simpara>
</section>
</section>
<section xml:id="_ovsdb_md_sal_southbound_plugin_developer_guide">
<title>OVSDB MD-SAL Southbound Plugin Developer Guide</title>
<section xml:id="_overview_20">
<title>Overview</title>
<simpara>The Open vSwitch Database (OVSDB) Model Driven Service Abstraction Layer
(MD-SAL) Southbound Plugin provides an MD-SAL based interface to
Open vSwitch systems.  This is done by augmenting the MD-SAL topology node with
a YANG model which replicates some (but not all) of the Open vSwitch schema.</simpara>
</section>
<section xml:id="_ovsdb_md_sal_southbound_plugin_architecture_and_operation">
<title>OVSDB MD-SAL Southbound Plugin Architecture and Operation</title>
<simpara>The architecture and operation of the OVSDB MD-SAL Southbound plugin is
illustrated in the following set of diagrams.</simpara>
<section xml:id="_connecting_to_an_ovsdb_node">
<title>Connecting to an OVSDB Node</title>
<simpara>An OVSDB node is a system which is running the OVS software and is capable of
being managed by an OVSDB manager.  The OVSDB MD-SAL Southbound plugin in
OpenDaylight is capable of operating as an OVSDB manager.  Depending on the
configuration of the OVSDB node, the connection of the OVSDB manager can
be active or passive.</simpara>
<section xml:id="_active_ovsdb_node_manager_workflow">
<title>Active OVSDB Node Manager Workflow</title>
<simpara>An active OVSDB node manager connection is made when OpenDaylight initiates the
connection to the OVSDB node.  In order for this to work, you must configure the
OVSDB node to listen on a TCP port for the connection (i.e.
OpenDaylight is active and the OVSDB node is passive).  This option can be
configured on the OVSDB node using the following command:</simpara>

<literallayout class="monospaced">ovs-vsctl set-manager ptcp:6640</literallayout>


<simpara>The following diagram illustrates the sequence of events which occur when
OpenDaylight initiates an active OVSDB manager connection to an OVSDB node.</simpara>
<figure>
<title>Active OVSDB Manager Connection</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ovsdb-sb-active-connection.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ovsdb sb active connection</phrase></textobject>
  </mediaobject>
</figure>

<variablelist>
<varlistentry>
<term>Step 1</term>
<listitem>
<simpara>Create an OVSDB node by using RESTCONF or an OpenDaylight plugin. The OVSDB node
is listed under the OVSDB topology node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 2</term>
<listitem>
<simpara>Add the OVSDB node to the OVSDB MD-SAL southbound configuration datastore. The
OVSDB southbound provider is registered to listen for data change events on the
portion of the MD-SAL topology data store which contains the OVSDB southbound
topology node augmentations. The addition of an OVSDB node causes an event which
is received by the OVSDB Southbound provider.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 3</term>
<listitem>
<simpara>The OVSDB Southbound provider initiates a connection to the OVSDB node using
the connection information provided in the configuration OVSDB node (i.e. IP
address and TCP port number).</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 4</term>
<listitem>
<simpara>The OVSDB Southbound provider adds the OVSDB node to the OVSDB MD-SAL
operational data store.  The operational data store contains OVSDB node
objects which represent active connections to OVSDB nodes.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 5</term>
<listitem>
<simpara>The OVSDB Southbound provider requests the schema and databases which are
supported by the OVSDB node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 6</term>
<listitem>
<simpara>The OVSDB Southbound provider uses the database and schema information to
construct a monitor request which causes the OVSDB node to send the controller
any updates made to the OVSDB databases on the OVSDB node.</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_passive_ovsdb_node_manager_workflow">
<title>Passive OVSDB Node Manager Workflow</title>
<simpara>A passive OVSDB node connection to OpenDaylight is made when the OVSDB node
initiates the connection to OpenDaylight.  In order for this to work, you must
configure the OVSDB node to connect to the IP address and OVSDB port on which
OpenDaylight is listening.  This option can be configured on the OVSDB node
using the following command:</simpara>

<literallayout class="monospaced">ovs-vsctl set-manager tcp:&lt;IP address&gt;:6640</literallayout>


<simpara>The following diagram illustrates the sequence of events which occur when an
OVSDB node connects to OpenDaylight.</simpara>
<figure>
<title>Passive OVSDB Manager Connection</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ovsdb-sb-passive-connection.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ovsdb sb passive connection</phrase></textobject>
  </mediaobject>
</figure>

<variablelist>
<varlistentry>
<term>Step 1</term>
<listitem>
<simpara>The OVSDB node initiates a connection to OpenDaylight.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 2</term>
<listitem>
<simpara>The OVSDB Southbound provider adds the OVSDB node to the OVSDB MD-SAL
operational data store.  The operational data store contains OVSDB node
objects which represent active connections to OVSDB nodes.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 3</term>
<listitem>
<simpara>The OVSDB Southbound provider requests the schema and databases which are
supported by the OVSDB node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 4</term>
<listitem>
<simpara>The OVSDB Southbound provider uses the database and schema information to
construct a monitor request which causes the OVSDB node to send back
any updates which have been made to the OVSDB databases on the OVSDB node.</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
</section>
<section xml:id="_ovsdb_node_id_in_the_southbound_operational_md_sal">
<title>OVSDB Node ID in the Southbound Operational MD-SAL</title>
<simpara>When OpenDaylight initiates an active connection to an OVSDB node, it
writes an external-id to the Open_vSwitch table on the OVSDB node.  The
external-id is an OpenDaylight instance identifier which identifies the
OVSDB topology node which has just been created.
Here is an example showing the value of the <emphasis>opendaylight-iid</emphasis> entry
in the external-ids column of the Open_vSwitch table where the
node-id of the OVSDB node is <emphasis>ovsdb:HOST1</emphasis>.</simpara>

<literallayout class="monospaced">$ ovs-vsctl list open_vswitch
...
external_ids        : {opendaylight-iid="/network-topology:network-topology/network-topology:topology[network-topology:topology-id='ovsdb:1']/network-topology:node[network-topology:node-id='ovsdb:HOST1']"}
...</literallayout>


<simpara>The <emphasis>opendaylight-iid</emphasis> entry in the external-ids column of the Open_vSwitch
table causes the OVSDB node to have same node-id in the operational
MD-SAL datastore as in the configuration MD-SAL datastore.  This holds true
if the OVSDB node manager settings are subsequently changed so that a
passive OVSDB manager connection is made.</simpara>
<simpara>If there is no <emphasis>opendaylight-iid</emphasis> entry in the external-ids column and
a passive OVSDB manager connection is made, then the node-id of the OVSDB
node in the operational MD-SAL datastore will be constructed using the UUID
of the Open_vSwitch table as follows.</simpara>

<literallayout class="monospaced">"node-id": "ovsdb://uuid/b8dc0bfb-d22b-4938-a2e8-b0084d7bd8c1"</literallayout>


<simpara>The <emphasis>opendaylight-iid</emphasis> entry can be removed from the Open_vSwitch table using
the following command.</simpara>

<literallayout class="monospaced">$ sudo ovs-vsctl remove open_vswitch . external-id "opendaylight-iid"</literallayout>


</section>
<section xml:id="_ovsdb_changes_by_using_ovsdb_southbound_config_md_sal">
<title>OVSDB Changes by using OVSDB Southbound Config MD-SAL</title>
<simpara>After the connection has been made to an OVSDB node, you can make changes to the
OVSDB node by using the OVSDB Southbound Config MD-SAL.  You can
make CRUD operations by using the RESTCONF interface or by a plugin
using the MD-SAL APIs.  The following diagram illustrates the high-level flow of
events.</simpara>
<figure>
<title>OVSDB Changes by using the Southbound Config MD-SAL</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ovsdb-sb-config-crud.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ovsdb sb config crud</phrase></textobject>
  </mediaobject>
</figure>

<variablelist>
<varlistentry>
<term>Step 1</term>
<listitem>
<simpara>A change to the OVSDB Southbound Config MD-SAL is made.  Changes include adding
or deleting bridges and ports, or setting attributes of OVSDB nodes, bridges or
ports.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 2</term>
<listitem>
<simpara>The OVSDB Southbound provider receives notification of the changes made to the
OVSDB Southbound Config MD-SAL data store.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 3</term>
<listitem>
<simpara>As appropriate, OVSDB transactions are constructed and transmitted to the OVSDB
node to update the OVSDB database on the OVSDB node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 4</term>
<listitem>
<simpara>The OVSDB node sends update messages to the OVSDB Southbound provider to
indicate the changes made to the OVSDB nodes database.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 5</term>
<listitem>
<simpara>The OVSDB Southbound provider maps the changes received from the OVSDB node
into corresponding changes made to the OVSDB Southbound Operational
MD-SAL data store.</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_detecting_changes_in_ovsdb_coming_from_outside_opendaylight">
<title>Detecting changes in OVSDB coming from outside OpenDaylight</title>
<simpara>Changes to the OVSDB nodes database may also occur independently of OpenDaylight.
OpenDaylight also receives notifications for these events and updates the
Southbound operational MD-SAL.  The following diagram illustrates the sequence
of events.</simpara>
<figure>
<title>OVSDB Changes made directly on the OVSDB node</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ovsdb-sb-oper-crud.jpg" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ovsdb sb oper crud</phrase></textobject>
  </mediaobject>
</figure>

<variablelist>
<varlistentry>
<term>Step 1</term>
<listitem>
<simpara>Changes are made to the OVSDB node outside of OpenDaylight (e.g. ovs-vsctl).</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 2</term>
<listitem>
<simpara>The OVSDB node constructs update messages to inform OpenDaylight of the changes
made to its databases.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Step 3</term>
<listitem>
<simpara>The OVSDB Southbound provider maps the OVSDB database changes to corresponding
changes in the OVSDB Southbound operational MD-SAL data store.</simpara>
</listitem>
</varlistentry>
</variablelist>

</section>
<section xml:id="_ovsdb_model">
<title>OVSDB Model</title>
<simpara>The OVSDB Southbound MD-SAL operates using a YANG model which is based on the
abstract topology node model found in the
<link xlink:href="https://github.com/opendaylight/yangtools/blob/stable/lithium/model/ietf/ietf-topology/src/main/yang/network-topology%402013-10-21.yang">network topology model</link>.</simpara>
<simpara>The augmentations for the OVSDB Southbound MD-SAL are defined in the
<link xlink:href="https://github.com/opendaylight/ovsdb/blob/stable/lithium/southbound/southbound-api/src/main/yang/ovsdb.yang">ovsdb.yang</link> file.</simpara>
<simpara>There are three augmentations:</simpara>
<variablelist>
<varlistentry>
<term><emphasis role="strong">ovsdb-node-augmentation</emphasis></term>
<listitem>
<simpara>This augments the topology node and maps primarily to the Open_vSwitch table of
the OVSDB schema.  It contains the following attributes.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">connection-info</emphasis> - holds the local and remote IP address and TCP port numbers for the OpenDaylight to OVSDB node connections</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">db-version</emphasis> - version of the OVSDB database</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">ovs-version</emphasis> - version of OVS</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list managed-node-entry</emphasis> - a list of references to ovsdb-bridge-augmentation nodes, which are the OVS bridges managed by this OVSDB node</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list datapath-type-entry</emphasis> - a list of the datapath types supported by the OVSDB node (e.g. <emphasis>system</emphasis>, <emphasis>netdev</emphasis>) - depends on newer OVS versions</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list interface-type-entry</emphasis> - a list of the interface types supported by the OVSDB node (e.g. <emphasis>internal</emphasis>, <emphasis>vxlan</emphasis>, <emphasis>gre</emphasis>, <emphasis>dpdk</emphasis>, etc.) - depends on newer OVS verions</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list openvswitch-external-ids</emphasis> - a list of the key/value pairs in the Open_vSwitch table external_ids column</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list openvswitch-other-config</emphasis> - a list of the key/value pairs in the Open_vSwitch table other_config column</simpara>
</listitem>
</itemizedlist>

</listitem>
</varlistentry>
<varlistentry>
<term><emphasis role="strong">ovsdb-bridge-augmentation</emphasis></term>
<listitem>
<simpara>This augments the topology node and maps to an specific bridge in the OVSDB
bridge table of the associated OVSDB node. It contains the following attributes.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">bridge-uuid</emphasis> - UUID of the OVSDB bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">bridge-name</emphasis> - name of the OVSDB bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">bridge-openflow-node-ref</emphasis> - a reference (instance-identifier) of the OpenFlow node associated with this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list protocol-entry</emphasis> - the version of OpenFlow protocol to use with the OpenFlow controller</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list controller-entry</emphasis> - a list of controller-uuid and is-connected status of the OpenFlow controllers associated with this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">datapath-id</emphasis> - the datapath ID associated with this bridge on the OVSDB node</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">datapath-type</emphasis> - the datapath type of this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">fail-mode</emphasis> - the OVSDB fail mode setting of this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">flow-node</emphasis> - a reference to the flow node corresponding to this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">managed-by</emphasis> - a reference to the ovsdb-node-augmentation (OVSDB node) that is managing this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list bridge-external-ids</emphasis> - a list of the key/value pairs in the bridge table external_ids column for this bridge</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list bridge-other-configs</emphasis> - a list of the key/value pairs in the bridge table other_config column for this bridge</simpara>
</listitem>
</itemizedlist>

</listitem>
</varlistentry>
<varlistentry>
<term><emphasis role="strong">ovsdb-termination-point-augmentation</emphasis></term>
<listitem>
<simpara>This augments the topology termination point model.  The OVSDB Southbound
MD-SAL uses this model to represent both the OVSDB port and OVSDB interface for
a given port/interface in the OVSDB schema.  It contains the following
attributes.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">port-uuid</emphasis> - UUID of an OVSDB port row</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">interface-uuid</emphasis> - UUID of an OVSDB interface row</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">name</emphasis> - name of the port</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">interface-type</emphasis> - the interface type</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list options</emphasis> - a list of port options</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">ofport</emphasis> - the OpenFlow port number of the interface</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">ofport_request</emphasis> - the requested OpenFlow port number for the interface</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">vlan-tag</emphasis> - the VLAN tag value</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list trunks</emphasis> - list of VLAN tag values for trunk mode</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">vlan-mode</emphasis> - the VLAN mode (e.g. access, native-tagged, native-untagged, trunk)</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list port-external-ids</emphasis> - a list of the key/value pairs in the port table external_ids column for this port</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list interface-external-ids</emphasis> - a list of the key/value pairs in the interface table external_ids interface for this interface</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list port-other-configs</emphasis> - a list of the key/value pairs in the port table other_config column for this port</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">list interface-other-configs</emphasis> - a list of the key/value pairs in the interface table other_config column for this interface</simpara>
</listitem>
</itemizedlist>

</listitem>
</varlistentry>
</variablelist>

</section>
</section>
<section xml:id="_examples_of_ovsdb_southbound_md_sal_api">
<title>Examples of OVSDB Southbound MD-SAL API</title>
<section xml:id="_connect_to_an_ovsdb_node">
<title>Connect to an OVSDB Node</title>
<simpara>This example RESTCONF command adds an OVSDB node object to the OVSDB
Southbound configuration data store and attempts to connect to the OVSDB host
located at the IP address 10.11.12.1 on TCP port 6640.</simpara>

<literallayout class="monospaced">POST http://&lt;host&gt;:8181/restconf/config/network-topology:network-topology/topology/ovsdb:1/
Content-Type: application/json
{
  "node": [
     {
       "node-id": "ovsdb:HOST1",
       "connection-info": {
         "ovsdb:remote-ip": "10.11.12.1",
         "ovsdb:remote-port": 6640
       }
     }
  ]
}</literallayout>


</section>
<section xml:id="_query_the_ovsdb_southbound_configuration_md_sal">
<title>Query the OVSDB Southbound Configuration MD-SAL</title>
<simpara>Following on from the previous example, if the OVSDB Southbound configuration
MD-SAL is queried, the RESTCONF command and the resulting reply is similar
to the following example.</simpara>

<literallayout class="monospaced">GET http://&lt;host&gt;:8080/restconf/config/network-topology:network-topology/topology/ovsdb:1/
Application/json data in the reply
{
  "topology": [
    {
      "topology-id": "ovsdb:1",
      "node": [
        {
          "node-id": "ovsdb:HOST1",
          "ovsdb:connection-info": {
            "remote-port": 6640,
            "remote-ip": "10.11.12.1"
          }
        }
      ]
    }
  ]
}</literallayout>


</section>
</section>
<section xml:id="_reference_documentation">
<title>Reference Documentation</title>
<simpara><link xlink:href="http://openvswitch.org/ovs-vswitchd.conf.db.5.pdf">Openvswitch schema</link></simpara>
</section>
</section>
<section xml:id="_ovsdb_openstack_developer_guide">
<title>OVSDB Openstack Developer Guide</title>
<section xml:id="_overview_21">
<title>Overview</title>
<simpara>The Open vSwitch database (OVSDB) Southbound Plugin component for OpenDaylight implements
the OVSDB  <link xlink:href="https://tools.ietf.org/html/rfc7047">RFC 7047</link> management protocol
that allows the southbound configuration of switches that support OVSDB. The
component comprises a library and a plugin. The OVSDB protocol
uses JSON-RPC calls to manipulate a physical or virtual switch that supports OVSDB.
Many vendors support OVSDB on various hardware platforms.
The OpenDaylight controller uses the library project to interact with an OVS
instance.</simpara>
<simpara><link xlink:href="http://www.openstack.org">OpenStack</link> is a popular open source Infrastructure
as a Service (IaaS) project, covering compute, storage and network management.
OpenStack can use OpenDaylight as its network management provider through the
Neutron API, which acts as a northbound for OpenStack. the OVSDB NetVirt piece
of the OVSDB project is a provider for the Neutron API in OpenDaylight.
OpenDaylight manages the network flows for the OpenStack compute nodes via
the OVSDB project, with the south-bound plugin. This section describes how to
set that up, and how to tell when everything is working.</simpara>
</section>
<section xml:id="_ovsdb_openstack_architecture">
<title>OVSDB Openstack Architecture</title>
<simpara>The OpenStack integration architecture uses the following technologies:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://tools.ietf.org/html/rfc7047">RFC 7047</link> - The Open vSwitch Database Management Protocol</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="http://www.opennetworking.org/images/stories/downloads/sdn-resources/onf-specifications/openflow/openflow-switch-v1.3.4.pdf">OpenFlow v1.3</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.openstack.org/wiki/Neutron/ML2">OpenStack Neutron ML2 Plugin</link></simpara>
</listitem>
</itemizedlist>

<simpara><inlinemediaobject>
  <imageobject>
    <imagedata fileref="./images/openstack_integration.png"/>
  </imageobject>
  <textobject><phrase>Openstack Integration</phrase></textobject>
</inlinemediaobject></simpara>
</section>
</section>
<section xml:id="_ovsdb_service_function_chaining_developer_guide">
<title>OVSDB Service Function Chaining Developer Guide</title>
<section xml:id="_overview_22">
<title>Overview</title>
<simpara>The OVSDB NetVirtSfc provides a classification and traffic steering component when integrated with OpenStack. Please refer to the Service Function Chaining project for the theory and programming of service chains.</simpara>
</section>
<section xml:id="_installing_the_netvirt_sfc_feature">
<title>Installing the NetVirt SFC Feature</title>
<simpara>Install the odl-ovsdb-sfc feature. The feature will also ensure that the odl-ovsdb-openstack feature as well as the openflowplugin, neutron and sfc features are installed.</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara>feature:install odl-ovsdb-sfc-ui
---</simpara>
<simpara>Verify the required features are installed:</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara>opendaylight-user@root&gt;feature:list -i | grep ovsdb</simpara>
<variablelist>
<varlistentry>
<term>odl-ovsdb-southbound-api             | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight </term>
<listitem>
<simpara>southbound :: api</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-southbound-impl            | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound </term>
<listitem>
<simpara>impl</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-southbound-impl-rest       | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: impl </term>
<listitem>
<simpara>REST</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-southbound-impl-ui         | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-southbound-1.2.1-SNAPSHOT     | OpenDaylight :: southbound :: impl </term>
<listitem>
<simpara>UI</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-library                    | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-library-1.2.1-SNAPSHOT        | OpenDaylight </term>
<listitem>
<simpara>library</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-openstack                  | 1.2.1-SNAPSHOT   | x         | ovsdb-1.2.1-SNAPSHOT                    | OpenDaylight :: OVSDB </term>
<listitem>
<simpara>OpenStack Network Virtual</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-sfc-api                    | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc </term>
<listitem>
<simpara>api</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-sfc                        | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight </term>
<listitem>
<simpara>ovsdb-sfc</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-sfc-rest                   | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc </term>
<listitem>
<simpara>REST</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>odl-ovsdb-sfc-ui                     | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc </term>
<listitem>
<simpara>UI</simpara>
</listitem>
</varlistentry>
</variablelist>

<simpara>opendaylight-user@root&gt;feature:list -i | grep sfc
odl-sfc-model                        | 0.2.0-SNAPSHOT   | x         | odl-sfc-0.2.0-SNAPSHOT                  | OpenDaylight :: sfc :: Model
odl-sfc-provider                     | 0.2.0-SNAPSHOT   | x         | odl-sfc-0.2.0-SNAPSHOT                  | OpenDaylight :: sfc :: Provider
odl-sfc-provider-rest                | 0.2.0-SNAPSHOT   | x         | odl-sfc-0.2.0-SNAPSHOT                  | OpenDaylight :: sfc :: Provider
odl-sfc-ovs                          | 0.2.0-SNAPSHOT   | x         | odl-sfc-0.2.0-SNAPSHOT                  | OpenDaylight :: OpenvSwitch
odl-sfcofl2                          | 0.2.0-SNAPSHOT   | x         | odl-sfc-0.2.0-SNAPSHOT                  | OpenDaylight :: sfcofl2
odl-ovsdb-sfc-test                   | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-test1.2.1-SNAPSHOT        | OpenDaylight :: ovsdb-sfc-test
odl-ovsdb-sfc-api                    | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc :: api
odl-ovsdb-sfc                        | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc
odl-ovsdb-sfc-rest                   | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc :: REST
odl-ovsdb-sfc-ui                     | 1.2.1-SNAPSHOT   | x         | odl-ovsdb-sfc-1.2.1-SNAPSHOT            | OpenDaylight :: ovsdb-sfc :: UI</simpara>
<simpara>opendaylight-user@root&gt;feature:list -i | grep neutron
odl-neutron-service                  | 0.6.0-SNAPSHOT   | x         | odl-neutron-0.6.0-SNAPSHOT              | OpenDaylight :: Neutron :: API
odl-neutron-northbound-api           | 0.6.0-SNAPSHOT   | x         | odl-neutron-0.6.0-SNAPSHOT              | OpenDaylight :: Neutron :: Northbound
odl-neutron-spi                      | 0.6.0-SNAPSHOT   | x         | odl-neutron-0.6.0-SNAPSHOT              | OpenDaylight :: Neutron :: API
odl-neutron-transcriber              | 0.6.0-SNAPSHOT   | x         | odl-neutron-0.6.0-SNAPSHOT              | OpenDaylight :: Neutron :: Implementation
---</simpara>
</section>
<section xml:id="_ovsdb_netvirt_service_function_chaining_example">
<title>OVSDB NetVirt Service Function Chaining Example</title>
<simpara>The architecture within OpenDaylight can be seen in the following figure:</simpara>
<figure>
<title>OpenDaylight OVSDB NetVirt SFC Architecture</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ovsdb/ODL_SFC_Architecture.png"/>
    </imageobject>
    <textobject><phrase>ODL SFC Architecture</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Tacker is a Virtual Network Functions Manager that is responsible for orchestrating the Service Function Chaining. Tacker is responsible for generating templates for Virtual Network Functions for OpenStack to instantiate the Service Functions. Tacker also uses the RESTCONF interfaces of OpenDaylight to create the Service Function Chains.</simpara>
</section>
<section xml:id="_classification">
<title>Classification</title>
<simpara>OVSDB NetVirt SFC implements the classification for the chains. The classification steers traffic from the tenant overlay to the chain overlay and back to the tenant overlay.</simpara>
<simpara>An Access Control List used by NetVirtSFC to create the classifier is shown below. This is an example of classifying HTTP traffic using the tcp port 80. In this example the user would have created a Service Function Chain with the name "http-sfc" as well as all the associated Service Functions and Service Function Forwarders for the chain.</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara><link xlink:href="http://localhost:8181/restconf/config/ietf-access-control-list:access-lists">http://localhost:8181/restconf/config/ietf-access-control-list:access-lists</link></simpara>
<simpara>{
    "access-lists": {
        "acl": [
            {
                "acl-name": "http-acl",
                "access-list-entries": {
                    "ace": [
                        {
                            "rule-name": "http-rule",
                            "matches": {
                                "source-port-range": {
                                    "lower-port": 0,
                                    "upper-port": 0
                                },
                                "protocol": 6,
                                "destination-port-range": {
                                    "lower-port": 80,
                                    "upper-port": 80
                                }
                            },
                            "actions": {
                                "netvirt-sfc-acl:sfc-name": "http-sfc"
                            }
                        }
                    ]
                }
            }
        ]
    }
}
---</simpara>
<simpara>When the chain is rendered using the Rendered Service Path RPC, NetvirtSfc will add the classification flows. The classification flows are shown below. The list shown has been modified to remove the NetVirt tenant overlay flows. The classification flow is identified with the cookie: 0x1110010000040255. The 6th digit of the cookie identifies the flow type as the classifier. The last 8 digits identify the chain with the first four digits indicating the NSH NSP and the last four digits identifying the NSH NSI. In this case the chain is identified with an NSP of 4 and the NSI is 255 to indicate the beginning of the chain.</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara>sudo ovs-ofctl --protocol=OpenFlow13 dump-flows br-int
OFPST_FLOW reply (OF1.3) (xid=0x2):
 cookie=0x0, duration=17.157s, table=0, n_packets=0, n_bytes=0, priority=6 actions=goto_table:1
 cookie=0x14, duration=10.692s, table=0, n_packets=0, n_bytes=0, priority=400,udp,in_port=4,tp_dst=6633 actions=LOCAL
 cookie=0x0, duration=17.134s, table=0, n_packets=0, n_bytes=0, dl_type=0x88cc actions=CONTROLLER:65535
 cookie=0x14, duration=10.717s, table=0, n_packets=0, n_bytes=0, priority=350,nsp=4 actions=goto_table:152
 cookie=0x14, duration=10.688s, table=0, n_packets=0, n_bytes=0, priority=400,udp,nw_dst=10.2.1.1,tp_dst=6633 actions=output:4
 cookie=0x0, duration=17.157s, table=1, n_packets=0, n_bytes=0, priority=0 actions=goto_table:11
 cookie=0x1110070000040254, duration=10.608s, table=1, n_packets=0, n_bytes=0, priority=40000,reg0=0x1,nsp=4,nsi=254,in_port=1 actions=goto_table:21
 cookie=0x0, duration=17.157s, table=11, n_packets=0, n_bytes=0, priority=0 actions=goto_table:21
 cookie=0x1110060000040254, duration=10.625s, table=11, n_packets=0, n_bytes=0, nsp=4,nsi=254,in_port=4 actions=load:0x1&#8594;NXM_NX_REG0[],move:NXM_NX_NSH_C2[]&#8594;NXM_NX_TUN_ID[0..31],resubmit(1,1)
 cookie=0x1110010000040255, duration=10.615s, table=11, n_packets=0, n_bytes=0, tcp,reg0=0x1,tp_dst=80 actions=move:NXM_NX_TUN_ID[0..31]&#8594;NXM_NX_NSH_C2[],set_nshc1:0xc0a83246,set_nsp:0x4,set_nsi:255,load:0xa020101&#8594;NXM_NX_TUN_IPV4_DST[],load:0x4&#8594;NXM_NX_TUN_ID[0..31],resubmit(,0)
 cookie=0x0, duration=17.157s, table=21, n_packets=0, n_bytes=0, priority=0 actions=goto_table:31
 cookie=0x1110040000000000, duration=10.765s, table=21, n_packets=0, n_bytes=0, priority=1024,arp,in_port=LOCAL,arp_tpa=10.2.1.1,arp_op=1 actions=move:NXM_OF_ETH_SRC[]&#8594;NXM_OF_ETH_DST[],set_field:f6:00:00:0f:00:01&#8594;eth_src,load:0x2&#8594;NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]&#8594;NXM_NX_ARP_THA[],move:NXM_OF_ARP_SPA[]&#8594;NXM_OF_ARP_TPA[],load:0xf600000f0001&#8594;NXM_NX_ARP_SHA[],load:0xa020101&#8594;NXM_OF_ARP_SPA[],IN_PORT
 cookie=0x0, duration=17.157s, table=31, n_packets=0, n_bytes=0, priority=0 actions=goto_table:41
 cookie=0x0, duration=17.157s, table=41, n_packets=0, n_bytes=0, priority=0 actions=goto_table:51
 cookie=0x0, duration=17.157s, table=51, n_packets=0, n_bytes=0, priority=0 actions=goto_table:61
 cookie=0x0, duration=17.142s, table=61, n_packets=0, n_bytes=0, priority=0 actions=goto_table:71
 cookie=0x0, duration=17.140s, table=71, n_packets=0, n_bytes=0, priority=0 actions=goto_table:81
 cookie=0x0, duration=17.116s, table=81, n_packets=0, n_bytes=0, priority=0 actions=goto_table:91
 cookie=0x0, duration=17.116s, table=91, n_packets=0, n_bytes=0, priority=0 actions=goto_table:101
 cookie=0x0, duration=17.107s, table=101, n_packets=0, n_bytes=0, priority=0 actions=goto_table:111
 cookie=0x0, duration=17.083s, table=111, n_packets=0, n_bytes=0, priority=0 actions=drop
 cookie=0x14, duration=11.042s, table=150, n_packets=0, n_bytes=0, priority=5 actions=goto_table:151
 cookie=0x14, duration=11.027s, table=151, n_packets=0, n_bytes=0, priority=5 actions=goto_table:152
 cookie=0x14, duration=11.010s, table=152, n_packets=0, n_bytes=0, priority=5 actions=goto_table:158
 cookie=0x14, duration=10.668s, table=152, n_packets=0, n_bytes=0, priority=650,nsp=4,nsi=255 actions=load:0xa020101&#8594;NXM_NX_TUN_IPV4_DST[],goto_table:158
 cookie=0x14, duration=10.995s, table=158, n_packets=0, n_bytes=0, priority=5 actions=drop
 cookie=0xba5eba11ba5eba11, duration=10.645s, table=158, n_packets=0, n_bytes=0, priority=751,nsp=4,nsi=255,in_port=4 actions=move:NXM_NX_NSH_C1[]&#8594;NXM_NX_NSH_C1[],move:NXM_NX_NSH_C2[]&#8594;NXM_NX_NSH_C2[],move:NXM_NX_TUN_ID[0..31]&#8594;NXM_NX_TUN_ID[0..31],IN_PORT
 cookie=0xba5eba11ba5eba11, duration=10.590s, table=158, n_packets=0, n_bytes=0, priority=751,nsp=4,nsi=254,in_port=4 actions=move:NXM_NX_NSI[]&#8594;NXM_NX_NSI[],move:NXM_NX_NSP[]&#8594;NXM_NX_NSP[],move:NXM_NX_NSH_C1[]&#8594;NXM_NX_TUN_IPV4_DST[],move:NXM_NX_NSH_C2[]&#8594;NXM_NX_TUN_ID[0..31],IN_PORT
 cookie=0xba5eba11ba5eba11, duration=10.640s, table=158, n_packets=0, n_bytes=0, priority=750,nsp=4,nsi=255 actions=move:NXM_NX_NSH_C1[]&#8594;NXM_NX_NSH_C1[],move:NXM_NX_NSH_C2[]&#8594;NXM_NX_NSH_C2[],move:NXM_NX_TUN_ID[0..31]&#8594;NXM_NX_TUN_ID[0..31],output:4
 cookie=0xba5eba11ba5eba11, duration=10.571s, table=158, n_packets=0, n_bytes=0, priority=761,nsp=4,nsi=254,nshc1=3232248390,in_port=4 actions=move:NXM_NX_NSI[]&#8594;NXM_NX_NSI[],move:NXM_NX_NSP[]&#8594;NXM_NX_NSP[],move:NXM_NX_NSH_C1[]&#8594;NXM_NX_TUN_IPV4_DST[],move:NXM_NX_NSH_C2[]&#8594;NXM_NX_TUN_ID[0..31],set_nshc1:0,resubmit(,11)
---</simpara>
</section>
<section xml:id="_configuration_6">
<title>Configuration</title>
<simpara>Some configuration is required due to application coexistence for the OpenFlow programming. The SFC project programs flows for the SFC overlay and NetVirt programs flows for the tenant overlay. Coexistence is achieved by each application owning a unique set of tables and providing a simple handoff between the tables.</simpara>
<simpara>First configure NetVirt to use table 1 as it&#8217;s starting table:</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara><link xlink:href="http://localhost:8181/restconf/config/netvirt-providers-config:netvirt-providers-config">http://localhost:8181/restconf/config/netvirt-providers-config:netvirt-providers-config</link></simpara>
<simpara>{
    "netvirt-providers-config": {
        "table-offset": 1
    }
}
---</simpara>
<simpara>Next configure SFC to start at table 150 and configure the table handoff. The configuration starts SFC at table 150 and sets the handoff to table 11 which is the NetVirt SFC classification table.</simpara>
<simpara><?asciidoc-hr?></simpara>

<simpara><link xlink:href="http://localhost:8181/restconf/config/sfc-of-renderer:sfc-of-renderer-config">http://localhost:8181/restconf/config/sfc-of-renderer:sfc-of-renderer-config</link></simpara>
<simpara>{
    "sfc-of-renderer-config": {
        "sfc-of-app-egress-table-offset": 11,
        "sfc-of-table-offset": 150
    }
}
---</simpara>
</section>
</section>
<section xml:id="_ovsdb_hardware_vtep_developer_guide">
<title>OVSDB Hardware VTEP Developer Guide</title>
<section xml:id="_overview_23">
<title>Overview</title>
<simpara>TBD</simpara>
</section>
<section xml:id="_ovsdb_hardware_vtep_architecture">
<title>OVSDB Hardware VTEP Architecture</title>
<simpara>TBD</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_pcep_developer_guide">
<title>PCEP Developer Guide</title>
<section xml:id="_overview_24">
<title>Overview</title>
<simpara>This section provides an overview of <emphasis role="strong">feature odl-bgpcep-pcep-all</emphasis> . This
feature will install everything needed for PCEP (Path Computation Element
Protocol) including establishing the connection, storing information about LSPs
(Label Switched Paths) and displaying data in network-topology overview.</simpara>
</section>
<section xml:id="_pcep_architecture">
<title>PCEP Architecture</title>
<simpara>Each feature represents a module in the BGPCEP codebase. The following diagram
illustrates how the features are related.</simpara>
<figure>
<title>PCEP Dependency Tree</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/pcep-dependency-tree.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>pcep dependency tree</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_key_apis_and_interfaces_10">
<title>Key APIs and Interfaces</title>
<section xml:id="_pcep">
<title>PCEP</title>
<section xml:id="_session_handling_3">
<title>Session handling</title>
<simpara><emphasis>32-pcep.xml</emphasis> defines only pcep-dispatcher the parser should be
using (global-pcep-extensions), factory for creating session proposals
(you can create different proposals for different PCCs (Path Computation Clients)).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
  &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:controller:pcep:impl"&gt;prefix:pcep-dispatcher-impl&lt;/type&gt;
  &lt;name&gt;global-pcep-dispatcher&lt;/name&gt;
  &lt;pcep-extensions&gt;
   &lt;type xmlns:pcepspi="urn:opendaylight:params:xml:ns:yang:controller:pcep:spi"&gt;pcepspi:extensions&lt;/type&gt;
   &lt;name&gt;global-pcep-extensions&lt;/name&gt;
  &lt;/pcep-extensions&gt;
  &lt;pcep-session-proposal-factory&gt;
    &lt;type xmlns:pcep="urn:opendaylight:params:xml:ns:yang:controller:pcep"&gt;pcep:pcep-session-proposal-factory&lt;/type&gt;
    &lt;name&gt;stateful07-proposal&lt;/name&gt;
  &lt;/pcep-session-proposal-factory&gt;
  &lt;boss-group&gt;
   &lt;type xmlns:netty="urn:opendaylight:params:xml:ns:yang:controller:netty"&gt;netty:netty-threadgroup&lt;/type&gt;
   &lt;name&gt;global-boss-group&lt;/name&gt;
  &lt;/boss-group&gt;
  &lt;worker-group&gt;
   &lt;type xmlns:netty="urn:opendaylight:params:xml:ns:yang:controller:netty"&gt;netty:netty-threadgroup&lt;/type&gt;
   &lt;name&gt;global-worker-group&lt;/name&gt;
  &lt;/worker-group&gt;
 &lt;/module&gt;</programlisting>

<simpara>For user configuration of PCEP, check User Guide.</simpara>
</section>
<section xml:id="_parser_2">
<title>Parser</title>
<simpara>The base PCEP parser includes messages and attributes from
<link xlink:href="http://tools.ietf.org/html/rfc5441">RFC5441</link>,
<link xlink:href="http://tools.ietf.org/html/rfc5541">RFC5541</link>,
<link xlink:href="http://tools.ietf.org/html/rfc5455">RFC5455</link>,
<link xlink:href="http://tools.ietf.org/html/rfc5557">RFC5557</link> and
<link xlink:href="http://tools.ietf.org/html/rfc5521">RFC5521</link>.</simpara>
</section>
<section xml:id="_registration_3">
<title>Registration</title>
<simpara>All parsers and serializers need to be registered
into <emphasis>Extension provider</emphasis>. This <emphasis>Extension provider</emphasis> is configured in
initial configuration of the parser-spi module (<emphasis>32-pcep.xml</emphasis>).</simpara>
<programlisting language="xml" linenumbering="unnumbered"> &lt;module&gt;
  &lt;type xmlns:prefix="urn:opendaylight:params:xml:ns:yang:controller:pcep:spi"&gt;prefix:pcep-extensions-impl&lt;/type&gt;
  &lt;name&gt;global-pcep-extensions&lt;/name&gt;
  &lt;extension&gt;
   &lt;type xmlns:pcepspi="urn:opendaylight:params:xml:ns:yang:controller:pcep:spi"&gt;pcepspi:extension&lt;/type&gt;
   &lt;name&gt;pcep-parser-base&lt;/name&gt;
  &lt;/extension&gt;
  &lt;extension&gt;
   &lt;type xmlns:pcepspi="urn:opendaylight:params:xml:ns:yang:controller:pcep:spi"&gt;pcepspi:extension&lt;/type&gt;
   &lt;name&gt;pcep-parser-ietf-stateful07&lt;/name&gt;
  &lt;/extension&gt;
  &lt;extension&gt;
   &lt;type xmlns:pcepspi="urn:opendaylight:params:xml:ns:yang:controller:pcep:spi"&gt;pcepspi:extension&lt;/type&gt;
   &lt;name&gt;pcep-parser-ietf-initiated00&lt;/name&gt;
  &lt;/extension&gt;
 &lt;/module&gt;</programlisting>

<itemizedlist>
<listitem>
<simpara><emphasis>pcep-parser-base</emphasis> - will register parsers and serializers
implemented in pcep-impl module</simpara>
</listitem>
<listitem>
<simpara><emphasis>pcep-parser-ietf-stateful07</emphasis> - will register parsers and
serializers implemented in stateful07 module</simpara>
</listitem>
</itemizedlist>

<simpara>Stateful07 module is a good example of a PCEP parser extension.</simpara>
<simpara>Configuration of PCEP parsers specifies one implementation of <emphasis>Extension
provider</emphasis> that will take care of registering mentioned parser
extensions:
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/spi/src/main/java/org/opendaylight/protocol/pcep/spi/pojo/SimplePCEPExtensionProviderContext.java;hb=refs/for/stable/lithium">SimplePCEPExtensionProviderContext</link>.
All registries are implemented in package
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=tree;f=pcep/spi/src/main/java/org/opendaylight/protocol/pcep/spi/pojo;hb=refs/for/stable/lithium">pcep-spi</link>.</simpara>
</section>
<section xml:id="_parsing_2">
<title>Parsing</title>
<simpara>Parsing of PCEP elements is mostly done equally to BGP,
the only exception is message parsing, that is described here.</simpara>
<simpara>In BGP messages, parsing of first-level elements (path-attributes)
can be validated in a simple way, as the attributes should be ordered
chronologically. PCEP, on the other hand, has a strict object order
policy, that is described in RBNF (Routing Backus-Naur Form) in each RFC.
Therefore the algorithm for parsing here is to parse all objects in order
as they appear in the message. The result of parsing is a list of <emphasis>PCEPObjects</emphasis>,
that is put through validation. <emphasis>validate()</emphasis> methods are present in each
message parser. Depending on the complexity of the message, it can
contain either a simple condition (checking the presence of a mandatory
object) or a full state machine.</simpara>
<simpara>In addition to that, PCEP requires sending error message for each
documented parsing error. This is handled by creating an empty list of
messages <emphasis>errors</emphasis> which is then passed as argument throughout whole
parsing process. If some parser encounters <emphasis>PCEPDocumentedException</emphasis>,
it has the duty to create appropriate PCEP error message and add it to
this list. In the end, when the parsing is finished, this list is
examined and all messages are sent to peer.</simpara>
<simpara>Better understanding provides this sequence diagram:</simpara>
<figure>
<title>Parsing</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/pcep-parsing.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>pcep parsing</phrase></textobject>
  </mediaobject>
</figure>

</section>
</section>
<section xml:id="_pcep_ietf_stateful">
<title>PCEP IETF stateful</title>
<simpara>This section summarizes module pcep-ietf-stateful07. The term
<emphasis>stateful</emphasis> refers to
<link xlink:href="http://tools.ietf.org/html/draft-ietf-pce-stateful-pce">draft-ietf-pce-stateful-pce</link>
and
<link xlink:href="http://tools.ietf.org/html/draft-ietf-pce-pce-initiated-lsp">draft-ietf-pce-pce-initiated-lsp</link>
in versions draft-ietf-pce-stateful-pce-07 with draft-ietf-pce-pce-initiated-lsp-00.</simpara>
<simpara>We will upgrade our implementation, when the stateful draft gets
promoted to RFC.</simpara>
<simpara>The stateful module is implemented as extensions to pcep-base-parser.
The stateful draft declared new elements as well as additional fields or
TLVs (type,length,value) to known objects. All new elements are defined in yang models, that
contain augmentations to elements defined in
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/api/src/main/yang/pcep-types.yang;hb=refs/for/stable/lithium">pcep-types.yang</link>.
In the case of extending known elements, the <emphasis>Parser</emphasis> class merely extends
the base class and overrides necessary methods as shown in following
diagram:</simpara>
<figure>
<title>Extending existing parsers</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/bgpcep/validation.png" contentwidth="550px" contentdepth="450px"/>
    </imageobject>
    <textobject><phrase>validation</phrase></textobject>
  </mediaobject>
</figure>

<simpara>All parsers (including those for newly defined PCEP elements) have to be
registered via the <emphasis>Activator</emphasis> class. This class is present in both modules.</simpara>
<simpara>In addition to parsers, the stateful module also introduces additional session
proposal. This proposal includes new fields defined in stateful drafts
for Open object.</simpara>
</section>
<section xml:id="_pcep_segment_routing_sr">
<title>PCEP segment routing (SR)</title>
<simpara>PCEP Segment Routing is an extension of base PCEP and
pcep-ietf-stateful-07 extension. The pcep-segment-routing module
implements
<link xlink:href="http://tools.ietf.org/html/draft-ietf-pce-segment-routing-01">draft-ietf-pce-segment-routing-01</link>.</simpara>
<simpara>The extension brings new SR-ERO (Explicit Route Object) and SR-RRO (Reported Route Object)
subobject composed of SID (Segment Identifier) and/or NAI (Node or Adjacency Identifier).
The segment Routing path is carried in the ERO and RRO object, as a list of
SR-ERO/SR-RRO subobjects in an order specified by the user. The draft defines new TLV -
SR-PCE-CAPABILITY TLV, carried in PCEP Open object, used to negotiate Segment
Routing ability.</simpara>
<simpara>The yang models of subobject, SR-PCE-CAPABILITY TLV and appropriate
augmentations are defined in
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/segment-routing/src/main/yang/odl-pcep-segment-routing.yang;hb=refs/for/stable/lithium">odl-pcep-segment-routing.yang</link>.<?asciidoc-br?>
The pcep-segment-routing module includes parsers/serializers for new
subobject
(<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/segment-routing/src/main/java/org/opendaylight/protocol/pcep/segment/routing/SrEroSubobjectParser.java;hb=refs/for/stable/lithium">SrEroSubobjectParser</link>)
and TLV
(<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/segment-routing/src/main/java/org/opendaylight/protocol/pcep/segment/routing/SrPceCapabilityTlvParser.java;hb=refs/for/stable/lithium">SrPceCapabilityTlvParser</link>).</simpara>
<simpara>The pcep-segment-routing module implements
<link xlink:href="http://tools.ietf.org/html/draft-ietf-pce-lsp-setup-type-01">draft-ietf-pce-lsp-setup-type-01</link>,
too. The draft defines new TLV - Path Setup Type TLV, which value
indicate path setup signaling technique. The TLV may be included in
RP(Request Parameters)/SRP(Stateful PCE Request Parameters) object.
For the default RSVP-TE (Resource Reservation Protocol), the TLV is omitted.
For Segment Routing, PST = 1 is defined.</simpara>
<simpara>The Path Setup Type TLV is modeled with yang in module
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/api/src/main/yang/pcep-types.yang;hb=refs/for/stable/lithium">pcep-types.yang</link>.
A parser/serializer is implemented in
<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=bgpcep.git;a=blob;f=pcep/impl/src/main/java/org/opendaylight/protocol/pcep/impl/tlv/PathSetupTypeTlvParser.java;hb=refs/for/stable/lithium">PathSetupTypeTlvParser</link>
and it is overriden in segment-routing module to provide the aditional
PST.</simpara>
</section>
<section xml:id="_pcep_topology">
<title>PCEP Topology</title>
<simpara>PCEP data is displayed only through one URL that is accessible from the base network-topology URL:</simpara>
<simpara><emphasis><link xlink:href="http://localhost:8181/restconf/operational/network-topology:network-topology/topology/pcep-topology">http://localhost:8181/restconf/operational/network-topology:network-topology/topology/pcep-topology</link></emphasis></simpara>
<simpara>Each PCC will be displayed as a node:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;node&gt;
 &lt;path-computation-client&gt;
  &lt;ip-address&gt;42.42.42.42&lt;/ip-address&gt;
  &lt;state-sync&gt;synchronized&lt;/state-sync&gt;
  &lt;stateful-tlv&gt;
   &lt;stateful&gt;
    &lt;initiation&gt;true&lt;/initiation&gt;
    &lt;lsp-update-capability&gt;true&lt;/lsp-update-capability&gt;
   &lt;/stateful&gt;
  &lt;/stateful-tlv&gt;
 &lt;/path-computation-client&gt;
 &lt;node-id&gt;pcc://42.42.42.42&lt;/node-id&gt;
&lt;/node&gt;
&lt;/source&gt;</programlisting>

<simpara>If some tunnels are configured on the network, they would be displayed on the same page, within a node that initiated the tunnel:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;node&gt;
 &lt;path-computation-client&gt;
  &lt;state-sync&gt;synchronized&lt;/state-sync&gt;
  &lt;stateful-tlv&gt;
   &lt;stateful&gt;
    &lt;initiation&gt;true&lt;/initiation&gt;
    &lt;lsp-update-capability&gt;true&lt;/lsp-update-capability&gt;
   &lt;/stateful&gt;
  &lt;/stateful-tlv&gt;
  &lt;reported-lsp&gt;
   &lt;name&gt;foo&lt;/name&gt;
   &lt;lsp&gt;
    &lt;operational&gt;down&lt;/operational&gt;
    &lt;sync&gt;false&lt;/sync&gt;
    &lt;ignore&gt;false&lt;/ignore&gt;
    &lt;plsp-id&gt;1&lt;/plsp-id&gt;
    &lt;create&gt;false&lt;/create&gt;
    &lt;administrative&gt;true&lt;/administrative&gt;
    &lt;remove&gt;false&lt;/remove&gt;
    &lt;delegate&gt;true&lt;/delegate&gt;
    &lt;processing-rule&gt;false&lt;/processing-rule&gt;
    &lt;tlvs&gt;
    &lt;lsp-identifiers&gt;
      &lt;ipv4&gt;
       &lt;ipv4-tunnel-sender-address&gt;43.43.43.43&lt;/ipv4-tunnel-sender-address&gt;
       &lt;ipv4-tunnel-endpoint-address&gt;0.0.0.0&lt;/ipv4-tunnel-endpoint-address&gt;
       &lt;ipv4-extended-tunnel-id&gt;0.0.0.0&lt;/ipv4-extended-tunnel-id&gt;
      &lt;/ipv4&gt;
      &lt;tunnel-id&gt;0&lt;/tunnel-id&gt;
      &lt;lsp-id&gt;0&lt;/lsp-id&gt;
     &lt;/lsp-identifiers&gt;
     &lt;symbolic-path-name&gt;
      &lt;path-name&gt;Zm9v&lt;/path-name&gt;
     &lt;/symbolic-path-name&gt;
    &lt;/tlvs&gt;
   &lt;/lsp&gt;
  &lt;/reported-lsp&gt;
  &lt;ip-address&gt;43.43.43.43&lt;/ip-address&gt;
 &lt;/path-computation-client&gt;
 &lt;node-id&gt;pcc://43.43.43.43&lt;/node-id&gt;
&lt;/node&gt;</programlisting>

<simpara>Note that, the <emphasis>&lt;path-name&gt;</emphasis> tag displays tunnel name in Base64 encoding.</simpara>
</section>
</section>
<section xml:id="_api_reference_documentation_11">
<title>API Reference Documentation</title>
<simpara>Javadocs are generated while creating mvn:site
and they are located in target/ directory in each module.</simpara>
</section>
</chapter>
<chapter xml:id="_packetcable_developer_guide">
<title>PacketCable Developer Guide</title>
<section xml:id="pcmm-specification">
<title>PCMM Specification</title>
<simpara><link xlink:href="http://www.cablelabs.com/specification/packetcable-multimedia-specification">PacketCable™
 Multimedia Specification</link></simpara>
</section>
<section xml:id="system-overview">
<title>System Overview</title>
<simpara>These components introduce a DOCSIS QoS Service Flow management using
the PCMM protocol. The driver component is responsible for the
PCMM/COPS/PDP functionality required to service requests from
PacketCable Provider and FlowManager. Requests are transposed into PCMM
Gate Control messages and transmitted via COPS to the CCAP/CMTS. This plugin
adheres to the PCMM/COPS/PDP functionality defined in the CableLabs
specification. PacketCable solution is an MDSAL compliant component.</simpara>
</section>
<section xml:id="packetcable-components">
<title>PacketCable Components</title>
<simpara>The packetcable maven project is comprised of several modules.</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Bundle</entry>
        
        <entry align="left" valign="top">Description</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>packetcable-driver</simpara></entry>
        
        <entry align="left" valign="top"><simpara>A common module that containts the COPS stack and
                            manages all connections to CCAPS/CMTSes.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>packetcable-emulator</simpara></entry>
        
        <entry align="left" valign="top"><simpara>A basic CCAP emulator to facilitate testing the
                            the plugin when no physical CCAP is avaible.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>packetcable-policy-karaf</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Generates a Karaf distribution with a config that
                            loads all the packetcable features at runtime.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>packetcable-policy-model</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Contains the YANG information model.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>packetcable-policy-server</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Provider hosts the model processing, RESTCONF,
                            and API implementation.</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<section xml:id="loging-levels">
<title>Setting Logging Levels</title>
<simpara>From the Karaf console</simpara>

<literallayout class="monospaced">log:set &lt;LEVEL&gt; (&lt;PACKAGE&gt;|&lt;BUNDLE&gt;)
Example
log:set DEBUG org.opendaylight.packetcable.packetcable-policy-server</literallayout>


</section>
</section>
<section xml:id="tools-for-testing">
<title>Tools for Testing</title>
<section xml:id="postman">
<title>Postman REST client for Chrome</title>
<simpara><link xlink:href="https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm?hl=en">Install
the Chrome extension</link></simpara>
<simpara><link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=packetcable.git;a=tree;f=packetcable-policy-server/doc/restconf-samples">Download
and import sample packetcable collection</link></simpara>
</section>
<section xml:id="view-rest-api">
<title>View Rest API</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Install the <literal>odl-mdsal-apidocs</literal> feature from the karaf console.</simpara>
</listitem>
<listitem>
<simpara>Open <link xlink:href="http://localhost:8181/apidoc/explorer/index.html">http://localhost:8181/apidoc/explorer/index.html</link> default dev build user/pass is admin/admin</simpara>
</listitem>
<listitem>
<simpara>Navigate to the PacketCable section.</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="yang-ide">
<title>Yang-IDE</title>
<simpara>Editing yang can be done in any text editor but Yang-IDE will help prevent mistakes.</simpara>
<simpara><link xlink:href="https://github.com/xored/yang-ide/wiki/Setup-and-build">Setup and Build
Yang-IDE for Eclipse</link></simpara>
</section>
</section>
<section xml:id="using-wireshark-to-trace-pcmm">
<title>Using Wireshark to Trace PCMM</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>To start wireshark with privileges issue the following command:</simpara>
<screen>sudo wireshark &amp;</screen>

</listitem>
<listitem>
<simpara>Select the interface to monitor.</simpara>
</listitem>
<listitem>
<simpara>Use the Filter to only display COPS messages by applying “cops” in
the filter field.</simpara>
</listitem>
</orderedlist>

<simpara><inlinemediaobject>
  <imageobject>
    <imagedata fileref="./images/Screenshot8.png" width="500"/>
  </imageobject>
  <textobject><phrase>Screenshot8</phrase></textobject>
</inlinemediaobject></simpara>
</section>
<section xml:id="debugging-and-verifying-dqos-gate-flows-on-the-cmts">
<title>Debugging and Verifying DQoS Gate (Flows) on the CCAP/CMTS</title>
<simpara>Below are some of the most useful CCAP/CMTS commands to verify flows have been
enabled on the CMTS.</simpara>
<section xml:id="cisco">
<title>Cisco</title>
<simpara><link xlink:href="http://www.cisco.com/c/en/us/td/docs/cable/cmts/cmd_ref/b_cmts_cable_cmd_ref.pdf">Cisco
CMTS Cable Command Reference</link></simpara>
</section>
<section xml:id="find-the-cable-modem">
<title>Find the Cable Modem</title>
<screen>10k2-DSG#show cable modem
                                                                                  D
MAC Address    IP Address      I/F           MAC           Prim RxPwr  Timing Num I
                                             State         Sid  (dBmv) Offset CPE P
0010.188a.faf6 0.0.0.0         C8/0/0/U0     offline       1    0.00   1482   0   N
74ae.7600.01f3 10.32.115.150   C8/0/10/U0    online        1    -0.50  1431   0   Y
0010.188a.fad8 10.32.115.142   C8/0/10/UB    w-online      2    -0.50  1507   1   Y
000e.0900.00dd 10.32.115.143   C8/0/10/UB    w-online      3    1.00   1677   0   Y
e86d.5271.304f 10.32.115.168   C8/0/10/UB    w-online      6    -0.50  1419   1   Y</screen>

</section>
<section xml:id="show-pcmm-plugin-connection">
<title>Show PCMM Plugin Connection</title>
<screen>10k2-DSG#show packetcabl ?
  cms     Gate Controllers connected to this PacketCable client
  event   Event message server information
  gate    PacketCable gate information
  global  PacketCable global information

10k2-DSG#show packetcable cms
GC-Addr        GC-Port  Client-Addr    COPS-handle  Version PSID Key PDD-Cfg


10k2-DSG#show packetcable cms
GC-Addr        GC-Port  Client-Addr    COPS-handle  Version PSID Key PDD-Cfg
10.32.0.240    54238    10.32.15.3     0x4B9C8150/1    4.0   0    0   0</screen>

</section>
<section xml:id="show-cops-messages">
<title>Show COPS Messages</title>
<screen>debug cops details</screen>

</section>
<section xml:id="use-cm-mac-address-to-list-service-flows">
<title>Use CM Mac Address to List Service Flows</title>
<screen>10k2-DSG#show cable modem
                                                                                  D
MAC Address    IP Address      I/F           MAC           Prim RxPwr  Timing Num I
                                             State         Sid  (dBmv) Offset CPE P
0010.188a.faf6 ---             C8/0/0/UB     w-online      1    0.50   1480   1   N
74ae.7600.01f3 10.32.115.150   C8/0/10/U0    online        1    -0.50  1431   0   Y
0010.188a.fad8 10.32.115.142   C8/0/10/UB    w-online      2    -0.50  1507   1   Y
000e.0900.00dd 10.32.115.143   C8/0/10/UB    w-online      3    0.00   1677   0   Y
e86d.5271.304f 10.32.115.168   C8/0/10/UB    w-online      6    -0.50  1419   1   Y


10k2-DSG#show cable modem 000e.0900.00dd service-flow


SUMMARY:
MAC Address    IP Address      Host          MAC           Prim  Num Primary    DS
                               Interface     State         Sid   CPE Downstream RfId
000e.0900.00dd 10.32.115.143   C8/0/10/UB    w-online      3     0   Mo8/0/2:1  2353


Sfid  Dir Curr  Sid   Sched  Prio MaxSusRate  MaxBrst     MinRsvRate  Throughput
          State       Type
23    US  act   3     BE     0    0           3044        0           39
30    US  act   16    BE     0    500000      3044        0           0
24    DS  act   N/A   N/A    0    0           3044        0           17



UPSTREAM SERVICE FLOW DETAIL:

SFID  SID   Requests   Polls      Grants     Delayed    Dropped    Packets
                                             Grants     Grants
23    3     784        0          784        0          0          784
30    16    0          0          0          0          0          0


DOWNSTREAM SERVICE FLOW DETAIL:

SFID  RP_SFID QID    Flg Policer               Scheduler             FrwdIF
                         Xmits      Drops      Xmits      Drops
24    33019   131550     0          0          777        0          Wi8/0/2:2

Flags Legend:
$: Low Latency Queue (aggregated)
~: CIR Queue</screen>

</section>
<section xml:id="deleting-a-pcmm-gate-message-from-the-cmts">
<title>Deleting a PCMM Gate Message from the CMTS</title>
<screen>10k2-DSG#test cable dsd  000e.0900.00dd 30</screen>

</section>
<section xml:id="find-service-flows">
<title>Find service flows</title>
<simpara>All gate controllers currently connected to the PacketCable client are
displayed</simpara>
<screen>show cable modem 00:11:22:33:44:55 service flow   ????
show cable modem</screen>

</section>
<section xml:id="debug-and-display-pcmm-gate-messages">
<title>Debug and display PCMM Gate messages</title>
<screen>debug packetcable gate control
debug packetcable gate events
show packetcable gate summary
show packetcable global
show packetcable cms</screen>

</section>
<section xml:id="debug-cops-messages">
<title>Debug COPS messages</title>
<screen>debug cops detail
debug packetcable cops
debug cable dynamic_qos trace</screen>

</section>
</section>
<section xml:id="integration-verification">
<title>Integration Verification</title>
<simpara>Checkout the integration project and perform regression tests.</simpara>
<screen>git clone ssh://${ODL_USERNAME}@git.opendaylight.org:29418/integration.git
git clone https:/git.opendaylight.org/gerrit/integration.git</screen>

<orderedlist numeration="arabic">
<listitem>
<simpara>Check and edit the
integration/features/src/main/resources/features.xml and follow the
directions there.</simpara>
</listitem>
<listitem>
<simpara>Check and edit the integration/features/pom.xml and add a dependency
for your feature file</simpara>
</listitem>
<listitem>
<simpara>Build integration/features and debug</simpara>
</listitem>
</orderedlist>

<simpara><literal>  mvn clean install</literal></simpara>
<simpara>Test your feature in the integration/distributions/extra/karaf/
distribution</simpara>
<screen>cd integration/distributions/extra/karaf/
mvn clean install
cd target/assembly/bin
./karaf</screen>

<section xml:id="service-wrapper">
<title>service-wrapper</title>
<simpara>Install <link xlink:href="http://karaf.apache.org/manual/latest/users-guide/wrapper.html">http://karaf.apache.org/manual/latest/users-guide/wrapper.html</link></simpara>
<screen>opendaylight-user@root&gt;feature:install service-wrapper
opendaylight-user@root&gt;wrapper:install --help
DESCRIPTION
        wrapper:install

Install the container as a system service in the OS.

SYNTAX
        wrapper:install [options]

OPTIONS
        -d, --display
                The display name of the service.
                (defaults to karaf)
        --help
                Display this help message
        -s, --start-type
                Mode in which the service is installed. AUTO_START or DEMAND_START (Default: AUTO_START)
                (defaults to AUTO_START)
        -n, --name
                The service name that will be used when installing the service. (Default: karaf)
                (defaults to karaf)
        -D, --description
                The description of the service.
                (defaults to )

opendaylight-user@root&gt; wrapper:install
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/bin/karaf-wrapper
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/bin/karaf-service
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/etc/karaf-wrapper.conf
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/lib/libwrapper.so
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/lib/karaf-wrapper.jar
Creating file: /home/user/odl/distribution-karaf-0.3.0-Lithium/lib/karaf-wrapper-main.jar

Setup complete.  You may wish to tweak the JVM properties in the wrapper configuration file:
/home/user/odl/distribution-karaf-0.3.0-Lithium/etc/karaf-wrapper.conf
before installing and starting the service.


Ubuntu/Debian Linux system detected:
  To install the service:
    $ ln -s /home/user/odl/distribution-karaf-0.3.0-Lithium/bin/karaf-service /etc/init.d/

  To start the service when the machine is rebooted:
    $ update-rc.d karaf-service defaults

  To disable starting the service when the machine is rebooted:
    $ update-rc.d -f karaf-service remove

  To start the service:
    $ /etc/init.d/karaf-service start

  To stop the service:
    $ /etc/init.d/karaf-service stop

  To uninstall the service :
    $ rm /etc/init.d/karaf-service</screen>

</section>
</section>
</chapter>
<chapter xml:id="_service_function_chaining">
<title>Service Function Chaining</title>
<section xml:id="_opendaylight_service_function_chaining_sfc_overiew">
<title>OpenDaylight Service Function Chaining (SFC) Overiew</title>
<simpara>OpenDaylight Service Function Chaining (SFC) provides the ability to define an ordered list of a network services (e.g. firewalls, load balancers). These service are then "stitched" together in the network to create a service chain. This project provides the infrastructure (chaining logic, APIs) needed for ODL to provision a service chain in the network and an end-user application for defining such chains.</simpara>
<itemizedlist>
<title>List of acronyms:</title>
<listitem>
<simpara>ACE - Access Control Entry</simpara>
</listitem>
<listitem>
<simpara>ACL - Access Control List</simpara>
</listitem>
<listitem>
<simpara>SCF - Service Classifier Function</simpara>
</listitem>
<listitem>
<simpara>SF - Service Function</simpara>
</listitem>
<listitem>
<simpara>SFC - Service Function Chain</simpara>
</listitem>
<listitem>
<simpara>SFF - Service Function Forwarder</simpara>
</listitem>
<listitem>
<simpara>SFG - Service Function Group</simpara>
</listitem>
<listitem>
<simpara>SFP - Service Function Path</simpara>
</listitem>
<listitem>
<simpara>RSP - Rendered Service Path</simpara>
</listitem>
<listitem>
<simpara>NSH - Network Service Header</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_sfc_classifier_control_and_date_plane_developer_guide">
<title>SFC Classifier Control and Date plane Developer guide</title>
<section xml:id="_overview_25">
<title>Overview</title>
<simpara>Description of classifier can be found in: <link xlink:href="https://datatracker.ietf.org/doc/draft-ietf-sfc-architecture/">https://datatracker.ietf.org/doc/draft-ietf-sfc-architecture/</link></simpara>
<simpara>Classifier manages everything from starting the packet listener to creation (and removal) of appropriate ip(6)tables rules and marking received packets accordingly. Its functionality is <emphasis role="strong">available only on Linux</emphasis> as it leverdges <emphasis role="strong">NetfilterQueue</emphasis>, which provides access to packets matched by an <emphasis role="strong">iptables</emphasis> rule. Classifier requires <emphasis role="strong">root privileges</emphasis> to be able to operate.</simpara>
<simpara>So far it is capable of processing ACL for MAC addresses, ports, IPv4 and IPv6. Supported protocols are TCP and UDP.</simpara>
</section>
<section xml:id="_classifier_architecture">
<title>Classifier Architecture</title>
<simpara>Python code located in the project repository sfc-py/common/classifier.py.</simpara>
<note>
<simpara>classifier assumes that Rendered Service Path (RSP) <emphasis role="strong">already exists</emphasis> in ODL when an ACL referencing it is obtained</simpara>
</note>

<orderedlist numeration="arabic">
<title>How it works:</title>
<listitem>
<simpara>sfc_agent receives an ACL and passes it for processing to the classifier</simpara>
</listitem>
<listitem>
<simpara>the RSP (its SFF locator) referenced by ACL is requested from ODL</simpara>
</listitem>
<listitem>
<simpara>if the RSP exists in the ODL then ACL based iptables rules for it are applied</simpara>
</listitem>
</orderedlist>

<simpara>After this process is over, every packet successfully matched to an iptables rule (i.e. successfully classified) will be NSH encapsulated and forwarded to a related SFF, which knows how to traverse the RSP.</simpara>
<simpara>Rules are created using appropriate iptables command. If the Access Control Entry (ACE) rule is MAC address related both iptables and ip6tabeles rules re issued. If ACE rule is IPv4 address related, only iptables rules are issued, same for IPv6.</simpara>
<note>
<simpara>iptables <emphasis role="strong">raw</emphasis> table contains all created rules</simpara>
</note>

<simpara>Information regarding already registered RSP(s) are stored in an internal data-store, which is represented as a dictionary:</simpara>

<literallayout class="monospaced">{rsp_id: {'name': &lt;rsp_name&gt;,
          'chains': {'chain_name': (&lt;ipv&gt;,),
                     ...
                     },
          'sff': {'ip': &lt;ip&gt;,
                  'port': &lt;port&gt;,
                  'starting-index': &lt;starting-index&gt;,
                  'transport-type': &lt;transport-type&gt;
                  },
          },
...
}</literallayout>


<itemizedlist>
<title>Where</title>
<listitem>
<simpara><literal>name</literal>: name of the RSP</simpara>
</listitem>
<listitem>
<simpara><literal>chains</literal>: dictionary of iptables chains related to the RSP with information about IP version for which the chain exists</simpara>
</listitem>
<listitem>
<simpara><literal>SFF</literal>: SFF forwarding parameters</simpara>
<itemizedlist>
<listitem>
<simpara><literal>ip</literal>: SFF IP address</simpara>
</listitem>
<listitem>
<simpara><literal>port</literal>: SFF port</simpara>
</listitem>
<listitem>
<simpara><literal>starting-index</literal>: index given to packet at first RSP hop</simpara>
</listitem>
<listitem>
<simpara><literal>transport-type</literal>: encapsulation protocol</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_key_apis_and_interfaces_11">
<title>Key APIs and Interfaces</title>
<simpara>This features exposes API to configure classifier (corresponds to service-function-classifier.yang)</simpara>
</section>
<section xml:id="_api_reference_documentation_12">
<title>API Reference Documentation</title>
<simpara>See: sfc-model/src/main/yang/service-function-classifier.yang</simpara>
</section>
</section>
<section xml:id="_sfc_ovs_plugin">
<title>SFC-OVS Plugin</title>
<section xml:id="_overview_26">
<title>Overview</title>
<simpara>SFC-OVS provides integration of SFC with Open vSwitch (OVS) devices.
Integration is realized through mapping of SFC objects (like SF, SFF,
Classifier, etc.) to OVS objects (like Bridge, TerminationPoint=Port/Interface).
The mapping takes care of automatic instantiation (setup) of corresponding object
whenever its counterpart is created. For example, when a new SFF is created,
the SFC-OVS plugin will create a new OVS bridge and when a new OVS Bridge is
created, the SFC-OVS plugin will create a new SFF.</simpara>
</section>
<section xml:id="_sfc_ovs_architecture">
<title>SFC-OVS Architecture</title>
<simpara>SFC-OVS uses the OVSDB MD-SAL Southbound API for getting/writing information
from/to OVS devices. The core functionality consists of two types of mapping:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>mapping from OVS to SFC</simpara>
<itemizedlist>
<listitem>
<simpara>OVS Bridge is mapped to SFF</simpara>
</listitem>
<listitem>
<simpara>OVS TerminationPoints are mapped to SFF DataPlane locators</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>mapping from SFC to OVS</simpara>
<itemizedlist>
<listitem>
<simpara>SFF is mapped to OVS Bridge</simpara>
</listitem>
<listitem>
<simpara>SFF DataPlane locators are mapped to OVS TerminationPoints</simpara>
</listitem>
</itemizedlist>

</listitem>
</orderedlist>

<figure>
<title>SFC &lt;&#8201;&#8212;&#8201;&gt; OVS mapping flow diagram</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/sfc/sfc-ovs-architecture.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>sfc ovs architecture</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_key_apis_and_interfaces_12">
<title>Key APIs and Interfaces</title>
<itemizedlist>
<listitem>
<simpara>SFF to OVS mapping API (methods to convert SFF object to OVS Bridge
and OVS TerminationPoints)</simpara>
</listitem>
<listitem>
<simpara>OVS to SFF mapping API (methods to convert OVS Bridge and OVS TerminationPoints
to SFF object)</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_sfc_southbound_rest_plugin">
<title>SFC Southbound REST Plugin</title>
<section xml:id="_overview_27">
<title>Overview</title>
<simpara>The Southbound REST Plugin is used to send configuration from DataStore down to
network devices supporting a REST API (i.e. they have a configured REST URI).
It supports POST/PUT/DELETE operations, which are triggered accordingly by
changes in the SFC data stores.</simpara>
<itemizedlist>
<title>In its current state it listens to changes in these SFC data stores:</title>
<listitem>
<simpara>Access Control List (ACL)</simpara>
</listitem>
<listitem>
<simpara>Service Classifier Function (SCF)</simpara>
</listitem>
<listitem>
<simpara>Service Function (SF)</simpara>
</listitem>
<listitem>
<simpara>Service Function Group (SFG)</simpara>
</listitem>
<listitem>
<simpara>Service Function Schedule Type (SFST)</simpara>
</listitem>
<listitem>
<simpara>Service Function Forwader (SFF)</simpara>
</listitem>
<listitem>
<simpara>Rendered Service Path (RSP)</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_southbound_rest_plugin_architecture">
<title>Southbound REST Plugin Architecture</title>
<orderedlist numeration="arabic">
<title>The Southbound REST Plugin is built from three main components:</title>
<listitem>
<simpara><emphasis role="strong">listeners</emphasis> - used to listen on changes in the SFC data stores</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">JSON exporters</emphasis> - used to export JSON-encoded data from binding-aware data
store objects</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">tasks</emphasis> - used to collect REST URIs of network devices and to send JSON-encoded
data down to these devices</simpara>
</listitem>
</orderedlist>

<figure>
<title>Southbound REST Plugin Architecture diagram</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/sfc/sb-rest-architecture.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>sb rest architecture</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_key_apis_and_interfaces_13">
<title>Key APIs and Interfaces</title>
<simpara>The plugin provides Southbound REST API designated to listening REST devices. It supports
POST/PUT/DELETE operations. The operation (with corresponding JSON-encoded data) is sent
to unique REST URL belonging to certain datatype.</simpara>
<itemizedlist>
<title>The URLs are following:</title>
<listitem>
<simpara>Access Control List (ACL):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/config/ietf-acl:access-lists/access-list/">http://&lt;host&gt;:&lt;port&gt;/config/ietf-acl:access-lists/access-list/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Service Function (SF):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/config/service-function:service-functions/service-function/">http://&lt;host&gt;:&lt;port&gt;/config/service-function:service-functions/service-function/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Service Function Group (SFG):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/config/service-function:service-function-groups/service-function-group/">http://&lt;host&gt;:&lt;port&gt;/config/service-function:service-function-groups/service-function-group/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Service Function Schedule Type (SFST):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/config/service-function-scheduler-type:service-function-scheduler-types/service-function-scheduler-type/">http://&lt;host&gt;:&lt;port&gt;/config/service-function-scheduler-type:service-function-scheduler-types/service-function-scheduler-type/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Service Function Forwarder (SFF):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/config/service-function-forwarder:service-function-forwarders/service-function-forwarder/">http://&lt;host&gt;:&lt;port&gt;/config/service-function-forwarder:service-function-forwarders/service-function-forwarder/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Rendered Service Path (RSP):
<literal><link xlink:href="http://&lt;host&gt;:&lt;port&gt;/operational/rendered-service-path:rendered-service-paths/rendered-service-path/">http://&lt;host&gt;:&lt;port&gt;/operational/rendered-service-path:rendered-service-paths/rendered-service-path/</link></literal></simpara>
</listitem>
</itemizedlist>

<simpara>Therefore, network devices willing to receive REST messages must listen on
these REST URLs.</simpara>
<note>
<simpara>Service Classifier Function (SCF) URL does not exist, because SCF is considered
as one of the network devices willing to receive REST messages. However, there
is a listener hooked on the SCF data store, which is triggering POST/PUT/DELETE
operations of ACL object, because ACL is referenced in <literal>service-function-classifier.yang</literal></simpara>
</note>

</section>
</section>
<section xml:id="_service_function_load_balancing_developer_guide">
<title>Service Function Load Balancing Developer Guide</title>
<section xml:id="_overview_28">
<title>Overview</title>
<simpara>SFC Load-Balancing feature implements load balancing of Service Functions, rather than a one-to-one mapping between Service Function Forwarder and Service Function.</simpara>
</section>
<section xml:id="_load_balancing_architecture">
<title>Load Balancing Architecture</title>
<simpara>Service Function Groups (SFG) can replace Service Functions (SF) in the Rendered Path model.
A Service Path can only be defined using SFGs or SFs, but not a combination of both.</simpara>
<simpara>Relevant objects in the YANG model are as follows:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Service-Function-Group-Algorithm:</simpara>

<literallayout class="monospaced">Service-Function-Group-Algorithms {
    Service-Function-Group-Algorithm {
        String name
        String type
    }
}</literallayout>



<literallayout class="monospaced">Available types: ALL, SELECT, INDIRECT, FAST_FAILURE</literallayout>


</listitem>
<listitem>
<simpara>Service-Function-Group:</simpara>

<literallayout class="monospaced">Service-Function-Groups {
    Service-Function-Group {
        String name
        String serviceFunctionGroupAlgorithmName
        String type
        String groupId
        Service-Function-Group-Element {
            String service-function-name
            int index
        }
    }
}</literallayout>


</listitem>
<listitem>
<simpara>ServiceFunctionHop: holds a reference to a name of SFG (or SF)</simpara>
</listitem>
</orderedlist>

</section>
<section xml:id="_key_apis_and_interfaces_14">
<title>Key APIs and Interfaces</title>
<simpara>This feature enhances the existing SFC API.</simpara>
<simpara>REST API commands include:
* For Service Function Group (SFG): read existing SFG, write new SFG, delete existing SFG, add Service Function (SF) to SFG, and delete SF from SFG
* For Service Function Group Algorithm (SFG-Alg): read, write, delete</simpara>
<simpara>Bundle providing the REST API: sfc-sb-rest
* Service Function Groups and Algorithms are defined in: sfc-sfg and sfc-sfg-alg
* Relevant JAVA API: SfcProviderServiceFunctionGroupAPI, SfcProviderServiceFunctionGroupAlgAPI</simpara>
</section>
</section>
<section xml:id="_service_function_scheduling_algorithms">
<title>Service Function Scheduling Algorithms</title>
<section xml:id="_overview_29">
<title>Overview</title>
<simpara>When creating the Rendered Service Path (RSP), the earlier release of SFC
chose the first available service function from a list of service function
names. Now a new API is introduced to allow developers to develop their own
schedule algorithms when creating the RSP. There are four scheduling algorithms
(Random, Round Robin, Load Balance and Shortest Path) are provided as examples
for the API definition. This guide gives a simple introduction of how to develop
service function scheduling algorithms based on the current extensible framework.</simpara>
</section>
<section xml:id="_architecture_2">
<title>Architecture</title>
<simpara>The following figure illustrates the service function selection framework and
algorithms.</simpara>
<figure>
<title>SF Scheduling Algorithm framework Architecture</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/sfc-sf-selection-arch.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>SF Selection Architecture</phrase></textobject>
  </mediaobject>
</figure>

<simpara>The YANG Model defines the Service Function Scheduling Algorithm type
identities and how they are stored in the MD-SAL data store for the scheduling
algorithms.</simpara>
<simpara>The MD-SAL data store stores all informations for the scheduling algorithms,
including their types, names, and status.</simpara>
<simpara>The API provides some basic APIs to manage the informations stored in the
MD-SAL data store, like putting new items into it, getting all scheduling
algorithms, etc.</simpara>
<simpara>The RESTCONF API provides APIs to manage the informations stored in the MD-SAL
data store through RESTful calls.</simpara>
<simpara>The Service Function Chain Renderer gets the enabled scheduling algorithm type,
and schedules the service functions with scheduling algorithm implementation.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_15">
<title>Key APIs and Interfaces</title>
<simpara>While developing a new Service Function Scheduling Algorithm, a new class
should be added and it should extend the base schedule class
SfcServiceFunctionSchedulerAPI. And the new class should implement the abstract
function:</simpara>
<simpara><literal>public List&lt;String&gt; scheduleServiceFuntions(ServiceFunctionChain chain, int serviceIndex)</literal>.</simpara>
<itemizedlist>
<title>input</title>
<listitem>
<simpara><emphasis role="strong"><literal>ServiceFunctionChain chain</literal></emphasis>: the chain which will be rendered</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong"><literal>int serviceIndex</literal></emphasis>: the initial service index for this rendered service path</simpara>
</listitem>
</itemizedlist>

<itemizedlist>
<title>output</title>
<listitem>
<simpara><emphasis role="strong"><literal>List&lt;String&gt;</literal></emphasis>: a list of service funtion names which scheduled by the
Service Function Scheduling Algorithm.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_api_reference_documentation_13">
<title>API Reference Documentation</title>
<simpara>Please refer the API docs generated in the mdsal-apidocs.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_snmp4sdn_developer_guide">
<title>SNMP4SDN Developer Guide</title>
<section xml:id="_overview_30">
<title>Overview</title>
<simpara>We propose a southbound plugin that can control the off-the-shelf commodity Ethernet switches for the purpose of building SDN using Ethernet switches. For Ethernet switches, forwarding table, VLAN table, and ACL are where one can install flow configuration on, and this is done via SNMP and CLI in the proposed plugin. In addition, some settings required for Ethernet switches in SDN, e.g., disabling STP and flooding, are proposed.</simpara>
<figure>
<title>SNMP4SDN as an OpenDaylight southbound plugin</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/snmp4sdn_in_odl_architecture.jpg" contentwidth="400"/>
    </imageobject>
    <textobject><phrase>SNMP4SDN as an OpenDaylight southbound plugin</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_architecture_3">
<title>Architecture</title>
<simpara>The modules in the plugin are depicted as the following figure.</simpara>
<figure>
<title>Modules in the SNMP4SDN Plugin</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/snmp4sdn_modules.jpg" contentwidth="400"/>
    </imageobject>
    <textobject><phrase>Modules in the SNMP4SDN Plugin</phrase></textobject>
  </mediaobject>
</figure>

<itemizedlist>
<listitem>
<simpara>AclService: add/remove ACL profile and rule on the switches.</simpara>
</listitem>
<listitem>
<simpara>FdbService: add/modify/remove FDB table entry on the switches.</simpara>
</listitem>
<listitem>
<simpara>VlanService: add/modify/remove VLAN table entry on the switches.</simpara>
</listitem>
<listitem>
<simpara>TopologyService: query and acquire the subnet topology.</simpara>
</listitem>
<listitem>
<simpara>InventoryService: acquire the switches and their ports.</simpara>
</listitem>
<listitem>
<simpara>DiscoveryService: probe and resolve the underlying switches as well as the port pairs connecting the switches. The probing is realized by SNMP queries. The updates from discovery will also be reflected to the TopologyService.</simpara>
</listitem>
<listitem>
<simpara>MiscConfigService: do kinds of settings on switches</simpara>
<itemizedlist>
<listitem>
<simpara>Supported STP and ARP settings such as enable/disable STP, get port&#8217;s STP state, get ARP table, set ARP entry, and others</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>VendorSpecificHandler: to assist the flow configuration services to call the switch-talking modules with correct parameters value and order.</simpara>
</listitem>
<listitem>
<simpara>Switch-talking modules</simpara>
<itemizedlist>
<listitem>
<simpara>For the services above, when they need to read or configure the underlying switches via SNMP or CLI, these queries are dealt with the modules SNMPHandler and CLIHandler which directly talk with the switches. The SNMPListener is to listen to snmp trap such as link up/down event or switch on/off event.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_design">
<title>Design</title>
<simpara>In terms of the architecture of the SNMP4SDN Plugin&#8217;s features, the features include flow configuration, topology discovery, and multi-vendor support. Their architectures please refer to Wiki (<link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:Developer_Guide#Design">Developer Guide - Design</link>).</simpara>
</section>
<section xml:id="_installation_and_configuration_guide">
<title>Installation and Configuration Guide</title>
<itemizedlist>
<listitem>
<simpara>Please refer to the <emphasis>Getting Started Guide</emphasis> in <link xlink:href="https://www.opendaylight.org/downloads">https://www.opendaylight.org/downloads</link>, find the SNMP4SDN section.</simpara>
</listitem>
<listitem>
<simpara>For the latest full guide, please refer to Wiki (<link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:Installation_Guide">Installation Guide</link>, <link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:User_Guide#Configuration">User Guide - Configuration</link>).</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_tutorial">
<title>Tutorial</title>
<itemizedlist>
<listitem>
<simpara>For the latest full guide, please refer to Wiki (<link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:User_Guide#Tutorial_.2F_How-To">User Guide - Tutorial</link>).</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_programmatic_interface_s">
<title>Programmatic Interface(s)</title>
<simpara>SNMP4SDN Plugin exposes APIs via MD-SAL with YANG model. The methods (RPC call) and data structures for them are listed below.</simpara>
<section xml:id="_topologyservice">
<title>TopologyService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>get-edge-list</simpara>
</listitem>
<listitem>
<simpara>get-node-list</simpara>
</listitem>
<listitem>
<simpara>get-node-connector-list</simpara>
</listitem>
<listitem>
<simpara>set-discovery-interval (given interval time in seconds)</simpara>
</listitem>
<listitem>
<simpara>rediscover</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Data structure</simpara>
<itemizedlist>
<listitem>
<simpara>node: composed of node-id, node-type</simpara>
</listitem>
<listitem>
<simpara>node-connector: composed of node-connector-id, node-connector-type, node</simpara>
</listitem>
<listitem>
<simpara>topo-edge: composed of head-node-connector-id, head-node-connector-type, head-node-id, head-node-type, tail-node-connector-id, tail-node-connector-type, tail-node-id, tail-node-type</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_vlanservice">
<title>VlanService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>add-vlan (given node ID, VLAN ID, VLAN name)</simpara>
</listitem>
<listitem>
<simpara>add-vlan-and-set-ports (given node ID, VLAN ID, VLAN name, tagged ports, untagged ports)</simpara>
</listitem>
<listitem>
<simpara>set-vlan-ports (given node ID, VLAN ID, tagged ports, untagged ports)</simpara>
</listitem>
<listitem>
<simpara>delete-vlan (given node ID, VLAN ID)</simpara>
</listitem>
<listitem>
<simpara>get-vlan-table (given node ID)</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_aclservice">
<title>AclService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>create-acl-profile (given node ID, acl-profile-index, acl-profile)</simpara>
</listitem>
<listitem>
<simpara>del-acl-profile (given node ID, acl-profile-index)</simpara>
</listitem>
<listitem>
<simpara>set-acl-rule (given node ID, acl-index, acl-rule)</simpara>
</listitem>
<listitem>
<simpara>del-acl-rule (given node ID, acl-index)</simpara>
</listitem>
<listitem>
<simpara>clear-acl-table (given node ID)</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Data structure</simpara>
<itemizedlist>
<listitem>
<simpara>acl-profile-index: composed of profile-id, profile name</simpara>
</listitem>
<listitem>
<simpara>acl-profile: composed of acl-layer, vlan-mask, src-ip-mask, dst-ip-mask</simpara>
</listitem>
<listitem>
<simpara>acl-layer: IP or ETHERNET</simpara>
</listitem>
<listitem>
<simpara>acl-index: composed of acl-profile-index, acl-rule-index</simpara>
</listitem>
<listitem>
<simpara>acl-rule-index: composed of rule-id, rule-name</simpara>
</listitem>
<listitem>
<simpara>acl-rule: composed of port-list, acl-layer, acl-field, acl-action</simpara>
</listitem>
<listitem>
<simpara>acl-field: composed of vlan-id, src-ip, dst-ip</simpara>
</listitem>
<listitem>
<simpara>acl-action: PERMIT or DENY</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_fdbservice">
<title>FdbService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>set-fdb-entry (given fdb-entry)</simpara>
</listitem>
<listitem>
<simpara>del-fdb-entry (given node-id, vlan-id, dest-mac-adddr)</simpara>
</listitem>
<listitem>
<simpara>get-fdb-entry (given node-id, vlan-id, dest-mac-adddr)</simpara>
</listitem>
<listitem>
<simpara>get-fdb-table (given node-id)</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Data structure</simpara>
<itemizedlist>
<listitem>
<simpara>fdb-entry: composed of node-id, vlan-id, dest-mac-addr, port, fdb-entry-type</simpara>
</listitem>
<listitem>
<simpara>fdb-entry-type: OTHER/INVALID/LEARNED/SELF/MGMT</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_miscconfigservice">
<title>MiscConfigService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>set-stp-port-state (given node-id, port, is_nable)</simpara>
</listitem>
<listitem>
<simpara>get-stp-port-state (given node-id, port)</simpara>
</listitem>
<listitem>
<simpara>get-stp-port-root (given node-id, port)</simpara>
</listitem>
<listitem>
<simpara>enable-stp (given node-id)</simpara>
</listitem>
<listitem>
<simpara>disable-stp (given node-id)</simpara>
</listitem>
<listitem>
<simpara>delete-arp-entry (given node-id, ip-address)</simpara>
</listitem>
<listitem>
<simpara>set-arp-entry (given node-id, arp-entry)</simpara>
</listitem>
<listitem>
<simpara>get-arp-entry (given node-id, ip-address)</simpara>
</listitem>
<listitem>
<simpara>get-arp-table (given node-id)</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Data structure</simpara>
<itemizedlist>
<listitem>
<simpara>stp-port-state: DISABLE/BLOCKING/LISTENING/LEARNING/FORWARDING/BROKEN</simpara>
</listitem>
<listitem>
<simpara>arp-entry: composed of ip-address and mac-address</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_switchdbservice">
<title>SwitchDbService</title>
<itemizedlist>
<listitem>
<simpara>RPC call</simpara>
<itemizedlist>
<listitem>
<simpara>reload-db
(The following 4 RPC implemention is TBD)</simpara>
</listitem>
<listitem>
<simpara>add-switch-entry</simpara>
</listitem>
<listitem>
<simpara>delete-switch-entry</simpara>
</listitem>
<listitem>
<simpara>clear-db</simpara>
</listitem>
<listitem>
<simpara>update-db</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Data structure</simpara>
<itemizedlist>
<listitem>
<simpara>switch-info: compose of node-ip, node-mac, community, cli-user-name, cli-password, model</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_help">
<title>Help</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:Main">SNMP4SDN Wiki</link></simpara>
</listitem>
<listitem>
<simpara>SNMP4SDN Mailing List (<link xlink:href="https://lists.opendaylight.org/mailman/listinfo/snmp4sdn-users">user</link>, <link xlink:href="https://lists.opendaylight.org/mailman/listinfo/snmp4sdn-dev">developer</link>)</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://wiki.opendaylight.org/view/SNMP4SDN:User_Guide#Troubleshooting">Latest troubleshooting in Wiki</link></simpara>
</listitem>
</itemizedlist>

</section>
</chapter>
<chapter xml:id="_sxp_developer_guide">
<title>SXP Developer Guide</title>
<section xml:id="_overview_31">
<title>Overview</title>
<simpara>SXP (Source-Group Tag eXchange Protocol) project is an effort to enhance OpenDaylight platform with IP-SGT (IP Address to Source Group Tag) bindings that can be learned from connected SXP-aware network nodes. The current implementation supports SXP protocol version 4 according to the Smith, Kandula - SXP <link xlink:href="https://tools.ietf.org/html/draft-smith-kandula-sxp-04">IETF draft</link> and grouping of peers and creating filters based on ACL/Prefix-list syntax for filtering outbound and inbound IP-SGT bindings. All protocol legacy versions 1-3 are supported as well. Additionally, version 4 adds bidirectional connection type as an extension of a unidirectional one.</simpara>
</section>
<section xml:id="_sxp_architecture">
<title>SXP Architecture</title>
<simpara>The SXP Server manages all connected clients in separate threads and a common SXP protocol agreement is used between connected peers. Each SXP network peer is modelled with its pertaining class, e.g., SXP Server represents the SXP Speaker, SXP Listener the Client. The server program creates the ServerSocket object on a specified port and waits until a client starts up and requests connect on the IP address and port of the server. The client program opens a Socket that is connected to the server running on the specified host IP address and port.</simpara>
<simpara>The SXP Listener maintains connection with its speaker peer. From an opened channel pipeline, all incoming SXP messages are processed by various handlers. Message must be decoded, parsed and validated.</simpara>
<simpara>The SXP Speaker is a counterpart to the SXP Listener. It maintains a connection with its listener peer and sends composed messages.</simpara>
<simpara>The SXP Binding Handler extracts the IP-SGT binding from a message and pulls it into the SXP-Database. If an error is detected during the IP-SGT extraction, an appropriate error code and sub-code is selected and an error message is sent back to the connected peer. All transitive messages are routed directly to the output queue of SXP Binding Dispatcher.</simpara>
<simpara>The SXP Binding Dispatcher represents a selector that will decides how many data from the SXP-database will be sent and when. It is responsible for message content composition based on maximum message length.</simpara>
<simpara>The SXP Binding Filters handles filtering of outgoing and incoming IP-SGT bindings according to BGP filtering using ACL and Prefix List syntax for specifying filter or based on Peer-sequence length.</simpara>
<simpara>The SXP Domains feature provides isolation of SXP peers and bindings learned between them, also exchange of Bindings is possible across SXP-Domains by ACL, Prefix List or Peer-Sequence filters</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_16">
<title>Key APIs and Interfaces</title>
<simpara>As this project is fairly small, it provides only few features that install and
provide all APIs and implementations for this project.</simpara>
<itemizedlist>
<listitem>
<simpara>sxp-controller</simpara>
</listitem>
<listitem>
<simpara>sxp-api</simpara>
</listitem>
<listitem>
<simpara>spx-core</simpara>
</listitem>
</itemizedlist>

<section xml:id="_sxp_controller">
<title>sxp-controller</title>
<simpara>RPC request handling</simpara>
</section>
<section xml:id="_sxp_api">
<title>sxp-api</title>
<simpara>Contains data holders and entities</simpara>
</section>
<section xml:id="_spx_core">
<title>spx-core</title>
<simpara>Main logic and core features</simpara>
</section>
</section>
<section xml:id="_api_reference_documentation_14">
<title>API Reference Documentation</title>
<simpara><link xlink:href="https://wiki.opendaylight.org/images/9/91/SXP_Restconf_Interface_and_Dynamic_Tree.pdf">RESTCONF Interface and Dynamic Tree</link>
<link xlink:href="https://wiki.opendaylight.org/images/6/6e/SXP_Specification_and_Architecture_v03.pdf">Specification and Architecture</link></simpara>
</section>
</chapter>
<chapter xml:id="_topology_processing_framework_developer_guide">
<title>Topology Processing Framework Developer Guide</title>
<section xml:id="_overview_32">
<title>Overview</title>
<simpara>The Topology Processing Framework allows developers to aggregate and filter topologies according to defined correlations. It also provides functionality, which you can use to make your own topology model by automating the translation from one model to another. For example to translate from the opendaylight-inventory model to only using the network-topology model.</simpara>
</section>
<section xml:id="_architecture_4">
<title>Architecture</title>
<section xml:id="_chapter_overview">
<title>Chapter Overview</title>
<simpara>In this chapter we describe the architecture of the Topology Processing Framework. In the first part, we provide information about available features and basic class relationships. In the second part, we describe our model specific approach, which is used to provide support for different models.</simpara>
</section>
<section xml:id="_basic_architecture">
<title>Basic Architecture</title>
<simpara>The Topology Processing Framework consists of several Karaf features:</simpara>
<itemizedlist>
<listitem>
<simpara>odl-topoprocessing-framework</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-inventory</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-network-topology</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-i2rs</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-inventory-rendering</simpara>
</listitem>
</itemizedlist>

<simpara>The feature odl-topoprocessing-framework contains the topoprocessing-api, topoprocessing-spi and topoprocessing-impl
bundles. This feature is the core of the Topology Processing Framework and is required by all others features.</simpara>
<itemizedlist>
<listitem>
<simpara>topoprocessing-api - contains correlation definitions and definitions required for rendering</simpara>
</listitem>
<listitem>
<simpara>topoprocessing-spi - entry point for topoprocessing service (start and close)</simpara>
</listitem>
<listitem>
<simpara>topoprocessing-impl - contains base implementations of handlers, listeners, aggregators and filtrators</simpara>
</listitem>
</itemizedlist>

<simpara>TopoProcessingProvider is the entry point for Topology Processing Framework. It requires a DataBroker instance. The DataBroker is needed for listener registration. There is also the TopologyRequestListener which listens on aggregated topology requests (placed into the configuration datastore) and UnderlayTopologyListeners which listen on underlay topology data changes (made in operational datastore). The TopologyRequestHandler saves toporequest data and provides a method for translating a path to the specified leaf. When a change in the topology occurs, the registered UnderlayTopologyListener processes this information for further aggregation and/or filtration. Finally, after an overlay topology is created, it is passed to the TopologyWriter, which writes this topology into operational datastore.</simpara>
<figure>
<title>Class relationship</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/TopologyRequestHandler_classesRelationship.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>TopologyRequestHandler classesRelationship</phrase></textobject>
  </mediaobject>
</figure>

<simpara>[1] TopologyRequestHandler instantiates TopologyWriter and TopologyManager. Then, according to the request, initializes either TopologyAggregator, TopologyFiltrator or LinkCalculator.</simpara>
<simpara>[2] It creates as many instances of UnderlayTopologyListener as there are underlay topologies.</simpara>
<simpara>[3] PhysicalNodes are created for relevant incoming nodes (those having node ID).</simpara>
<simpara>[4a] It performs aggregation and creates logical nodes.</simpara>
<simpara>[4b] It performs filtration and creates logical nodes.</simpara>
<simpara>[4c] It performs link computation and creates links between logical nodes.</simpara>
<simpara>[5] Logical nodes are put into wrapper.</simpara>
<simpara>[6] The wrapper is translated into the appropriate format and written into datastore.</simpara>
</section>
<section xml:id="_model_specific_approach">
<title>Model Specific Approach</title>
<simpara>The Topology Processing Framework consists of several modules and Karaf features, which provide support for different input models. Currently we support the network-topology, opendaylight-inventory and i2rs models. For each of these input models, the Topology Processing Framework has one module and one Karaf feature.</simpara>
<section xml:id="_how_it_works">
<title>How it works</title>
<formalpara>
<title>User point of view:</title>
<para>When you start the odl-topoprocessing-framework feature, the Topology Processing Framework starts without knowledge how to work with any input models. In order to allow the Topology Processing Framework to process some kind of input model, you must install one (or more) model specific features. Installing these features will also start odl-topoprocessing-framework feature if it is not already running. These features inject appropriate logic into the odl-topoprocessing-framework feature. From that point, the Topology Processing Framework is able to process different kinds of input models, specifically those that you install features for.</para>
</formalpara>
<formalpara>
<title>Developer point of view:</title>
<para>The topoprocessing-impl module contains (among other things) classes and interfaces, which are common for every model specific topoprocessing module. These classes and interfaces are implemented and extended by classes in particular model specific modules.
Model specific modules also depend on the TopoProcessingProvider class in the topoprocessing-spi module. This dependency is injected during installation of model specific features in Karaf. When a model specific feature is started, it calls the registerAdapters(adapters) method of the injected TopoProcessingProvider object. After this step, the Topology Processing Framework is able to use registered model adapters to work with input models.</para>
</formalpara>
<simpara>To achieve the described functionality we created a ModelAdapter interface. It represents installed feature and provides methods for creating crucial structures specific to each model.</simpara>
<figure>
<title>ModelAdapter interface</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/ModelAdapter.png" contentwidth="300"/>
    </imageobject>
    <textobject><phrase>ModelAdapter</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_model_specific_features">
<title>Model Specific Features</title>
<itemizedlist>
<listitem>
<simpara>odl-topoprocessing-network-topology - this feature contains logic to work with network-topology model</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-inventory - this feature contains logic to work with opendaylight-inventory model</simpara>
</listitem>
<listitem>
<simpara>odl-topoprocessing-i2rs - this feature contains logic to work with i2rs model</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_inventory_model_support">
<title>Inventory Model Support</title>
<simpara>The opendaylight-inventory model contains only nodes, termination points, information regarding these structures. This model co-operates with network-topology model, where other topology related information is stored. This means that we have to handle two input models at once. To support the inventory model, InventoryListener and NotificationInterConnector classes were introduced. Please see the flow diagrams below.</simpara>
<figure>
<title>Network topology model</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/Network_topology_model_flow_diagram.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Network topology model flow diagram</phrase></textobject>
  </mediaobject>
</figure>

<figure>
<title>Inventory model</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/Inventory_model_listener_diagram.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Inventory model listener diagram</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Here we can see the InventoryListener and NotificationInterConnector classes. InventoryListener listens on data changes in the inventory model and passes these changes wrapped as an UnderlayItem for further processing to NotificationInterConnector. It doesn&#8217;t contain node information - it contains a leafNode (node based on which aggregation occurs) instead.
The node information is stored in the topology model, where UnderlayTopologyListener is registered as usual. This listener delivers the missing information.</simpara>
<simpara>Then the NotificationInterConnector combines the two notifications into a complete UnderlayItem (no null values) and delivers this UnderlayItem for further processing (to next TopologyOperator).</simpara>
</section>
</section>
<section xml:id="_aggregation_and_filtration">
<title>Aggregation and Filtration</title>
<section xml:id="_chapter_overview_2">
<title>Chapter Overview</title>
<simpara>The Topology Processing Framework allows the creation of aggregated topologies and filtered views over existing topologies. Currently, aggregation and filtration is supported for topologies that follow <link xlink:href="https://github.com/opendaylight/yangtools/blob/master/model/ietf/ietf-topology/src/main/yang/network-topology%402013-10-21.yang">network-topology</link>, opendaylight-inventory or i2rs model. When a request to create an aggregated or filtered topology is received, the framework creates one listener per underlay topology. Whenever any specified underlay topology is changed, the appropriate listener is triggered with the change and the change is processed. Two types of correlations (functionalities) are currently supported:</simpara>
<itemizedlist>
<listitem>
<simpara>Aggregation</simpara>
<itemizedlist>
<listitem>
<simpara>Unification</simpara>
</listitem>
<listitem>
<simpara>Equality</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Filtration</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_terminology">
<title>Terminology</title>
<simpara>We use the term underlay item (physical node) for items (nodes, links, termination-points) from underlay and overlay item (logical node) for items from overlay topologies regardless of whether those are actually physical network elements.</simpara>
</section>
<section xml:id="_aggregation">
<title>Aggregation</title>
<simpara>Aggregation is an operation which creates an aggregated item from two or more items in the underlay topology if the aggregation condition is fulfilled. Requests for aggregated topologies must specify a list of underlay topologies over which the overlay (aggregated) topology will be created and a target field in the underlay item that the framework will check for equality.</simpara>
<section xml:id="_create_overlay_node">
<title>Create Overlay Node</title>
<simpara>First, each new underlay item is inserted into the proper topology store. Once the item is stored, the framework compares it (using the target field value) with all stored underlay items from underlay topologies. If there is a target-field match, a new overlay item is created containing pointers to all <emphasis>equal</emphasis> underlay items. The newly created overlay item is also given new references to its supporting underlay items.</simpara>
<formalpara>
<title>Equality case:</title>
<para>If an item doesn&#8217;t fulfill the equality condition with any other items, processing finishes after adding the item into topology store. It will stay there for future use, ready to create an aggregated item with a new underlay item, with which it would satisfy the equality condition.</para>
</formalpara>
<formalpara>
<title>Unification case:</title>
<para>An overlay item is created for all underlay items, even those which don&#8217;t fulfill the equality condition with any other items. This means than an overlay item is created for every underlay item, but for items which satisfy the equality condition, an aggregated item is created.</para>
</formalpara>
</section>
<section xml:id="_update_node">
<title>Update Node</title>
<simpara>Processing of updated underlay items depends on whether the target field has been modified. If yes, then:</simpara>
<itemizedlist>
<listitem>
<simpara>if the underlay item belonged to some overlay item, it is removed from that item. Next, if the aggregation condition on the target field is satisfied, the item is inserted into another overlay item. If the condition isn&#8217;t met then:</simpara>
<itemizedlist>
<listitem>
<simpara>in equality case - the item will not be present in overlay topology.</simpara>
</listitem>
<listitem>
<simpara>in unification case - the item will create an overlay item with a single underlay item and this will be written into overlay topology.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>if the item didn&#8217;t belong to some overlay item, it is checked again for aggregation with other underlay items.</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_remove_node">
<title>Remove Node</title>
<simpara>The underlay item is removed from the corresponding topology store, from it&#8217;s overlay item (if it belongs to one) and this way it is also removed from overlay topology.</simpara>
<formalpara>
<title>Equality case:</title>
<para>If there is only one underlay item left in the overlay item, the overlay item is removed.</para>
</formalpara>
<formalpara>
<title>Unification case:</title>
<para>The overlay item is removed once it refers to no underlay item.</para>
</formalpara>
</section>
</section>
<section xml:id="_filtration">
<title>Filtration</title>
<simpara>Filtration is an operation which results in creation of overlay topology containing only items fulfilling conditions set in the topoprocessing request.</simpara>
<section xml:id="_create_underlay_item">
<title>Create Underlay Item</title>
<simpara>If a newly created underlay item passes all filtrators and their conditions, then it is stored in topology store and a creation notification is delivered into topology manager. No operation otherwise.</simpara>
</section>
<section xml:id="_update_underlay_item">
<title>Update Underlay Item</title>
<simpara>First, the updated item is checked for presence in topology store:</simpara>
<itemizedlist>
<listitem>
<simpara>if it is present in topology store:</simpara>
<itemizedlist>
<listitem>
<simpara>if it meets the filtering conditions, then processUpdatedData notification is triggered</simpara>
</listitem>
<listitem>
<simpara>else processRemovedData notification is triggered</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>if item isn&#8217;t present in topology store</simpara>
<itemizedlist>
<listitem>
<simpara>if item meets filtering conditions, then processCreatedData notification is triggered</simpara>
</listitem>
<listitem>
<simpara>else it is ignored</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_remove_underlay_item">
<title>Remove Underlay Item</title>
<simpara>If an underlay node is supporting some overlay node, the overlay node is simply removed.</simpara>
</section>
<section xml:id="_default_filtrator_types">
<title>Default Filtrator Types</title>
<simpara>There are seven types of default filtrators defined in the framework:</simpara>
<itemizedlist>
<listitem>
<simpara>IPv4-address filtrator - checks if specified field meets IPv4 address + mask criteria</simpara>
</listitem>
<listitem>
<simpara>IPv6-address filtrator - checks if specified field meets IPv6 address + mask criteria</simpara>
</listitem>
<listitem>
<simpara>Specific number filtrator - check for specific number</simpara>
</listitem>
<listitem>
<simpara>Specific string filtrator - checks for specific string</simpara>
</listitem>
<listitem>
<simpara>Range number filtrator - checks if specified field is higher than provided minimum and lower than provided maximum</simpara>
</listitem>
<listitem>
<simpara>Range string filtrator - checks if specified field is alphabetically greater than provided minimum and alphabetically lower than provided maximum</simpara>
</listitem>
<listitem>
<simpara>Script filtrator - allows a user or application to implement their own filtrator</simpara>
</listitem>
</itemizedlist>

</section>
<section xml:id="_register_custom_filtrator">
<title>Register Custom Filtrator</title>
<simpara>There might be some use case that cannot be achieved with the default filtrators. In these cases, the framework offers the possibility for a user or application to register a custom filtrator.</simpara>
</section>
</section>
<section xml:id="_pre_filtration_filtration_aggregation">
<title>Pre-Filtration / Filtration &amp; Aggregation</title>
<simpara>This feature was introduced in order to lower memory and performance demands. It is a combination of the filtration and aggregation operations. First, uninteresting items are filtered out and then aggregation is performed only on items that passed filtration. This way the framework saves on compute time. The PreAggregationFiltrator and TopologyAggregator share the same TopoStoreProvider (and thus topology store) which results in lower memory demands (as underlay items are stored only in one topology store - they aren&#8217;t stored twice).</simpara>
</section>
</section>
<section xml:id="_link_computation">
<title>Link Computation</title>
<section xml:id="_chapter_overview_3">
<title>Chapter Overview</title>
<simpara>During the topology request processing, we create overlay nodes with lists of supporting underlay nodes. Because these overlay nodes have completely new identifiers, we lose link information. To regain this link information, we provide Link Computation functionality. Its main purpose is to create new overlay links based on the links from the underlay topologies and underlay items from overlay items. The required information for Link Computation is provided via the Link Computation model in (<link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=topoprocessing.git;a=blob;f=topoprocessing-api/src/main/yang/topology-link-computation.yang;hb=refs/heads/stable/beryllium">topology-link-computation.yang</link>).</simpara>
</section>
<section xml:id="_link_computation_functionality">
<title>Link Computation Functionality</title>
<simpara>Let us consider two topologies with following components:</simpara>
<simpara>Topology 1:</simpara>
<itemizedlist>
<listitem>
<simpara>Node: <literal>node:1:1</literal></simpara>
</listitem>
<listitem>
<simpara>Node: <literal>node:1:2</literal></simpara>
</listitem>
<listitem>
<simpara>Node: <literal>node:1:3</literal></simpara>
</listitem>
<listitem>
<simpara>Link: <literal>link:1:1</literal> (from <literal>node:1:1</literal> to <literal>node:1:2</literal>)</simpara>
</listitem>
<listitem>
<simpara>Link: <literal>link:1:2</literal> (from <literal>node:1:3</literal> to <literal>node:1:2</literal>)</simpara>
</listitem>
</itemizedlist>

<simpara>Topology 2:</simpara>
<itemizedlist>
<listitem>
<simpara>Node: <literal>node:2:1</literal></simpara>
</listitem>
<listitem>
<simpara>Node: <literal>node:2:2</literal></simpara>
</listitem>
<listitem>
<simpara>Node: <literal>node:2:3</literal></simpara>
</listitem>
<listitem>
<simpara>Link: <literal>link:2:1</literal> (from <literal>node:2:1</literal> to <literal>node:2:3</literal>)</simpara>
</listitem>
</itemizedlist>

<simpara>Now let&#8217;s say that we applied some operations over these topologies that results into aggregating together</simpara>
<itemizedlist>
<listitem>
<simpara><literal>node:1:1</literal> and <literal>node:2:3</literal> (<literal>node:1</literal>)</simpara>
</listitem>
<listitem>
<simpara><literal>node:1:2</literal> and <literal>node:2:2</literal> (<literal>node:2</literal>)</simpara>
</listitem>
<listitem>
<simpara><literal>node:1:3</literal> and <literal>node:2:1</literal> (<literal>node:3</literal>)</simpara>
</listitem>
</itemizedlist>

<simpara>At this point we can no longer use available links in new topology because of the node ID change, so we must create new overlay links with source and destination node set to new nodes IDs. It means that <literal>link:1:1</literal> from topology 1 will create new link <literal>link:1</literal>. Since original source (<literal>node:1:1</literal>) is already aggregated under <literal>node:1</literal>, it will become source node for <literal>link:1</literal>. Using same method the destination will be <literal>node:2</literal>. And the final output will be three links:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>link:1</literal>, from <literal>node:1</literal> to <literal>node:2</literal></simpara>
</listitem>
<listitem>
<simpara><literal>link:2</literal>, from <literal>node:3</literal> to <literal>node:2</literal></simpara>
</listitem>
<listitem>
<simpara><literal>link:3</literal>, from <literal>node:3</literal> to <literal>node:1</literal></simpara>
</listitem>
</itemizedlist>

<figure>
<title>Overlay topology with computed links</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/LinkComputation.png" contentwidth="461"/>
    </imageobject>
    <textobject><phrase>LinkComputation</phrase></textobject>
  </mediaobject>
</figure>

</section>
<section xml:id="_in_depth_look">
<title>In-Depth Look</title>
<simpara>The main logic behind Link Computation is executed in the LinkCalculator operator. The required information is passed to LinkCalculator through the LinkComputation section of the topology request. This section is defined in the topology-link-computation.yang file. The main logic also covers cases when some underlay nodes may not pass through other topology operators.</simpara>
<section xml:id="_link_computation_model">
<title>Link Computation Model</title>
<simpara>There are three essential pieces of information for link computations. All of them are provided within the LinkComputation section. These pieces are:</simpara>
<itemizedlist>
<listitem>
<simpara>output model</simpara>
</listitem>
</itemizedlist>

<programlisting language="yang" linenumbering="unnumbered">leaf output-model {
    type identityref {
        base topo-corr:model;
    }
    description "Desired output model for computed links.";
}</programlisting>

<itemizedlist>
<listitem>
<simpara>overlay topology with new nodes</simpara>
</listitem>
</itemizedlist>

<programlisting language="yang" linenumbering="unnumbered">container node-info {
    leaf node-topology {
        type string;
        mandatory true;
        description "Topology that contains aggregated nodes.
                     This topology will be used for storing computed links.";
    }
    uses topo-corr:input-model-grouping;
}</programlisting>

<itemizedlist>
<listitem>
<simpara>underlay topologies with original links</simpara>
</listitem>
</itemizedlist>

<programlisting language="yang" linenumbering="unnumbered">list link-info {
    key "link-topology input-model";
    leaf link-topology {
        type string;
        mandatory true;
        description "Topology that contains underlay (base) links.";
    }
    leaf aggregated-links {
        type boolean;
        description "Defines if link computation should be based on supporting-links.";
    }
    uses topo-corr:input-model-grouping;
}</programlisting>

<simpara>This whole section is augmented into <literal>network-topology:topology</literal>. By placing this section out of correlations section, it allows us to send link computation request separately from topology operations request.</simpara>
</section>
<section xml:id="_main_logic">
<title>Main Logic</title>
<simpara>Taking into consideration that some of the underlay nodes may not transform into overlay nodes (e.g. they are filtered out), we created two possible states for links:</simpara>
<itemizedlist>
<listitem>
<simpara>matched - a link is considered as matched when both original source and destination node were transformed to overlay nodes</simpara>
</listitem>
<listitem>
<simpara>waiting - a link is considered as waiting if original source, destination or both nodes are missing from the overlay topology</simpara>
</listitem>
</itemizedlist>

<simpara>All links in waiting the state are stored in waitingLinks list, already matched links are stored in matchedLinks list and overlay nodes are stored in the storedOverlayNodes list. All processing is based only on information in these lists.
Processing created, updated and removed underlay items is slightly different and described in next sections separately.</simpara>
<simpara><emphasis role="strong">Processing Created Items</emphasis></simpara>
<simpara>Created items can be either nodes or links, depending on the type of listener from which they came. In the case of a link, it is immediately added to waitingLinks and calculation for possible overlay link creations (calculatePossibleLink) is started. The flow diagram for this process is shown in the following picture:</simpara>
<figure>
<title>Flow diagram of processing created items</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/LinkComputationFlowDiagram.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>LinkComputationFlowDiagram</phrase></textobject>
  </mediaobject>
</figure>

<simpara>Searching for the source and destination nodes in the calculatePossibleLink method runs over each node in storedOverlayNodes and the IDs of each supporting node is compared against IDs from the underlay link&#8217;s source and destination nodes. If there are any nodes missing, the link remains in the waiting state. If both the source and destination nodes are found, the corresponding overlay nodes is recorded as the new source and destination. The link is then removed from waitingLinks and a new CalculatedLink is added to the matched links. At the end, the new link (if it exists) is written into the datastore.</simpara>
<simpara>If the created item is an overlayNode, this is added to storedOverlayNodes and we call calculatePossibleLink for every link in waitingLinks.</simpara>
<simpara><emphasis role="strong">Processing Updated Items</emphasis></simpara>
<simpara>The difference from processing created items is that we have three possible types of updated items: overlay nodes, waiting underlay links, and matched underlay links.</simpara>
<itemizedlist>
<listitem>
<simpara>In the case of a change in a matched link, this must be recalculated and based on the result it will either be matched with new source and destination or will be returned to waiting links. If the link is moved back to a waiting state, it must also be removed from the datastore.</simpara>
</listitem>
<listitem>
<simpara>In the case of change in a waiting link, it is passed to the calculation process and based on the result will either remain in waiting state or be promoted to the matched state.</simpara>
</listitem>
<listitem>
<simpara>In the case of a change in an overlay node, storedOverlayNodes must be updated properly and all links must be recalculated in case of changes.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Processing Removed items</emphasis></simpara>
<simpara>Same as for processing updated item there can be three types of removed items:</simpara>
<itemizedlist>
<listitem>
<simpara>In case of waiting link removal, the link is just removed from waitingLinks</simpara>
</listitem>
<listitem>
<simpara>In case of matched link removal, the link is removed from matchingLinks and datastore</simpara>
</listitem>
<listitem>
<simpara>In case of overlay node removal, the node must be removed form storedOverlayNodes and all matching links must be recalculated</simpara>
</listitem>
</itemizedlist>

</section>
</section>
</section>
<section xml:id="_wrapper_rpc_republishing_writing_mechanism">
<title>Wrapper, RPC Republishing, Writing Mechanism</title>
<section xml:id="_chapter_overview_4">
<title>Chapter Overview</title>
<simpara>During the process of aggregation and filtration, overlay items (so called logical nodes) were created from underlay items (physical nodes). In the topology manager, overlay items are put into a wrapper. A wrapper is identified with unique ID and contains list of logical nodes. Wrappers are used to deal with transitivity of underlay items - which permits grouping of overlay items (into wrappers).</simpara>
<figure>
<title>Wrapper</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/wrapper.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>wrapper</phrase></textobject>
  </mediaobject>
</figure>

<simpara>PN1, PN2, PN3 = physical nodes</simpara>
<simpara>LN1, LN2 = logical nodes</simpara>
</section>
<section xml:id="_rpc_republishing">
<title>RPC Republishing</title>
<simpara>All RPCs registered to handle underlay items are re-registered under their corresponding wrapper ID. RPCs of underlay items (belonging to an overlay item) are gathered, and registered under ID of their wrapper.</simpara>
<section xml:id="_rpc_call">
<title>RPC Call</title>
<simpara>When RPC is called on overlay item, this call is delegated to it&#8217;s underlay items, this means that the RPC is called on all underlay items of this overlay item.</simpara>
</section>
</section>
<section xml:id="_writing_mechanism">
<title>Writing Mechanism</title>
<simpara>When a wrapper (containing overlay item(s) with it&#8217;s underlay item(s)) is ready to be written into data store, it has to be converted into DOM format. After this translation is done, the result is written into datastore. Physical nodes are stored as supporting-nodes.
In order to use resources responsibly, writing operation is divided into two steps. First, a set of threads registers prepared operations (deletes and puts) and one thread makes actual write operation in batch.</simpara>
</section>
</section>
<section xml:id="_topology_rendering_guide_inventory_rendering">
<title>Topology Rendering Guide - Inventory Rendering</title>
<section xml:id="_chapter_overview_5">
<title>Chapter Overview</title>
<simpara>In the most recent OpenDaylight release, the opendaylight-inventory model is marked as deprecated. To facilitate migration from it to the network-topology model, there were requests to render (translate) data from inventory model (whether augmented or not) to another model for further processing. The Topology Processing Framework was extended to provide this functionality by implementing several rendering-specific classes. This chapter is a step-by-step guide on how to implement your own topology rendering using our inventory rendering as an example.</simpara>
</section>
<section xml:id="_use_case">
<title>Use case</title>
<simpara>For the purpose of this guide we are going to render the following augmented fields from the OpenFlow model:</simpara>
<itemizedlist>
<listitem>
<simpara>from inventory node:</simpara>
<itemizedlist>
<listitem>
<simpara>manufacturer</simpara>
</listitem>
<listitem>
<simpara>hardware</simpara>
</listitem>
<listitem>
<simpara>software</simpara>
</listitem>
<listitem>
<simpara>serial-number</simpara>
</listitem>
<listitem>
<simpara>description</simpara>
</listitem>
<listitem>
<simpara>ip-address</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>from inventory node-connector:</simpara>
<itemizedlist>
<listitem>
<simpara>name</simpara>
</listitem>
<listitem>
<simpara>hardware-address</simpara>
</listitem>
<listitem>
<simpara>current-speed</simpara>
</listitem>
<listitem>
<simpara>maximum-speed</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

<simpara>We also want to preserve the node ID and termination-point ID from opendaylight-topology-inventory model, which is network-topology part of the inventory model.</simpara>
</section>
<section xml:id="_implementation_2">
<title>Implementation</title>
<simpara>There are two ways to implement support for your specific topology rendering:</simpara>
<itemizedlist>
<listitem>
<simpara>add a module to your project that depends on the Topology Processing Framework</simpara>
</listitem>
<listitem>
<simpara>add a module to the Topology Processing Framework itself</simpara>
</listitem>
</itemizedlist>

<simpara>Regardless, a successful implementation must complete all of the following steps.</simpara>
<section xml:id="_step1_target_model_creation">
<title>Step1 - Target Model Creation</title>
<simpara>Because the network-topology node does not have fields to store all desired data, it is necessary to create new model to render this extra data in to. For this guide we created the inventory-rendering model. The picture below shows how data will be rendered and stored.</simpara>
<figure>
<title>Rendering to the inventory-rendering model</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/topoprocessing/Inventory_Rendering_Use_case.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>Inventory Rendering Use case</phrase></textobject>
  </mediaobject>
</figure>

<important>
<simpara>When implementing your version of the topology-rendering model in the Topology Processing Framework, the source file of the model (.yang) must be saved in /topoprocessing-api/src/main/yang folder so corresponding structures can be generated during build and can be accessed from every module through dependencies.</simpara>
</important>

<simpara>When the target model is created you have to add an identifier through which you can set your new model as output model. To do that you have to add another identity item to topology-correlation.yang file. For our inventory-rendering model identity looks like this:</simpara>
<programlisting language="yang" linenumbering="unnumbered">identity inventory-rendering-model {
	description "inventory-rendering.yang";
	base model;
}</programlisting>

<simpara>After that you will be able to set inventory-rendering-model as output model in XML.</simpara>
</section>
<section xml:id="_step2_module_and_feature_creation">
<title>Step2 - Module and Feature Creation</title>
<important>
<simpara>This and following steps are based on the <link linkend="_model_specific_approach">model specific approach</link> in the Topology Processing Framework. We highly recommend that you familiarize yourself with this approach in advance.</simpara>
</important>

<simpara>To create a base module and add it as a feature to Karaf in the Topology Processing, Framework we made the changes in following <link xlink:href="https://git.opendaylight.org/gerrit/#/c/26223/">commit</link>. Changes in other projects will likely be similar.</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">File</entry>
        
        <entry align="left" valign="top">Changes</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>pom.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>add new module to topoprocessing</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>features.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>add feature to topoprocessing</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>features/pom.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>add dependencies needed by features</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>topoprocessing-artifacts/pom.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>add artifact</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>topoprocessing-config/pom.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>add configuration file</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>81-topoprocessing-inventory-rendering-config.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>configuration file for new module</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>topoprocessing-inventory-rendering/pom.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>main pom for new module</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TopoProcessingProviderIR.java</simpara></entry>
        
        <entry align="left" valign="top"><simpara>contains startup method which register new model adapter</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TopoProcessingProviderIRModule.java</simpara></entry>
        
        <entry align="left" valign="top"><simpara>generated class which contains createInstance method. You should call your startup method from here.</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>TopoProcessingProviderIRModuleFactory.java</simpara></entry>
        
        <entry align="left" valign="top"><simpara>generated class. You will probably not need to edit this file</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>log4j.xml</simpara></entry>
        
        <entry align="left" valign="top"><simpara>configuration file for logger
topoprocessing-inventory-rendering-provider-impl.yang</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_step3_module_adapters_creation">
<title>Step3 - Module Adapters Creation</title>
<simpara>There are seven mandatory interfaces or abstract classes that needs to be implemented in each module. They are:</simpara>
<itemizedlist>
<listitem>
<simpara>TopoProcessingProvider - provides module registration</simpara>
</listitem>
<listitem>
<simpara>ModelAdapter - provides model specific instances</simpara>
</listitem>
<listitem>
<simpara>TopologyRequestListener - listens on changes in the configuration datastore</simpara>
</listitem>
<listitem>
<simpara>TopologyRequestHandler - processes configuration datastore changes</simpara>
</listitem>
<listitem>
<simpara>UnderlayTopologyListener - listens for changes in the specific model</simpara>
</listitem>
<listitem>
<simpara>LinkTransaltor and NodeTranslator - used by OverlayItemTranslator to create NormalizedNodes from OverlayItems</simpara>
</listitem>
</itemizedlist>

<simpara>The name convention we used was to add an abbreviation for the specific model to the beginning of implementing class name (e.g. the IRModelAdapter refers to class which implements ModelAdapter in module Inventory Rendering). In the case of the provider class, we put the abbreviation at the end.</simpara>
<important>
<itemizedlist>
<listitem>
<simpara>In the next sections, we use the terms TopologyRequestListener, TopologyRequestHandler, etc. without a prepended or appended abbreviation because the steps apply regardless of which specific model you are targeting.</simpara>
</listitem>
<listitem>
<simpara>If you want to implement rendering from inventory to network-topology, you can just copy-paste our module and additional changes will be required only in the output part.</simpara>
</listitem>
</itemizedlist>

</important>

<simpara><emphasis role="strong">Provider part</emphasis></simpara>
<simpara>This part is the starting point of the whole module. It is responsible for creating and registering TopologyRequestListeners. It is necessary to create three classes which will import:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TopoProcessingProviderModule</emphasis> - is a generated class from topoprocessing-inventory-rendering-provider-impl.yang (created in previous step, file will appear after first build). Its method <literal>createInstance()</literal> is called at the feature start and must be modified to create an instance of TopoProcessingProvider and calli its <literal>startup(TopoProcessingProvider topoProvider)</literal> function.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">TopoProcessingProvider</emphasis> - in <literal>startup(TopoProcessingProvider topoProvider)</literal> function provides ModelAdapter registration to TopoProcessingProviderImpl.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">ModelAdapter</emphasis> - provides creation of corresponding module specific classes.</simpara>
</listitem>
</itemizedlist>

<simpara><emphasis role="strong">Input part</emphasis></simpara>
<simpara>This includes the creation of the classes responsible for input data processing. In this case, we had to create five classes implementing:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TopologyRequestListener</emphasis> and <emphasis role="strong">TopologyRequestHandler</emphasis> - when notified about a change in the configuration datastore, verify if the change contains a topology request (has correlations in it) and creates UnderlayTopologyListeners if needed. The implementation of these classes will differ according to the model in which are correlations saved (network-topology or i2rs). In the case of using network-topology, as the input model, you can use our classes IRTopologyRequestListener and IRTopologyRequestHandler.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">UnderlayTopologyListener</emphasis> - registers underlay listeners according to input model. In our case (listening in the inventory model), we created listeners for the network-topology model and inventory model, and set the NotificationInterConnector as the first operator and set the IRRenderingOperator as the second operator (after NotificationInterConnector). Same as for TopologyRequestListener/Handler, if you are rendering from the inventory model, you can use our class IRUnderlayTopologyListener.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">InventoryListener</emphasis> - a new implementation of this class is required only for inventory input model. This is because the InventoryListener from topoprocessing-impl requires pathIdentifier which is absent in the case of rendering.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">TopologyOperator</emphasis> - replaces classic topoprocessing operator. While the classic operator provides specific operations on topology, the rendering operator just wraps each received UnderlayItem to OverlayItem and sends them to write.</simpara>
</listitem>
</itemizedlist>

<important>
<simpara>For purposes of topology rendering from inventory to network-topology, there are misused fields in UnderlayItem as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>item - contains node from network-topology part of inventory</simpara>
</listitem>
<listitem>
<simpara>leafItem - contains node from inventory</simpara>
</listitem>
</itemizedlist>

<simpara>In case of implementing UnderlayTopologyListener or InventoryListener you have to carefully adjust UnderlayItem creation to these terms.</simpara>
</important>

<simpara><emphasis role="strong">Output part</emphasis></simpara>
<simpara>The output part of topology rendering is responsible for translating received overlay items to normalized nodes. In the case of inventory rendering, this is where node information from inventory are combined with node information from network-topology. This combined information is stored in our inventory-rendering model normalized node and passed to the writer.</simpara>
<simpara>The output part consists of two translators implementing the NodeTranslator and LinkTranslator interfaces.</simpara>
<simpara><emphasis role="strong">NodeTranslator implementation</emphasis> - The NodeTranslator interface has one <literal>translate(OverlayItemWrapper wrapper)</literal> method. For our purposes, there is one important thing in wrapper - the list of OverlayItems which have one or more common UnderlayItems. Regardless of this list, in the case of rendering it will always contains only one OverlayItem. This item has list of UnderlayItems, but again in case of rendering there will be only one UnderlayItem item in this list. In NodeTranslator, the OverlayItem and corresponding UnderlayItem represent nodes from the translating model.</simpara>
<simpara>The UnderlayItem has several attributes. How you will use these attributes in your rendering is up to you, as you create this item in your topology operator. For example, as mentioned above, in our inventory rendering example there is an inventory node normalized node stored in the UnderlayItem leafNode attribute, and we also store node-id from network-topology model in UnderlayItem itemId attribute. You can now use these attributes to build a normalized node for your new model. How to read and create normalized nodes is out of scope of this document.</simpara>
<simpara><emphasis role="strong">LinkTranslator implementation</emphasis> - The LinkTranslator interface also has one <literal>translate(OverlayItemWrapper wrapper)</literal> method. In our inventory rendering this method returns <literal>null</literal>, because the inventory model doesn&#8217;t have links. But if you also need links, this is the place where you should translate it into a normalized node for your model. In LinkTranslator, the OverlayItem and corresponding UnderlayItem represent links from the translating model. As in NodeTranslator, there will be only one OverlayItem and one UnderlayItem in the corresponding lists.</simpara>
</section>
</section>
<section xml:id="_testing">
<title>Testing</title>
<simpara>If you want to test our implementation you must apply <link xlink:href="https://git.opendaylight.org/gerrit/#/c/26612">this patch</link>. It adds an OpenFlow Plugin dependency so we can use it in the Karaf distribution as a feature. After adding patch and building the whole framework, you can start Karaf. Next, you have to install necessary features. In our case it is:</simpara>
<simpara><literal>feature:install odl-restconf-noauth odl-topoprocessing-inventory-rendering odl-openflowplugin-southbound-li odl-openflowplugin-nsf-model-li</literal></simpara>
<simpara>Now you can send messages to REST from any REST client (e.g. Postman in Chrome). Messages have to have following headers:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Header</entry>
        
        <entry align="left" valign="top">Value</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Content-Type:</simpara></entry>
        
        <entry align="left" valign="top"><simpara>application/xml</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>Accept:</simpara></entry>
        
        <entry align="left" valign="top"><simpara>application/xml</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>username:</simpara></entry>
        
        <entry align="left" valign="top"><simpara>admin</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>password:</simpara></entry>
        
        <entry align="left" valign="top"><simpara>admin</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>Firstly send topology request to <link xlink:href="http://localhost:8181/restconf/config/network-topology:network-topology/topology/render:1">http://localhost:8181/restconf/config/network-topology:network-topology/topology/render:1</link> with method PUT. Example of simple rendering request:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;topology xmlns="urn:TBD:params:xml:ns:yang:network-topology"&gt;
  &lt;topology-id&gt;render:1&lt;/topology-id&gt;
    &lt;correlations xmlns="urn:opendaylight:topology:correlation" &gt;
      &lt;output-model&gt;inventory-rendering-model&lt;/output-model&gt;
      &lt;correlation&gt;
         &lt;correlation-id&gt;1&lt;/correlation-id&gt;
          &lt;type&gt;rendering-only&lt;/type&gt;
          &lt;correlation-item&gt;node&lt;/correlation-item&gt;
          &lt;rendering&gt;
            &lt;underlay-topology&gt;und-topo:1&lt;/underlay-topology&gt;
        &lt;/rendering&gt;
      &lt;/correlation&gt;
    &lt;/correlations&gt;
&lt;/topology&gt;</programlisting>

<simpara>This request says that we want create topology with name render:1 and this topology should be stored in the inventory-rendering-model and it should be created from topology flow:1 by node rendering.</simpara>
<simpara>Next we send the network-topology part of topology flow:1. So to the URL <link xlink:href="http://localhost:8181/restconf/config/network-topology:network-topology/topology/und-topo:1">http://localhost:8181/restconf/config/network-topology:network-topology/topology/und-topo:1</link> we PUT:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;topology xmlns="urn:TBD:params:xml:ns:yang:network-topology"
          xmlns:it="urn:opendaylight:model:topology:inventory"
          xmlns:i="urn:opendaylight:inventory"&gt;
    &lt;topology-id&gt;und-topo:1&lt;/topology-id&gt;
    &lt;node&gt;
        &lt;node-id&gt;openflow:1&lt;/node-id&gt;
        &lt;it:inventory-node-ref&gt;
  	/i:nodes/i:node[i:id="openflow:1"]
        &lt;/it:inventory-node-ref&gt;
        &lt;termination-point&gt;
            &lt;tp-id&gt;tp:1&lt;/tp-id&gt;
            &lt;it:inventory-node-connector-ref&gt;
                /i:nodes/i:node[i:id="openflow:1"]/i:node-connector[i:id="openflow:1:1"]
            &lt;/it:inventory-node-connector-ref&gt;
        &lt;/termination-point&gt;
    &lt;/node&gt;
&lt;/topology&gt;</programlisting>

<simpara>And the last input will be inventory part of topology. To the URL <link xlink:href="http://localhost:8181/restconf/config/opendaylight-inventory:nodes">http://localhost:8181/restconf/config/opendaylight-inventory:nodes</link> we PUT:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;nodes
    xmlns="urn:opendaylight:inventory"&gt;
    &lt;node&gt;
        &lt;id&gt;openflow:1&lt;/id&gt;
        &lt;node-connector&gt;
            &lt;id&gt;openflow:1:1&lt;/id&gt;
            &lt;port-number
                xmlns="urn:opendaylight:flow:inventory"&gt;1
            &lt;/port-number&gt;
            &lt;current-speed
                xmlns="urn:opendaylight:flow:inventory"&gt;10000000
            &lt;/current-speed&gt;
            &lt;name
                xmlns="urn:opendaylight:flow:inventory"&gt;s1-eth1
            &lt;/name&gt;
            &lt;supported
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/supported&gt;
            &lt;current-feature
                xmlns="urn:opendaylight:flow:inventory"&gt;copper ten-gb-fd
            &lt;/current-feature&gt;
            &lt;configuration
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/configuration&gt;
            &lt;peer-features
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/peer-features&gt;
            &lt;maximum-speed
                xmlns="urn:opendaylight:flow:inventory"&gt;0
            &lt;/maximum-speed&gt;
            &lt;advertised-features
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/advertised-features&gt;
            &lt;hardware-address
                xmlns="urn:opendaylight:flow:inventory"&gt;0E:DC:8C:63:EC:D1
            &lt;/hardware-address&gt;
            &lt;state
                xmlns="urn:opendaylight:flow:inventory"&gt;
                &lt;link-down&gt;false&lt;/link-down&gt;
                &lt;blocked&gt;false&lt;/blocked&gt;
                &lt;live&gt;false&lt;/live&gt;
            &lt;/state&gt;
            &lt;flow-capable-node-connector-statistics
                xmlns="urn:opendaylight:port:statistics"&gt;
                &lt;receive-errors&gt;0&lt;/receive-errors&gt;
                &lt;receive-frame-error&gt;0&lt;/receive-frame-error&gt;
                &lt;receive-over-run-error&gt;0&lt;/receive-over-run-error&gt;
                &lt;receive-crc-error&gt;0&lt;/receive-crc-error&gt;
                &lt;bytes&gt;
                    &lt;transmitted&gt;595&lt;/transmitted&gt;
                    &lt;received&gt;378&lt;/received&gt;
                &lt;/bytes&gt;
                &lt;receive-drops&gt;0&lt;/receive-drops&gt;
                &lt;duration&gt;
                    &lt;second&gt;28&lt;/second&gt;
                    &lt;nanosecond&gt;410000000&lt;/nanosecond&gt;
                &lt;/duration&gt;
                &lt;transmit-errors&gt;0&lt;/transmit-errors&gt;
                &lt;collision-count&gt;0&lt;/collision-count&gt;
                &lt;packets&gt;
                    &lt;transmitted&gt;7&lt;/transmitted&gt;
                    &lt;received&gt;5&lt;/received&gt;
                &lt;/packets&gt;
                &lt;transmit-drops&gt;0&lt;/transmit-drops&gt;
            &lt;/flow-capable-node-connector-statistics&gt;
        &lt;/node-connector&gt;
        &lt;node-connector&gt;
            &lt;id&gt;openflow:1:LOCAL&lt;/id&gt;
            &lt;port-number
                xmlns="urn:opendaylight:flow:inventory"&gt;4294967294
            &lt;/port-number&gt;
            &lt;current-speed
                xmlns="urn:opendaylight:flow:inventory"&gt;0
            &lt;/current-speed&gt;
            &lt;name
                xmlns="urn:opendaylight:flow:inventory"&gt;s1
            &lt;/name&gt;
            &lt;supported
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/supported&gt;
            &lt;current-feature
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/current-feature&gt;
            &lt;configuration
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/configuration&gt;
            &lt;peer-features
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/peer-features&gt;
            &lt;maximum-speed
                xmlns="urn:opendaylight:flow:inventory"&gt;0
            &lt;/maximum-speed&gt;
            &lt;advertised-features
                xmlns="urn:opendaylight:flow:inventory"&gt;
            &lt;/advertised-features&gt;
            &lt;hardware-address
                xmlns="urn:opendaylight:flow:inventory"&gt;BA:63:87:0C:76:41
            &lt;/hardware-address&gt;
            &lt;state
                xmlns="urn:opendaylight:flow:inventory"&gt;
                &lt;link-down&gt;false&lt;/link-down&gt;
                &lt;blocked&gt;false&lt;/blocked&gt;
                &lt;live&gt;false&lt;/live&gt;
            &lt;/state&gt;
            &lt;flow-capable-node-connector-statistics
                xmlns="urn:opendaylight:port:statistics"&gt;
                &lt;receive-errors&gt;0&lt;/receive-errors&gt;
                &lt;receive-frame-error&gt;0&lt;/receive-frame-error&gt;
                &lt;receive-over-run-error&gt;0&lt;/receive-over-run-error&gt;
                &lt;receive-crc-error&gt;0&lt;/receive-crc-error&gt;
                &lt;bytes&gt;
                    &lt;transmitted&gt;576&lt;/transmitted&gt;
                    &lt;received&gt;468&lt;/received&gt;
                &lt;/bytes&gt;
                &lt;receive-drops&gt;0&lt;/receive-drops&gt;
                &lt;duration&gt;
                    &lt;second&gt;28&lt;/second&gt;
                    &lt;nanosecond&gt;426000000&lt;/nanosecond&gt;
                &lt;/duration&gt;
                &lt;transmit-errors&gt;0&lt;/transmit-errors&gt;
                &lt;collision-count&gt;0&lt;/collision-count&gt;
                &lt;packets&gt;
                    &lt;transmitted&gt;6&lt;/transmitted&gt;
                    &lt;received&gt;6&lt;/received&gt;
                &lt;/packets&gt;
                &lt;transmit-drops&gt;0&lt;/transmit-drops&gt;
            &lt;/flow-capable-node-connector-statistics&gt;
        &lt;/node-connector&gt;
        &lt;serial-number
            xmlns="urn:opendaylight:flow:inventory"&gt;None
        &lt;/serial-number&gt;
        &lt;manufacturer
            xmlns="urn:opendaylight:flow:inventory"&gt;Nicira, Inc.
        &lt;/manufacturer&gt;
        &lt;hardware
            xmlns="urn:opendaylight:flow:inventory"&gt;Open vSwitch
        &lt;/hardware&gt;
        &lt;software
            xmlns="urn:opendaylight:flow:inventory"&gt;2.1.3
        &lt;/software&gt;
        &lt;description
            xmlns="urn:opendaylight:flow:inventory"&gt;None
        &lt;/description&gt;
		&lt;ip-address
			xmlns="urn:opendaylight:flow:inventory"&gt;10.20.30.40
      &lt;/ip-address&gt;
        &lt;meter-features
            xmlns="urn:opendaylight:meter:statistics"&gt;
            &lt;max_bands&gt;0&lt;/max_bands&gt;
            &lt;max_color&gt;0&lt;/max_color&gt;
            &lt;max_meter&gt;0&lt;/max_meter&gt;
        &lt;/meter-features&gt;
        &lt;group-features
            xmlns="urn:opendaylight:group:statistics"&gt;
            &lt;group-capabilities-supported
                xmlns:x="urn:opendaylight:group:types"&gt;x:chaining
            &lt;/group-capabilities-supported&gt;
            &lt;group-capabilities-supported
                xmlns:x="urn:opendaylight:group:types"&gt;x:select-weight
            &lt;/group-capabilities-supported&gt;
            &lt;group-capabilities-supported
                xmlns:x="urn:opendaylight:group:types"&gt;x:select-liveness
            &lt;/group-capabilities-supported&gt;
            &lt;max-groups&gt;4294967040&lt;/max-groups&gt;
            &lt;actions&gt;67082241&lt;/actions&gt;
            &lt;actions&gt;0&lt;/actions&gt;
        &lt;/group-features&gt;
    &lt;/node&gt;
&lt;/nodes&gt;</programlisting>

<simpara>After this, the expected result from a GET request to <link xlink:href="http://127.0.0.1:8181/restconf/operational/network-topology:network-topology">http://127.0.0.1:8181/restconf/operational/network-topology:network-topology</link> is:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;network-topology
    xmlns="urn:TBD:params:xml:ns:yang:network-topology"&gt;
    &lt;topology&gt;
        &lt;topology-id&gt;render:1&lt;/topology-id&gt;
        &lt;node&gt;
            &lt;node-id&gt;openflow:1&lt;/node-id&gt;
            &lt;node-augmentation
                xmlns="urn:opendaylight:topology:inventory:rendering"&gt;
                &lt;ip-address&gt;10.20.30.40&lt;/ip-address&gt;
                &lt;serial-number&gt;None&lt;/serial-number&gt;
                &lt;manufacturer&gt;Nicira, Inc.&lt;/manufacturer&gt;
                &lt;description&gt;None&lt;/description&gt;
                &lt;hardware&gt;Open vSwitch&lt;/hardware&gt;
                &lt;software&gt;2.1.3&lt;/software&gt;
            &lt;/node-augmentation&gt;
            &lt;termination-point&gt;
                &lt;tp-id&gt;openflow:1:1&lt;/tp-id&gt;
                &lt;tp-augmentation
                    xmlns="urn:opendaylight:topology:inventory:rendering"&gt;
                    &lt;hardware-address&gt;0E:DC:8C:63:EC:D1&lt;/hardware-address&gt;
                    &lt;current-speed&gt;10000000&lt;/current-speed&gt;
                    &lt;maximum-speed&gt;0&lt;/maximum-speed&gt;
                    &lt;name&gt;s1-eth1&lt;/name&gt;
                &lt;/tp-augmentation&gt;
            &lt;/termination-point&gt;
            &lt;termination-point&gt;
                &lt;tp-id&gt;openflow:1:LOCAL&lt;/tp-id&gt;
                &lt;tp-augmentation
                    xmlns="urn:opendaylight:topology:inventory:rendering"&gt;
                    &lt;hardware-address&gt;BA:63:87:0C:76:41&lt;/hardware-address&gt;
                    &lt;current-speed&gt;0&lt;/current-speed&gt;
                    &lt;maximum-speed&gt;0&lt;/maximum-speed&gt;
                    &lt;name&gt;s1&lt;/name&gt;
                &lt;/tp-augmentation&gt;
            &lt;/termination-point&gt;
        &lt;/node&gt;
    &lt;/topology&gt;
&lt;/network-topology&gt;</programlisting>

</section>
</section>
<section xml:id="_key_apis_and_interfaces_17">
<title>Key APIs and Interfaces</title>
<simpara>The basic provider class is TopoProcessingProvider which provides startup and shutdown
methods. Otherwise, the framework communicates via requests and outputs stored
in the MD-SAL datastores.</simpara>
</section>
<section xml:id="_api_reference_documentation_15">
<title>API Reference Documentation</title>
<simpara>You can find API examples on <link xlink:href="https://wiki.opendaylight.org/view/Topology_Processing_Framework:Developer_Guide:End_to_End_Example">this wiki page</link>.</simpara>
</section>
</chapter>
<chapter xml:id="_ttp_model_developer_guide">
<title>TTP Model Developer Guide</title>
<section xml:id="_overview_33">
<title>Overview</title>
<simpara>Table Type Patterns are a specification developed by the
<link xlink:href="https://www.opennetworking.org/">Open Networking Foundation</link> to enable
the description and negotiation of subsets of the OpenFlow protocol.
This is particularly useful for hardware switches that support OpenFlow
as it enables the to describe what features they do (and thus also what
features they do not) support. More details can be found in the full
specification listed on the
<link xlink:href="https://www.opennetworking.org/sdn-resources/onf-specifications/openflow">OpenFlow
specifications page</link>.</simpara>
</section>
<section xml:id="_ttp_model_architecture">
<title>TTP Model Architecture</title>
<simpara>The TTP Model provides a YANG-modeled type for a TTP and allows them
to be associated with a master list of known TTPs, as well as active
and supported TTPs with nodes in the MD-SAL inventory model.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_18">
<title>Key APIs and Interfaces</title>
<simpara>The key API provided by the TTP Model feature is the ability to store
a set of TTPs in the MD-SAL as well as associate zero or one active
TTPs and zero or more supported TTPs along with a given node in the
MD-SAL inventory model.</simpara>
</section>
<section xml:id="_api_reference_documentation_16">
<title>API Reference Documentation</title>
<section xml:id="_restconf">
<title>RESTCONF</title>
<simpara>See the generated RESTCONF API documentation at:
<link xlink:href="http://localhost:8181/apidoc/explorer/index.html">http://localhost:8181/apidoc/explorer/index.html</link></simpara>
<simpara>Look for the onf-ttp module to expand and see the various RESTCONF
APIs.</simpara>
</section>
<section xml:id="_java_bindings">
<title>Java Bindings</title>
<simpara>As stated above there are 3 locations where a Table Type Pattern can be
placed into the MD-SAL Data Store. They correspond to 3 different REST
API URIs:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara><literal>restconf/config/onf-ttp:opendaylight-ttps/onf-ttp:table-type-patterns/</literal></simpara>
</listitem>
<listitem>
<simpara><literal>restconf/config/opendaylight-inventory:nodes/node/{id}/ttp-inventory-node:active_ttp/</literal></simpara>
</listitem>
<listitem>
<simpara><literal>restconf/config/opendaylight-inventory:nodes/node/{id}/ttp-inventory-node:supported_ttps/</literal></simpara>
</listitem>
</orderedlist>

<note>
<simpara>Typically, these URIs are running on the machine the controller is on
at port 8181. If you are on the same machine they can thus be accessed
at <literal><link xlink:href="http://localhost:8181/&lt;uri&gt;">http://localhost:8181/&lt;uri&gt;</link></literal></simpara>
</note>

</section>
</section>
<section xml:id="_using_the_ttp_model_restconf_apis">
<title>Using the TTP Model RESTCONF APIs</title>
<section xml:id="_setting_rest_http_headers">
<title>Setting REST HTTP Headers</title>
<section xml:id="_authentication">
<title>Authentication</title>
<simpara>The REST API calls require authentication by default. The default
method is to use basic auth with a user name and password of &#8216;admin&#8217;.</simpara>
</section>
<section xml:id="_content_type_and_accept">
<title>Content-Type and Accept</title>
<simpara>RESTCONF supports both xml and json. This example focuses on JSON, but
xml can be used just as easily. When doing a PUT or POST be sure to
specify the appropriate <literal>Conetnt-Type</literal> header: either
<literal>application/json</literal> or <literal>application/xml</literal>.</simpara>
<simpara>When doing a GET be sure to specify the appropriate <literal>Accept</literal> header:
again, either <literal>application/json</literal> or <literal>application/xml</literal>.</simpara>
</section>
</section>
<section xml:id="_content">
<title>Content</title>
<simpara>The contents of a PUT or POST should be a OpenDaylight Table Type
Pattern. An example of one is provided below. The example can also be
found at <link xlink:href="https://git.opendaylight.org/gerrit/gitweb?p=ttp.git;a=blob;f=parser/sample-TTP-from-tests.ttp;h=45130949b25c6f86b750959d27d04ec2208935fb;hb=HEAD"><literal>parser/sample-TTP-from-tests.ttp</literal> in the TTP git repository</link>.</simpara>
<formalpara>
<title>Sample Table Type Pattern (json)</title>
<para>
<screen>{
    "table-type-patterns": {
        "table-type-pattern": [
            {
                "security": {
                    "doc": [
                        "This TTP is not published for use by ONF. It is an example and for",
                        "illustrative purposes only.",
                        "If this TTP were published for use it would include",
                        "guidance as to any security considerations in this doc member."
                    ]
                },
                "NDM_metadata": {
                    "authority": "org.opennetworking.fawg",
                    "OF_protocol_version": "1.3.3",
                    "version": "1.0.0",
                    "type": "TTPv1",
                    "doc": [
                        "Example of a TTP supporting L2 (unicast, multicast, flooding), L3 (unicast only),",
                        "and an ACL table."
                    ],
                    "name": "L2-L3-ACLs"
                },
                "identifiers": [
                    {
                        "doc": [
                            "The VLAN ID of a locally attached L2 subnet on a Router."
                        ],
                        "var": "&lt;subnet_VID&gt;"
                    },
                    {
                        "doc": [
                            "An OpenFlow group identifier (integer) identifying a group table entry",
                            "of the type indicated by the variable name"
                        ],
                        "var": "&lt;&lt;group_entry_types/name&gt;&gt;"
                    }
                ],
                "features": [
                    {
                        "doc": [
                            "Flow entry notification Extension – notification of changes in flow entries"
                        ],
                        "feature": "ext187"
                    },
                    {
                        "doc": [
                            "Group notifications Extension – notification of changes in group or meter entries"
                        ],
                        "feature": "ext235"
                    }
                ],
                "meter_table": {
                    "meter_types": [
                        {
                            "name": "ControllerMeterType",
                            "bands": [
                                {
                                    "type": "DROP",
                                    "rate": "1000..10000",
                                    "burst": "50..200"
                                }
                            ]
                        },
                        {
                            "name": "TrafficMeter",
                            "bands": [
                                {
                                    "type": "DSCP_REMARK",
                                    "rate": "10000..500000",
                                    "burst": "50..500"
                                },
                                {
                                    "type": "DROP",
                                    "rate": "10000..500000",
                                    "burst": "50..500"
                                }
                            ]
                        }
                    ],
                    "built_in_meters": [
                        {
                            "name": "ControllerMeter",
                            "meter_id": 1,
                            "type": "ControllerMeterType",
                            "bands": [
                                {
                                    "rate": 2000,
                                    "burst": 75
                                }
                            ]
                        },
                        {
                            "name": "AllArpMeter",
                            "meter_id": 2,
                            "type": "ControllerMeterType",
                            "bands": [
                                {
                                    "rate": 1000,
                                    "burst": 50
                                }
                            ]
                        }
                    ]
                },
                "table_map": [
                    {
                        "name": "ControlFrame",
                        "number": 0
                    },
                    {
                        "name": "IngressVLAN",
                        "number": 10
                    },
                    {
                        "name": "MacLearning",
                        "number": 20
                    },
                    {
                        "name": "ACL",
                        "number": 30
                    },
                    {
                        "name": "L2",
                        "number": 40
                    },
                    {
                        "name": "ProtoFilter",
                        "number": 50
                    },
                    {
                        "name": "IPv4",
                        "number": 60
                    },
                    {
                        "name": "IPv6",
                        "number": 80
                    }
                ],
                "parameters": [
                    {
                        "doc": [
                            "documentation"
                        ],
                        "name": "Showing-curt-how-this-works",
                        "type": "type1"
                    }
                ],
                "flow_tables": [
                    {
                        "doc": [
                            "Filters L2 control reserved destination addresses and",
                            "may forward control packets to the controller.",
                            "Directs all other packets to the Ingress VLAN table."
                        ],
                        "name": "ControlFrame",
                        "flow_mod_types": [
                            {
                                "doc": [
                                    "This match/action pair allows for flow_mods that match on either",
                                    "ETH_TYPE or ETH_DST (or both) and send the packet to the",
                                    "controller, subject to metering."
                                ],
                                "name": "Frame-To-Controller",
                                "match_set": [
                                    {
                                        "field": "ETH_TYPE",
                                        "match_type": "all_or_exact"
                                    },
                                    {
                                        "field": "ETH_DST",
                                        "match_type": "exact"
                                    }
                                ],
                                "instruction_set": [
                                    {
                                        "doc": [
                                            "This meter may be used to limit the rate of PACKET_IN frames",
                                            "sent to the controller"
                                        ],
                                        "instruction": "METER",
                                        "meter_name": "ControllerMeter"
                                    },
                                    {
                                        "instruction": "APPLY_ACTIONS",
                                        "actions": [
                                            {
                                                "action": "OUTPUT",
                                                "port": "CONTROLLER"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ],
                        "built_in_flow_mods": [
                            {
                                "doc": [
                                    "Mandatory filtering of control frames with C-VLAN Bridge reserved DA."
                                ],
                                "name": "Control-Frame-Filter",
                                "priority": "1",
                                "match_set": [
                                    {
                                        "field": "ETH_DST",
                                        "mask": "0xfffffffffff0",
                                        "value": "0x0180C2000000"
                                    }
                                ]
                            },
                            {
                                "doc": [
                                    "Mandatory miss flow_mod, sends packets to IngressVLAN table."
                                ],
                                "name": "Non-Control-Frame",
                                "priority": "0",
                                "instruction_set": [
                                    {
                                        "instruction": "GOTO_TABLE",
                                        "table": "IngressVLAN"
                                    }
                                ]
                            }
                        ]
                    }
                ],
                "group_entry_types": [
                    {
                        "doc": [
                            "Output to a port, removing VLAN tag if needed.",
                            "Entry per port, plus entry per untagged VID per port."
                        ],
                        "name": "EgressPort",
                        "group_type": "INDIRECT",
                        "bucket_types": [
                            {
                                "name": "OutputTagged",
                                "action_set": [
                                    {
                                        "action": "OUTPUT",
                                        "port": "&lt;port_no&gt;"
                                    }
                                ]
                            },
                            {
                                "name": "OutputUntagged",
                                "action_set": [
                                    {
                                        "action": "POP_VLAN"
                                    },
                                    {
                                        "action": "OUTPUT",
                                        "port": "&lt;port_no&gt;"
                                    }
                                ]
                            },
                            {
                                "opt_tag": "VID-X",
                                "name": "OutputVIDTranslate",
                                "action_set": [
                                    {
                                        "action": "SET_FIELD",
                                        "field": "VLAN_VID",
                                        "value": "&lt;local_vid&gt;"
                                    },
                                    {
                                        "action": "OUTPUT",
                                        "port": "&lt;port_no&gt;"
                                    }
                                ]
                            }
                        ]
                    }
                ],
                "flow_paths": [
                    {
                        "doc": [
                            "This object contains just a few examples of flow paths, it is not",
                            "a comprehensive list of the flow paths required for this TTP.  It is",
                            "intended that the flow paths array could include either a list of",
                            "required flow paths or a list of specific flow paths that are not",
                            "required (whichever is more concise or more useful."
                        ],
                        "name": "L2-2",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACLskip",
                            "L2-Unicast",
                            "EgressPort"
                        ]
                    },
                    {
                        "name": "L2-3",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACLskip",
                            "L2-Multicast",
                            "L2Mcast",
                            "[EgressPort]"
                        ]
                    },
                    {
                        "name": "L2-4",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACL-skip",
                            "VID-flood",
                            "VIDflood",
                            "[EgressPort]"
                        ]
                    },
                    {
                        "name": "L2-5",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACLskip",
                            "L2-Drop"
                        ]
                    },
                    {
                        "name": "v4-1",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACLskip",
                            "L2-Router-MAC",
                            "IPv4",
                            "v4-Unicast",
                            "NextHop",
                            "EgressPort"
                        ]
                    },
                    {
                        "name": "v4-2",
                        "path": [
                            "Non-Control-Frame",
                            "IV-pass",
                            "Known-MAC",
                            "ACLskip",
                            "L2-Router-MAC",
                            "IPv4",
                            "v4-Unicast-ECMP",
                            "L3ECMP",
                            "NextHop",
                            "EgressPort"
                        ]
                    }
                ]
            }
        ]
    }
}</screen>
</para>
</formalpara>

</section>
<section xml:id="_making_a_rest_call">
<title>Making a REST Call</title>
<simpara>In this example we&#8217;ll do a PUT to install the sample TTP from above
into OpenDaylight and then retrieve it both as json and as xml. We&#8217;ll
use the <link xlink:href="https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm">
Postman - REST Client</link> for Chrome in the examples, but any method of
accessing REST should work.</simpara>
<simpara>First, we&#8217;ll fill in the basic information:</simpara>
<figure>
<title>Filling in URL, content, Content-Type and basic auth</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ttp-screen1-basic-auth.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ttp screen1 basic auth</phrase></textobject>
  </mediaobject>
</figure>

<orderedlist numeration="arabic">
<listitem>
<simpara>Set the URL to <literal><link xlink:href="http://localhost:8181/restconf/config/onf-ttp:opendaylight-ttps/onf-ttp:table-type-patterns/">http://localhost:8181/restconf/config/onf-ttp:opendaylight-ttps/onf-ttp:table-type-patterns/</link></literal></simpara>
</listitem>
<listitem>
<simpara>Set the action to <literal>PUT</literal></simpara>
</listitem>
<listitem>
<simpara>Click Headers and</simpara>
</listitem>
<listitem>
<simpara>Set a header for <literal>Content-Type</literal> to <literal>application/json</literal></simpara>
</listitem>
<listitem>
<simpara>Make sure the content is set to raw and</simpara>
</listitem>
<listitem>
<simpara>Copy the sample TTP from above into the content</simpara>
</listitem>
<listitem>
<simpara>Click the Basic Auth tab and</simpara>
</listitem>
<listitem>
<simpara>Set the username and password to admin</simpara>
</listitem>
<listitem>
<simpara>Click Refresh headers</simpara>
</listitem>
</orderedlist>

<figure>
<title>Refreshing basic auth headers</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ttp-screen2-applied-basic-auth.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ttp screen2 applied basic auth</phrase></textobject>
  </mediaobject>
</figure>

<simpara>After clicking Refresh headers, we can see that a new header
(<literal>Authorization</literal>) has been created and this will allow us to
authenticate to make the REST call.</simpara>
<figure>
<title>PUTting a TTP</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ttp-screen3-sent-put.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ttp screen3 sent put</phrase></textobject>
  </mediaobject>
</figure>

<simpara>At this point, clicking send should result in a Status response of <literal>200
OK</literal> indicating we&#8217;ve successfully PUT the TTP into OpenDaylight.</simpara>
<figure>
<title>Retrieving the TTP as json via a GET</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ttp-screen4-get-json.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ttp screen4 get json</phrase></textobject>
  </mediaobject>
</figure>

<simpara>We can now retrieve the TTP by:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Changing the action to <literal>GET</literal></simpara>
</listitem>
<listitem>
<simpara>Setting an <literal>Accept</literal> header to <literal>application/json</literal> and</simpara>
</listitem>
<listitem>
<simpara>Pressing send</simpara>
</listitem>
</orderedlist>

<figure>
<title>Retrieving the TTP as xml via a GET</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/ttp-screen5-get-xml.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>ttp screen5 get xml</phrase></textobject>
  </mediaobject>
</figure>

<simpara>The same process can retrieve the content as xml by setting the
<literal>Accept</literal> header to <literal>application/xml</literal>.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="_ttp_cli_tools_developer_guide">
<title>TTP CLI Tools Developer Guide</title>
<section xml:id="_overview_34">
<title>Overview</title>
<simpara>Table Type Patterns are a specification developed by the
<link xlink:href="https://www.opennetworking.org/">Open Networking Foundation</link> to enable
the description and negotiation of subsets of the OpenFlow protocol.
This is particularly useful for hardware switches that support OpenFlow
as it enables the to describe what features they do (and thus also what
features they do not) support. More details can be found in the full
specification listed on the
<link xlink:href="https://www.opennetworking.org/sdn-resources/onf-specifications/openflow">OpenFlow
specifications page</link>.</simpara>
<simpara>The TTP CLI Tools provide a way for people interested in TTPs to read
in, validate, output, and manipulate TTPs as a self-contained,
executable jar file.</simpara>
</section>
<section xml:id="_ttp_cli_tools_architecture">
<title>TTP CLI Tools Architecture</title>
<simpara>The TTP CLI Tools use the TTP Model and the YANG Tools/RESTCONF codecs
to translate between the Data Transfer Objects (DTOs) and JSON/XML.</simpara>
</section>
<section xml:id="_command_line_options">
<title>Command Line Options</title>
<simpara>This will cover the various options for the CLI Tools. For now, there
are no options and it merely outputs fixed data using the codecs.</simpara>
</section>
</chapter>
<chapter xml:id="_unified_secure_channel">
<title>Unified Secure Channel</title>
<section xml:id="_overview_35">
<title>Overview</title>
<simpara>The Unified Secure Channel (USC) feature provides REST API, manager, and plugin for unified
secure channels.  The REST API provides a northbound api.  The manager
monitors, maintains, and provides channel related services.  The plugin
handles the lifecycle of channels.</simpara>
</section>
<section xml:id="_usc_channel_architecture">
<title>USC Channel Architecture</title>
<itemizedlist>
<listitem>
<simpara>USC Agent</simpara>
<itemizedlist>
<listitem>
<simpara>The USC Agent provides proxy and agent functionality on top of all standard protocols supported by the device.  It initiates call-home with the controller, maintains live connections with with the controller, acts as a demuxer/muxer for packets with the USC header, and authenticates the controller.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>USC Plugin</simpara>
<itemizedlist>
<listitem>
<simpara>The USC Plugin is responsible for communication between the controller and the USC agent .  It responds to call-home with the controller, maintains live connections with the devices, acts as a muxer/demuxer for packets with the USC header, and provides support for TLS/DTLS.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>USC Manager</simpara>
<itemizedlist>
<listitem>
<simpara>The USC Manager handles configurations, high availability, security, monitoring, and clustering support for USC.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>USC UI</simpara>
<itemizedlist>
<listitem>
<simpara>The USC UI is responsible for displaying a graphical user interface representing the state of USC in the OpenDaylight DLUX UI.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_usc_channel_apis_and_interfaces">
<title>USC Channel APIs and Interfaces</title>
<simpara>This section describes the APIs for interacting with the unified secure
channels.</simpara>
<section xml:id="_usc_channel_topology_api">
<title>USC Channel Topology API</title>
<simpara>The USC project maintains a topology that is YANG-based in MD-SAL.  These models are available via RESTCONF.</simpara>
<itemizedlist>
<listitem>
<simpara>Name: view-channel</simpara>
</listitem>
<listitem>
<simpara>URL: <link xlink:href="http://${ipaddress}:8181/restconf/operations/usc-channel:view-channel">http://${ipaddress}:8181/restconf/operations/usc-channel:view-channel</link></simpara>
</listitem>
<listitem>
<simpara>Description: Views the current state of the USC environment.</simpara>
</listitem>
</itemizedlist>

</section>
</section>
<section xml:id="_api_reference_documentation_17">
<title>API Reference Documentation</title>
<simpara>Go to <link xlink:href="http://${ipaddress}:8181/apidoc/explorer/index.html">http://${ipaddress}:8181/apidoc/explorer/index.html</link>, sign in, and expand the usc-channel panel.  From there, users can execute various API calls to test their USC deployment.</simpara>
</section>
</chapter>
<chapter xml:id="_virtual_tenant_network_vtn">
<title>Virtual Tenant Network (VTN)</title>
<section xml:id="_opendaylight_virtual_tenant_network_vtn_overview">
<title>OpenDaylight Virtual Tenant Network (VTN) Overview</title>
<simpara>OpenDaylight Virtual Tenant Network (VTN) is an application that provides multi-tenant virtual network on an SDN controller.</simpara>
<simpara>Conventionally, huge investment in the network systems and operating expenses are needed because the network is configured as a silo for each department and system. Therefore various network appliances must be installed for each tenant and those boxes cannot be shared with others. It is a heavy work to design, implement and operate the entire complex network.</simpara>
<simpara>The uniqueness of VTN is a logical abstraction plane. This enables the complete separation of logical plane from physical plane. Users can design and deploy any desired network without knowing the physical network topology or bandwidth restrictions.</simpara>
<simpara>VTN allows the users to define the network with a look and feel of conventional L2/L3 network. Once the network is designed on VTN, it will automatically be mapped into underlying physical network, and then configured on the individual switch leverage SDN control protocol. The definition of logical plane makes it possible not only to hide the complexity of the underlying network but also to better manage network resources. It achieves reducing reconfiguration time of network services and minimizing network configuration errors. OpenDaylight Virtual Tenant Network (VTN) is an application that provides multi-tenant virtual network on an SDN controller. It provides API for creating a common virtual network irrespective of the physical network.</simpara>
<figure>
<title>VTN Architecture</title>
  <mediaobject>
    <imageobject>
      <imagedata fileref="./images/vtn/vtn-overview.png" contentwidth="500"/>
    </imageobject>
    <textobject><phrase>vtn overview</phrase></textobject>
  </mediaobject>
</figure>

<simpara>It is implemented as two major components</simpara>
<itemizedlist>
<listitem>
<simpara><link linkend="_vtn_manager">VTN Manager</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="_vtn_coordinator">VTN Coordinator</link></simpara>
</listitem>
</itemizedlist>

<section xml:id="_vtn_manager">
<title>VTN Manager</title>
<simpara>An OpenDaylight Plugin that interacts with other modules to implement the components of the VTN model. It also provides a REST interface to configure VTN components in OpenDaylight. VTN Manager is implemented as one plugin to the OpenDaylight. This provides a REST interface to create/update/delete VTN components. The user command in VTN Coordinator is translated as REST API to VTN Manager by the OpenDaylight Driver component. In addition to the above mentioned role, it also provides an implementation to the OpenStack L2 Network Functions API.</simpara>
<section xml:id="_function_outline">
<title>Function Outline</title>
<simpara>The table identifies the functions and the interface used by VTN Components:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="3">
    
    <colspec colname="col_1" colwidth="33*"/>
    
    <colspec colname="col_2" colwidth="33*"/>
    
    <colspec colname="col_3" colwidth="33*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Component</entry>
        
        <entry align="left" valign="top">Interface</entry>
        
        <entry align="left" valign="top">Purpose</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>VTN Manager</simpara></entry>
        
        <entry align="left" valign="top"><simpara>RESTful API</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Configure VTN Virtualization model components in OpenDaylight</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>VTN Manager</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Neutron API implementation</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Handle Networks API from OpenStack (Neutron Interface)</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>VTN Coordinator</simpara></entry>
        
        <entry align="left" valign="top"><simpara>RESTful API</simpara></entry>
        
        <entry align="left" valign="top"><simpara>(1) Uses the RESTful interface of VTN Manager and configures VTN Virtualization model components in OpenDaylight.<?asciidoc-br?>
(2) Handles multiple OpenDaylight orchestration.<?asciidoc-br?>
(3) Provides API to read the physical network details. See <link xlink:href="https://wiki.OpenDaylight.org/view/OpenDaylight_Virtual_Tenant_Network_(VTN):VTN_Coordinator:RestApi:L2_Network_Example_Using_VTN_Virtualization">samples</link> for usage.</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
<section xml:id="_feature_overview">
<title>Feature Overview</title>
<simpara>There are three features</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">odl-vtn-manager</emphasis> provides VTN Manager&#8217;s JAVA API.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">odl-vtn-manager-rest</emphasis> provides VTN Manager&#8217;s REST API.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">odl-vtn-manager-neutron</emphasis> provides the integration with Neutron interface.</simpara>
</listitem>
</itemizedlist>

<simpara>REST API documentation for VTN Manager, please refer to:
<link xlink:href="https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/manager/model/target/site/models/">https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/manager/model/target/site/models/</link></simpara>
<simpara>For VTN Java API documentation, please refer to: <link xlink:href="https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/target/apidocs/index.html">https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/target/apidocs/index.html</link></simpara>
<simpara>Once the Karaf distribution is up, install dlux and apidocs.</simpara>
<screen>feature:install odl-dlux-all odl-mdsal-apidocs</screen>

<section xml:id="_logging_in">
<title>Logging In</title>
<simpara>To Log in to DLUX, after installing the application:</simpara>
<itemizedlist>
<listitem>
<simpara>Open a browser and enter the login URL as <link xlink:href="http://&lt;OpenDaylight-IP&gt;:8181/index.html">http://&lt;OpenDaylight-IP&gt;:8181/index.html</link>.</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>Replace "&lt;OpenDaylight-IP&gt;" with the IP address of OpenDaylight  based on your environment.</simpara>
</note>

<itemizedlist>
<listitem>
<simpara>Login to the application with user ID and password credentials as admin.</simpara>
</listitem>
</itemizedlist>

<note>
<simpara>admin is the only default user available for DLUX in this release.</simpara>
</note>

<itemizedlist>
<listitem>
<simpara>In the right hand side frame, click "Yang UI".</simpara>
</listitem>
</itemizedlist>

<simpara>YANG documentation for VTN Manager, please refer to: <link xlink:href="https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/manager/model/target/site/models/">https://jenkins.opendaylight.org/releng/view/vtn/job/vtn-merge-beryllium/lastSuccessfulBuild/artifact/manager/model/target/site/models/</link></simpara>
</section>
</section>
</section>
<section xml:id="_vtn_coordinator">
<title>VTN Coordinator</title>
<simpara>The VTN Coordinator is an external application that provides a REST interface for an user to use OpenDaylight VTN Virtualization. It interacts with VTN Manager plugin to implement the user configuration. It is also capable of multiple OpenDaylight orchestration. It realizes VTN provisioning in OpenDaylight instances. In the OpenDaylight architecture VTN Coordinator is part of the network application, orchestration and services layer. VTN Coordinator will use the REST interface exposed by the VTN Manger to realize the virtual network using OpenDaylight. It uses OpenDaylight APIs (REST) to construct the virtual network in OpenDaylight instances. It provides REST APIs for northbound VTN applications and supports virtual networks spanning across multiple OpenDaylight by coordinating across OpenDaylight.</simpara>
<section xml:id="_feature_overview_2">
<title>Feature Overview</title>
<simpara>VTN Coordinator doesn&#8217;t have Karaf features.</simpara>
<simpara>For VTN Coordinator REST API, please refer to: <link xlink:href="https://wiki.opendaylight.org/view/OpenDaylight_Virtual_Tenant_Network_%28VTN%29:VTN_Coordinator:RestApi">https://wiki.opendaylight.org/view/OpenDaylight_Virtual_Tenant_Network_%28VTN%29:VTN_Coordinator:RestApi</link></simpara>
</section>
</section>
<section xml:id="_usage_examples">
<title>Usage Examples</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://wiki.OpenDaylight.org/view/OpenDaylight_Virtual_Tenant_Network_(VTN):VTN_Coordinator:RestApi:How_to_configure_L2_Network_with_Single_Controller">L2 Network using Single Controller</link></simpara>
</listitem>
</itemizedlist>

</section>
</section>
</chapter>
<chapter xml:id="_yang_tools">
<title>YANG Tools</title>
<section xml:id="_overview_36">
<title>Overview</title>
<simpara>YANG Tools is set of libraries and tooling providing support for use
<link xlink:href="https://tools.ietf.org/html/rfc6020">YANG</link> for Java (or other JVM-based language) projects and
applications.</simpara>
<simpara>YANG Tools provides following features in OpenDaylight:</simpara>
<itemizedlist>
<listitem>
<simpara>parsing of YANG sources and
semantic inference of relationship across YANG models as defined in
<link xlink:href="https://tools.ietf.org/html/rfc6020">RFC6020</link></simpara>
</listitem>
<listitem>
<simpara>representation of YANG-modeled data in Java</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Normalized Node</emphasis> representation - DOM-like tree model, which uses conceptual
meta-model more tailored to YANG and OpenDaylight use-cases than a standard XML
DOM model allows for.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Java Binding</emphasis> - concrete data model and classes generated from YANG models,
designed to provide compile-time safety when working with YANG-modeled data.</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>serialization / deserialization of YANG-modeled data driven by YANG
models</simpara>
<itemizedlist>
<listitem>
<simpara>XML - as defined in <link xlink:href="https://tools.ietf.org/html/rfc6020">RFC6020</link></simpara>
</listitem>
<listitem>
<simpara>JSON - as defined in <link xlink:href="https://tools.ietf.org/html/rfc6020">draft-lhotka-netmod-yang-json-01</link></simpara>
</listitem>
<listitem>
<simpara>Java Binding to Normalized Node and vice-versa</simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara>Integration of YANG model parsing into Maven build lifecycle and
support for third-party generators processing YANG models.</simpara>
</listitem>
</itemizedlist>

<simpara>YANG Tools project consists of following logical subsystems:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Commons</emphasis> - Set of general purpose code, which is not specific to YANG, but
is also useful outside YANG Tools implementation.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">YANG Model and Parser</emphasis> - YANG semantic model and lexical and semantic parser
of YANG models, which creates in-memory cross-referenced represenation of
YANG models, which is used by other components to determine their behaviour
based on the model.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">YANG Data</emphasis> - Definition of Normalized Node APIs and Data Tree APIs, reference
implementation of these APIs and implementation of XML and JSON codecs for
Normalized Nodes.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">YANG Maven Plugin</emphasis> - Maven plugin which integrates YANG parser into Maven
build lifecycle and provides code-generation framework for components, which
wants to generate code or other artefacts based on YANG model.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">YANG Java Binding</emphasis> - Mapping of YANG model to generated Java APIs.
Java Binding also references to set of compile-time and runtime components which
implements this mapping, provides generation of classes and APIs based on
YANG models and integrate these Java Binding objects with <emphasis role="strong">YANG Data</emphasis> APIs
and components.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Models</emphasis> - Set of <emphasis role="strong">IETF</emphasis> and <emphasis role="strong">YANG Tools</emphasis> models, with generated Java Bindings
so they could be simply consumed outside of <emphasis role="strong">YANG Tools</emphasis>.</simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_yang_java_binding_mapping_rules">
<title>YANG Java Binding: Mapping rules</title>
<simpara>This chapter covers the details of mapping YANG to Java.</simpara>
<note>
<simpara>The following source code examples does not show canonical generated
code, but rather illustrative example. Generated classes and interfaces may
differ from this examples, but APIs are preserved.</simpara>
</note>

<section xml:id="_general_conversion_rules">
<title>General conversion rules</title>
<section xml:id="_package_names_of_yang_models">
<title>Package names of YANG models</title>
<simpara>The package name consists of the following parts:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Opendaylight prefix</emphasis> - Specifies the opendaylight prefix. Every package name
starts with the prefix <literal>org.opendaylight.yang.gen.v</literal>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Java Binding version</emphasis> - Specifies the YANG Java Binding version.
Curent Binding version is <literal>1</literal>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Namespace</emphasis> - Specified by the value of <literal>namespace</literal> substatement.
URI is converted to package name structure.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Revision</emphasis> - Specifies the concatenation of word <literal>rev</literal> and value of <literal>module</literal>
substatements <literal>revision</literal> argument value without leading zeros before month and day.
For example: <literal>rev201379</literal></simpara>
</listitem>
</itemizedlist>

<simpara>After the package name is generated, we check if it contains any Java keywords
or starts with a digit. If so, then we add an underscore before the offending
token.</simpara>
<simpara>The following is a list of keywords which are prefixed with underscore:</simpara>
<simpara>abstract, assert, boolean, break, byte, case, catch, char, class, const,
continue, default, double, do, else, enum, extends, false, final, finally,
float, for, goto, if, implements, import, instanceof, int, interface, long,
native, new, null, package, private, protected, public, return, short, static,
strictfp, super, switch, synchronized, this, throw, throws, transient, true, try,
void, volatile, while</simpara>
<simpara>As an example suppose following yang model:</simpara>
<programlisting language="yang" linenumbering="unnumbered">module module {
    namespace "urn:2:case#module";
    prefix "sbd";
    organization "OPEN DAYLIGHT";
    contact "http://www.example.com/";
    revision 2013-07-09 {
    }
}</programlisting>

<simpara>After applying rules (replacing digits and Java keywords) the resulting
package name is <literal>org.opendaylight.yang.gen.v1.urn._2._case.module.rev201379</literal></simpara>
</section>
<section xml:id="_additional_packages">
<title>Additional Packages</title>
<simpara>In cases when YANG statement contain some of specific YANG
statements additional packages are generated to designate this containment.
Table below provides details of parent statement and nested statements, which
yields additional package generation:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Parent statement</entry>
        
        <entry align="left" valign="top">Substatement</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>list</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, choice</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>container</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, choice</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>choice</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>leaf, list, leaf-list, container, case</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>case</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, choice</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>rpc <literal>input</literal> or <literal>output</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, (choice isn&#8217;t supported)</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>notification</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, (choice isn&#8217;t supported)</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara><literal>augment</literal></simpara></entry>
        
        <entry align="left" valign="top"><simpara>list, container, choice, case</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>Substatements are not only mapped to Java setter methods in the interface
representing the parent statement, but they also generate packages with
names consisting of the parent statement package name with the parent statement
name appended.</simpara>
<simpara>For example, this YANG model considers the container statement <literal>cont</literal> as the
direct substatement of the module.</simpara>
<programlisting language="yang" linenumbering="unnumbered">container cont {
  container cont-inner {
  }
  list outter-list {
    list list-in-list {
    }
  }
}</programlisting>

<simpara>Container <literal>cont</literal> is the parent statement for the substatements
<literal>cont-inner</literal> and <literal>outter-list</literal>. <literal>list outter-list</literal> is the parent
statement for substatement <literal>list-in-list</literal>.</simpara>
<simpara>Java code is generated in the following structure:<?asciidoc-br?></simpara>
<itemizedlist>
<listitem>
<simpara><literal>org.opendaylight.yang.gen.v1.urn.module.rev201379</literal> - package contains direct
substatements of module statement</simpara>
<itemizedlist>
<listitem>
<simpara><literal>Cont.java</literal></simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><literal>org.opendaylight.yang.gen.v1.urn.module.rev201379.cont</literal> - package contains
substatements of <literal>cont</literal> container statement</simpara>
<itemizedlist>
<listitem>
<simpara><literal>ContInner.java</literal> - interface representing container <literal>cont-inner</literal></simpara>
</listitem>
<listitem>
<simpara><literal>OutterList.java</literal> - interface representing list <literal>outer-list</literal></simpara>
</listitem>
</itemizedlist>

</listitem>
<listitem>
<simpara><literal>org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.outter.list</literal> - package
contains substatements of outter-list list element</simpara>
<itemizedlist>
<listitem>
<simpara><literal>ListInList.java</literal></simpara>
</listitem>
</itemizedlist>

</listitem>
</itemizedlist>

</section>
<section xml:id="_class_and_interface_names">
<title>Class and interface names</title>
<simpara>Some YANG statements are mapped to Java classes and interfaces. The name of YANG
element may contain various characters which aren&#8217;t permitted in Java class names.
Firstly whitespaces are trimmed from YANG name. Next the characters space, -, `
are deleted and the subsequent letter is capitalized. At the end, first letter is
capitalized.</simpara>
<simpara>For example,
<literal>example-name_ without_capitalization</literal> would map to
<literal>ExampleNameWithoutCapitalization</literal>.</simpara>
</section>
<section xml:id="_getter_and_setter_names">
<title>Getter and setter names</title>
<simpara>In some cases, YANG statements are converted to getter and/or setter methods.
The process for getter is:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>the name of YANG statement is converted to Java class name style as
<link linkend="_class_and_interface_names">explained above</link>.</simpara>
</listitem>
<listitem>
<simpara>the word <literal>get</literal> is added as prefix, if resulting type is <literal>Boolean</literal>, the name
is prefixed with <literal>is</literal> prefix instead of <literal>get</literal>.</simpara>
</listitem>
<listitem>
<simpara>the return type of the getter method is set to Java type representing substatement</simpara>
</listitem>
</orderedlist>

<simpara>The process for setter is:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>the name of YANG statement is converted to Java class name style as
<link linkend="_class_and_interface_names">explained above</link>.</simpara>
</listitem>
<listitem>
<simpara>the word <literal>set</literal> is added as prefix</simpara>
</listitem>
<listitem>
<simpara>the input parameter name is set to element&#8217;s name converted to Java parameter style</simpara>
</listitem>
<listitem>
<simpara>the return parameter is set to builder type</simpara>
</listitem>
</orderedlist>

</section>
</section>
<section xml:id="_statement_specific_mapping">
<title>Statement specific mapping</title>
<section xml:id="_module_statement">
<title>module statement</title>
<simpara>YANG <literal>module</literal> statement is converted to Java as two Java classes.
Each of the classes is in the separate Java file. The names of Java files are
composed as follows:
<literal>&lt;module name&gt;&lt;suffix&gt;.java</literal> where <literal>&lt;suffix&gt;</literal> is either data or service.</simpara>
<section xml:id="_data_interface">
<title>Data Interface</title>
<simpara>Data Interface has a mapping similar to container, but contains only top level
nodes defined in module.</simpara>
<simpara>Data interface serves only as marker interface for type-safe APIs of
<literal>InstanceIdentifier</literal>.</simpara>
</section>
<section xml:id="_service_interface">
<title>Service Interface</title>
<simpara>Service Interface serves to describe RPC contract defined in the module.
This RPC contract is defined by <literal>rpc</literal> statements.</simpara>
<simpara>RPC implementation usually implement this interface and users of the RPCs
use this interface to invoke RPCs.</simpara>
</section>
</section>
<section xml:id="_container_statement">
<title>container statement</title>
<simpara>YANG containers are mapped to Java interfaces which extend the Java DataObject and
Augmentable&lt;container-interface&gt;, where container-interface is the name of the mapped
interface.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {

}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public interface Cont extends ChildOf&lt;...&gt;, Augmentable&lt;Cont&gt; {
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_leaf_statement">
<title>Leaf statement</title>
<simpara>Each leaf has to contain at least one type substatement. The leaf is mapped to
getter method of parent statement with return type equal to type substatement
value.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {
  leaf lf {
    type string;
  }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public interface Cont extends DataObject, Augmentable&lt;Cont&gt; {
    String getLf(); <co xml:id="CO6-1"/>
}</programlisting>
</para>
</formalpara>

<calloutlist>
  
  <callout arearefs="CO6-1">
    <para>Represents <literal>leaf lf</literal></para>
    
  </callout>
  
</calloutlist>

</section>
<section xml:id="_leaf_list_statement">
<title>leaf-list statement</title>
<simpara>Each leaf-list has to contain one type substatement. The leaf-list is mapped
to getter method of parent statement with return type equal to List of type
substatement value.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {
    leaf-list lf-lst {
        type string;
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public interface Cont extends DataObject, Augmentable&lt;Cont&gt; {
    List&lt;String&gt; getLfLst();
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_list_statement">
<title>list statement</title>
<simpara><literal>list</literal> statements are mapped to Java interfaces and a getter method is
generated in the interface associated with it&#8217;s parent statement.
The return type of getter the method is a Java List of objects implementing
the interface generated corresponding to the <literal>list statement.
Mapping of `list</literal> substatement to Java:</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {
  list outter-list {
    key "leaf-in-list";
    leaf number {
      type uint64;
    }
  }
}</programlisting>
</para>
</formalpara>

<simpara>The list statement  <literal>example-list</literal> is mapped to the Java interface <literal>ExampleList</literal> and
the <literal>Cont</literal> interface (parent of <literal>ExampleList</literal>) contains getter method with return
type <literal>List&lt;ExampleList&gt;</literal>. The presence of a <literal>key</literal> statement, triggers generation
of <literal>ExampleListKey</literal>, which may be used to identify item in list.</simpara>
<simpara>The end result is this Java:</simpara>
<formalpara>
<title>OutterList.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379.cont;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;
import Java.util.List;
import org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.outter.list.ListInList;

public interface OutterList extends DataObject, Augmentable&lt;OutterList&gt; {

    List&lt;String&gt; getLeafListInList();

    List&lt;ListInList&gt; getListInList();

    /*
    Returns Primary Key of Yang List Type
    */
    OutterListKey getOutterListKey();

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>OutterListKey.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379.cont;

import org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.OutterListKey;
import Java.math.BigInteger;

public class OutterListKey {

    private BigInteger _leafInList;

    public OutterListKey(BigInteger _leafInList) {
        super();
        this_leafInList = _leafInList;
    }

    public BigInteger getLeafInList() {
        return _leafInList;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((_leafInList == null) ? 0 : _leafInList.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        OutterListKey other = (OutterListKey) obj;
        if (_leafInList == null) {
            if (other._LeafInList != null) {
                return false;
            }
        } else if(!_leafInList.equals(other._leafInList)) {
            return false;
        }
        return true;
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder();
        builder.append("OutterListKey [_leafInList=");
        builder.append(_leafInList);
        builder.append("]");
        return builder.toString();
    }
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_choice_and_case_statements">
<title>choice and case statements</title>
<simpara>A <literal>choice</literal> element is mapped in mostly the same way a <literal>list</literal> element is. The
<literal>choice</literal> element is mapped to and interface (marker interface) and a new getter
method with the return type of a Java <literal>List</literal> of this marker interfaces is added
to the interface corresponding to the parent statement. Any <literal>case</literal>
substatements are mapped to Java interfaces which extend the marker interface.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {
    choice example-choice {
        case foo-case {
          leaf foo {
            type string;
          }
        }
        case bar-case {
            leaf bar {
              type string;
            }
        }
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;
import org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.ChoiceTest;

public interface Cont extends DataObject, Augmentable&lt;Cont&gt; {

    ExampleChoice getExampleChoice();

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>ExampleChoice.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379.cont;

import org.opendaylight.yangtools.yang.binding.DataObject;

public interface ExampleChoice extends DataContainer {
}</programlisting>
</para>
</formalpara>

<formalpara>
<title>FooCase.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.example.choice;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;
import org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.ChoiceTest;

public interface FooCase extends ExampleChoice, DataObject, Augmentable&lt;FooCase&gt; {

    String getFoo();

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>BarCase.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.example.choice;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;
import org.opendaylight.yang.gen.v1.urn.module.rev201379.cont.ChoiceTest;

public interface BarCase extends ExampleChoice, DataObject, Augmentable&lt;BarCase&gt; {

    String getBar();

}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_grouping_and_uses_statements">
<title>grouping and uses statements</title>
<simpara><literal>grouping`s are mapped to Java interfaces. `uses</literal> statements in some element
(using of concrete grouping) are mapped as extension of interface for this
element with the interface which represents grouping.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG Model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">grouping grp {
  leaf foo {
    type string;
  }
}

container cont {
    uses grp;
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Grp.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import org.opendaylight.yangtools.yang.binding.DataObject;

public interface Grp extends DataObject {

    String getFoo();

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;

public interface Cont extends DataObject, Augmentable&lt;Cont&gt;, Grp {
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_rpc_input_and_output_statements">
<title>rpc, input and output statements</title>
<simpara>An <literal>rpc</literal> statement is mapped to Java as method of class <literal>ModuleService.java</literal>.
Any substatements of an <literal>rpc</literal> are mapped as follows:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Rpc Substatement</entry>
        
        <entry align="left" valign="top">Mapping</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>input</simpara></entry>
        
        <entry align="left" valign="top"><simpara>presence of input statement triggers generation of interface</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>output</simpara></entry>
        
        <entry align="left" valign="top"><simpara>presence of output statement triggers generation of interface</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">rpc rpc-test1 {
    output {
        leaf lf-output {
            type string;
        }
    }
    input {
        leaf lf-input {
            type string;
        }
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>ModuleService.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import Java.util.concurrent.Future;
import org.opendaylight.yangtools.yang.common.RpcResult;

public interface ModuleService {

    Future&lt;RpcResult&lt;RpcTest1Output&gt;&gt; rpcTest1(RpcTest1Input input);

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>RpcTest1Input.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

public interface RpcTest1Input {

    String getLfInput();

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>RpcTest1Output.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

public interface RpcTest1Output {

    String getLfOutput();

}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_notification_statement">
<title>notification statement</title>
<simpara><literal>notification</literal> statements are mapped to Java interfaces which extend
the Notification interface.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">notification notif {
	}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Notif.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;


import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;
import org.opendaylight.yangtools.yang.binding.Notification;

public interface Notif extends DataObject, Augmentable&lt;Notif&gt;, Notification {
}</programlisting>
</para>
</formalpara>

</section>
</section>
<section xml:id="_augment_statement">
<title>augment statement</title>
<simpara><literal>augment</literal> statements are mapped to Java interfaces. The interface starts with
the same name as the name of augmented interface with a suffix corresponding to
the order number of augmenting interface. The augmenting interface also extends
<literal>Augmentation&lt;&gt;</literal> with actual type parameter equal to augmented interface.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG Model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">container cont {
}

augment "/cont" {
  leaf additional-value {
    type string;
  }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>Cont.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentable;

public interface Cont extends DataObject, Augmentable&lt;Cont&gt; {

}</programlisting>
</para>
</formalpara>

<formalpara>
<title>Cont1.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">package org.opendaylight.yang.gen.v1.urn.module.rev201379;

import org.opendaylight.yangtools.yang.binding.DataObject;
import org.opendaylight.yangtools.yang.binding.Augmentation;

public interface Cont1 extends DataObject, Augmentation&lt;Cont&gt; {

}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_yang_type_mapping">
<title>YANG Type mapping</title>
<section xml:id="_typedef_statement">
<title>typedef statement</title>
<simpara>YANG <literal>typedef</literal> statements are mapped to Java classes. A <literal>typedef</literal> may contain following
substatements:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Substatement</entry>
        
        <entry align="left" valign="top">Behaviour</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>type</simpara></entry>
        
        <entry align="left" valign="top"><simpara>determines wrapped type and how class will be generated</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>descripton</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Javadoc description</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>units</simpara></entry>
        
        <entry align="left" valign="top"><simpara>is not mapped</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>default</simpara></entry>
        
        <entry align="left" valign="top"><simpara>is not mapped</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<section xml:id="_valid_arguments_type">
<title>Valid Arguments Type</title>
<simpara>Simple values of type argument are mapped as follows:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">YANG Type</entry>
        
        <entry align="left" valign="top">Java type</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>boolean</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Boolean</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>empty</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Boolean</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>int8</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Byte</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>int16</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Short</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>int32</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Integer</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>int64</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Long</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>string</simpara></entry>
        
        <entry align="left" valign="top"><simpara>String or, wrapper class (if pattern substatement is specified)</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>decimal64</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Double</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>uint8</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Short</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>uint16</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Integer</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>uint32</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Long</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>uint64</simpara></entry>
        
        <entry align="left" valign="top"><simpara>BigInteger</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>binary</simpara></entry>
        
        <entry align="left" valign="top"><simpara>byte[]</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>Complex values of type argument are mapped as follows:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Argument Type</entry>
        
        <entry align="left" valign="top">Java type</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>enumeration</simpara></entry>
        
        <entry align="left" valign="top"><simpara>generated java enum</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>bits</simpara></entry>
        
        <entry align="left" valign="top"><simpara>generated class for bits</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>leafref</simpara></entry>
        
        <entry align="left" valign="top"><simpara>same type as referenced leaf</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>identityref</simpara></entry>
        
        <entry align="left" valign="top"><simpara>Class</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>union</simpara></entry>
        
        <entry align="left" valign="top"><simpara>generated java class</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>instance-identifier</simpara></entry>
        
        <entry align="left" valign="top"><simpara><literal>org.opendaylight.yangtools.yang.binding.InstanceIdentifier</literal></simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

</section>
</section>
<section xml:id="_enumeration_substatement_enum">
<title>Enumeration Substatement Enum</title>
<simpara>The YANG <literal>enumeration</literal> type has to contain some <literal>enum</literal> substatements. An <literal>enumeration</literal> is mapped as Java enum type (standalone class) and every YANG enum substatements is mapped to Java enum&#8217;s predefined values.</simpara>
<simpara>An <literal>enum</literal> statement can have following substatements:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Enum&#8217;s Substatement</entry>
        
        <entry align="left" valign="top">Java mapping</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>description</simpara></entry>
        
        <entry align="left" valign="top"><simpara>is not mapped in API</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>value</simpara></entry>
        
        <entry align="left" valign="top"><simpara>mapped as input parameter for every predefined value of enum</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">typedef typedef-enumeration {
    type enumeration {
        enum enum1 {
            description "enum1 description";
            value 18;
        }
        enum enum2 {
            value 16;
        }
        enum enum3 {
        }
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>TypedefEnumeration.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public enum TypedefEnumeration {
    Enum1(18),
    Enum2(16),
    Enum3(19);

    int value;

    private TypedefEnumeration(int value) {
        this.value = value;
    }
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_bits_s_substatement_bit">
<title>Bits&#8217;s Substatement Bit</title>
<simpara>The YANG <literal>bits</literal> type has to contain some bit substatements. YANG <literal>bits</literal> is mapped to
a Java class (standalone class) and every YANG <literal>bits</literal> substatements is mapped to a
boolean attribute of that class. In addition, the class provides overridden versions
of the Object methods <literal>hashCode</literal>, <literal>toString</literal>, and <literal>equals</literal>.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG Model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">typedef typedef-bits {
  type bits {
    bit first-bit {
      description "first-bit description";
        position 15;
      }
    bit second-bit;
  }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>TypedefBits.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public class TypedefBits {

    private Boolean firstBit;
    private Boolean secondBit;

    public TypedefBits() {
        super();
    }

    public Boolean getFirstBit() {
        return firstBit;
    }

    public void setFirstBit(Boolean firstBit) {
        this.firstBit = firstBit;
    }

    public Boolean getSecondBit() {
        return secondBit;
    }

    public void setSecondBit(Boolean secondBit) {
        this.secondBit = secondBit;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result +
         ((firstBit == null) ? 0 : firstBit.hashCode());
        result = prime * result +
         ((secondBit == null) ? 0 : secondBit.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        TypedefBits other = (TypedefBits) obj;
        if (firstBit == null) {
            if (other.firstBit != null) {
                return false;
            }
        } else if(!firstBit.equals(other.firstBit)) {
            return false;
        }
        if (secondBit == null) {
            if (other.secondBit != null) {
                return false;
            }
        } else if(!secondBit.equals(other.secondBit)) {
            return false;
        }
        return true;
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder();
        builder.append("TypedefBits [firstBit=");
        builder.append(firstBit);
        builder.append(", secondBit=");
        builder.append(secondBit);
        builder.append("]");
        return builder.toString();
    }
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_union_s_substatement_type">
<title>Union&#8217;s Substatement Type</title>
<simpara>If the type of a <literal>typedef</literal> is <literal>union</literal>, it has to contain <literal>type</literal> substatements.
The <literal>union typedef</literal> is mapped to class and its <literal>type</literal> substatements are mapped
to private class members. Every YANG union subtype gets its own Java constructor
with a parameter which represent just that one attribute.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">typedef typedef-union {
    type union {
        type int32;
        type string;
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>TypdefUnion.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public class TypedefUnion {

    private Integer int32;
    private String string;

    public TypedefUnion(Integer int32) {
        super();
        this.int32 = int32;
    }

    public TypedefUnion(String string) {
        super();
        this.string = string;
    }

    public Integer getInt32() {
        return int32;
    }

    public String getString() {
        return string;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((int32 == null) ? 0 : int32.hashCode());
        result = prime * result + ((string == null) ? 0 : string.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        TypedefUnion other = (TypedefUnion) obj;
        if (int32 == null) {
            if (other.int32 != null) {
                return false;
            }
        } else if(!int32.equals(other.int32)) {
            return false;
        }
        if (string == null) {
            if (other.string != null) {
                return false;
            }
        } else if(!string.equals(other.string)) {
            return false;
        }
        return true;
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder();
        builder.append("TypedefUnion [int32=");
        builder.append(int32);
        builder.append(", string=");
        builder.append(string);
        builder.append("]");
        return builder.toString();
    }
}</programlisting>
</para>
</formalpara>

</section>
<section xml:id="_string_mapping">
<title>String Mapping</title>
<simpara>The YANG <literal>string</literal> type can contain the substatements <literal>length</literal>
and <literal>pattern</literal> which are mapped as follows:</simpara>
<informaltable frame="all"
    rowsep="1" colsep="1">
  
  <tgroup cols="2">
    
    <colspec colname="col_1" colwidth="50*"/>
    
    <colspec colname="col_2" colwidth="50*"/>
    
    
    <thead>
      
      <row>
        
        <entry align="left" valign="top">Type substatements</entry>
        
        <entry align="left" valign="top">Mapping to Java</entry>
        
      </row>
      
    </thead>
    
    <tbody>
      
      <row>
        
        <entry align="left" valign="top"><simpara>length</simpara></entry>
        
        <entry align="left" valign="top"><simpara>not mapped</simpara></entry>
        
      </row>
      
      <row>
        
        <entry align="left" valign="top"><simpara>pattern</simpara></entry>
        
        <entry align="left" valign="top"><simpara>. list of string constants = list of patterns<?asciidoc-br?>
. list of Pattern objects<?asciidoc-br?>
. static initialization block where list of Patterns is initialized from list of string of constants</simpara></entry>
        
      </row>
      
    </tbody>
    
  </tgroup>
</informaltable>

<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">typedef typedef-string {
    type string {
        length 44;
        pattern "[a][.]*"
    }
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>TypedefString.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public class TypedefString {

    private static final List&lt;Pattern&gt; patterns = new ArrayList&lt;Pattern&gt;();
    public static final List&lt;String&gt; PATTERN`CONSTANTS = Arrays.asList("[a][.]*");

    static {
        for (String regEx : PATTERN`CONSTANTS) {
            patterns.add(Pattern.compile(regEx));
        }
    }

    private String typedefString;

    public TypedefString(String typedefString) {
        super();
        // Pattern validation
        this.typedefString = typedefString;
    }

    public String getTypedefString() {
        return typedefString;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((typedefString == null) ? 0 : typedefString.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) {
            return true;
        }
        if (obj == null) {
            return false;
        }
        if (getClass() != obj.getClass()) {
            return false;
        }
        TypedefString other = (TypedefString) obj;
        if (typedefString == null) {
            if (other.typedefString != null) {
                return false;
            }
        } else if(!typedefString.equals(other.typedefString)) {
            return false;
        }
        return true;
    }

    @Override
    public String toString() {
        StringBuilder builder = new StringBuilder();
        builder.append("TypedefString [typedefString=");
        builder.append(typedefString);
        builder.append("]");
        return builder.toString();
    }
}</programlisting>
</para>
</formalpara>

</section>
</section>
<section xml:id="_identity_statement">
<title>identity statement</title>
<simpara>The purpose of the <literal>identity</literal> statement is to define a new globally unique,
abstract, and untyped value.</simpara>
<simpara>The <literal>base</literal> substatement argument is the name of existing identity from which
the new identity is derived.</simpara>
<simpara>Given that, an <literal>identity</literal> statement is mapped to Java abstract class and
any <literal>base</literal> substatements are mapped as <literal>extends</literal> Java keyword.
The identity name is translated to class name.</simpara>
<simpara>For example, the following YANG:</simpara>
<formalpara>
<title>YANG Model</title>
<para>
<programlisting language="yang" linenumbering="unnumbered">identity toast-type {

}

identity white-bread {
   base toast-type;
}</programlisting>
</para>
</formalpara>

<simpara>is converted into this Java:</simpara>
<formalpara>
<title>ToastType.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public abstract class ToastType extends BaseIdentity {
    protected ToastType() {
        super();
    }
}</programlisting>
</para>
</formalpara>

<formalpara>
<title>WhiteBread.java</title>
<para>
<programlisting language="java" linenumbering="unnumbered">public abstract class WhiteBread extends ToastType {
    protected WhiteBread() {
        super();
    }
}</programlisting>
</para>
</formalpara>

</section>
</section>
</chapter>
<chapter xml:id="_yang_push_developer_guide">
<title>YANG-PUSH Developer Guide</title>
<section xml:id="_overview_37">
<title>Overview</title>
<simpara>The YANG PUBSUB project allows subscriptions to be placed on
targeted subtrees of YANG datastores residing on remote devices.
Changes in YANG objects within the remote subtree can be pushed
to an OpenDaylight controller as specified without a requiring
the controller to make a continuous set of fetch requests.</simpara>
<section xml:id="_yang_push_capabilities_available">
<title>YANG-PUSH capabilities available</title>
<simpara>This module contains the base code which embodies the intent of YANG-PUSH requirements for subscription as defined in {i2rs-pub-sub-requirements} [<link xlink:href="https://datatracker.ietf.org/doc/draft-ietf-i2rs-pub-sub-requirements/">https://datatracker.ietf.org/doc/draft-ietf-i2rs-pub-sub-requirements/</link>].   The mechanism for delivering on these YANG-PUSH requirements over Netconf transport is defined in {netconf-yang-push} [netconf-yang-push: <link xlink:href="https://tools.ietf.org/html/draft-ietf-netconf-yang-push-00">https://tools.ietf.org/html/draft-ietf-netconf-yang-push-00</link>].</simpara>
<simpara>Note that in the current release, not all capabilities of draft-ietf-netconf-yang-push are realized.   Currently only implemented is <emphasis role="strong">create-subscription</emphasis> RPC support from <link xlink:href="mailto:ietf-datastore-push@2015-10-15.yang">ietf-datastore-push@2015-10-15.yang</link>; and this will be for periodic subscriptions only.  There of course is intent to provide much additional functionality in future OpenDaylight releases.</simpara>
</section>
<section xml:id="_future_yang_push_capabilities">
<title>Future YANG-PUSH capabilities</title>
<simpara>Over time, the intent is to flesh out more robust capabilities which will allow OpenDaylight applications to subscribe to YANG-PUSH compliant devices.  Capabilities for future releases will include:</simpara>
<simpara>Support for subscription change/delete:
<emphasis role="strong">modify-subscription</emphasis> rpc support for all mountpoint devices or particular mountpoint device
<emphasis role="strong">delete-subscription</emphasis> rpc support for all mountpoint devices or particular mountpoint device</simpara>
<simpara>Support for static subscriptions:
This will enable the receipt of subscription updates pushed from publishing devices where no signaling from the controller has been used to establish the subscriptions.</simpara>
<simpara>Support for additional transports:
NETCONF is not the only transport of interest to OpenDaylight or the subscribed devices.  Over time this code will support Restconf and HTTP/2 transport requirements defined in {netconf-restconf-yang-push} [<link xlink:href="https://tools.ietf.org/html/draft-voit-netconf-restconf-yang-push-01">https://tools.ietf.org/html/draft-voit-netconf-restconf-yang-push-01</link>]</simpara>
</section>
</section>
<section xml:id="_yang_push_architecture">
<title>YANG-PUSH Architecture</title>
<simpara>The code architecture of Yang push consists of two main elements</simpara>
<simpara>YANGPUSH Provider
YANGPUSH Listener</simpara>
<simpara>YANGPUSH Provider receives create-subscription requests from applications and then establishes/registers the corresponding listener which will receive information pushed by a publisher.  In addition, YANGPUSH Provider also invokes an augmented OpenDaylight create-subscription RPC which enables applications to register for notification as per rfc5277. This augmentation adds periodic time period (duration) and subscription-id values to the existing RPC parameters. The Java package supporting this capability is “org.opendaylight.yangpush.impl”. Below class supports the YANGPUSH Provider capability:</simpara>
<simpara>(1) YangpushDomProvider
The Binding Independent version. It uses a neutral data Document Object Model format for data and API calls, which is independent of any generated Java language bindings from the YANG model.</simpara>
<simpara>The YANGPUSH Listener accepts update notifications from a device after they have been de-encapsulated from the NETCONF transport.  The YANGPUSH Listener then passes these updates to MD-SAL.  This function is implemented via the YangpushDOMNotificationListener class within the “org.opendaylight.yangpush.listner” Java package.</simpara>
</section>
<section xml:id="_key_apis_and_interfaces_19">
<title>Key APIs and Interfaces</title>
<section xml:id="_yangpushdomprovider">
<title>YangpushDomProvider</title>
<simpara>Central to this is onSessionInitiated  which acquires the Document Object Model format based versions of MD-SAL services, including the MountPoint service and RPCs.  Via these acquired services, invoke registerDataChangeListener over in YangpushDOMNotificationListener.</simpara>
</section>
<section xml:id="_yangpushdomnotificationlistener">
<title>YangpushDOMNotificationListener</title>
<simpara>This API handles instances of a received Push Updates which are inbound to the listener and places these in MD-SAL.   Key classes in include:</simpara>
<simpara>onPushUpdate
Converts and validates the encoding of the pushed subscription update. If the subscription exists and is active, calls updateDataStoreForPushUpdate so that the information can be put in MD-SAL. Finally logs the pushed subscription update as well as some additional context information.</simpara>
<simpara>updateDataStoreForPushUpdate
Used to put the published information into MD-SAL.  This pushed information will also include elements such as the subscription-id, the identity of the publisher, the time of the update, the incoming encoding type, and the pushed YANG subtree information.</simpara>
<simpara>YangpushDOMNotificationListener
Starts the listener tracking a new Subscription ID from a particular publisher.</simpara>
</section>
</section>
<section xml:id="_api_reference_documentation_18">
<title>API Reference Documentation</title>
<simpara>Javadocs are generated while creating mvn:site
and they are located in target/ directory in each module.</simpara>
</section>
</chapter>
</part>
</book>